\section{Series}\label{sec:series}

\paragraph{...}

Here \( (X, \norm) \) will refer to a Banach space over \( \BbbK \).

\begin{definition}\label{def:convergent_series}
  When extending addition to a countable amount of terms, we need to impose some regularity conditions to avoid contradictions. The topologies of \( \BbbR \) and \( \BbbC \) are complete and allow us to define convergent and divergent series. We define series in great generality because the theory easily allows it.

  A \term{numeric series} or simply \term{series} is an infinite sequence \( x_0, x_1, \ldots \in X \), which we call \term{terms}, usually written as
  \begin{equation}\label{def:convergent_series/series}
    \sum_{k=0}^\infty x_k.
  \end{equation}

  To each series, there corresponds its sequence of \term{partial sums}
  \begin{equation*}
    S_n \coloneqq \sum_{k=0}^n x_k, n = 0, 1, 2, \ldots
  \end{equation*}

  We can equivalently define a series as a sequence of partial sums and then recover the terms as
  \begin{equation*}
    x_k \coloneqq \begin{cases}
      S_0,           & k = 0, \\
      S_k - S_{k-1}, & k > 0
    \end{cases}
  \end{equation*}

  We say that the series \eqref{def:convergent_series/series} \term{converges} to a value \( x \) if \( \lim_{n \to \infty} S_n = x \) in the sense of \fullref{def:net_limit_point}. The value \( x \) is called the \term{sum} of the series.

  If a series does not converge, we say that it is \term{divergent}.

  If the related series
  \begin{equation}\label{def:convergent_series/absolute_series}
    \sum_{k=0}^\infty \norm{x_k}
  \end{equation}
  converges, we say that \eqref{def:convergent_series/series} is \term{absolutely convergent}.
\end{definition}

\begin{example}\label{ex:series}
  Several examples of series are
  \begin{itemize}
    \item An absolutely convergent series is \eqref{eq:thm:def:geometric_series/series_sum_interior}.
    \item A divergent series is the harmonic series \eqref{eq:ex:harmonic_series/harmonic}.
    \item A convergent, but not absolutely convergent series is the alternating harmonic series \eqref{eq:ex:harmonic_series/alternating}.
  \end{itemize}
\end{example}

\begin{proposition}\label{thm:truncated_series_convergence}
  For any positive integer \( n \), the series \eqref{def:convergent_series/series} converges if and only if the truncated series with \( k > n \) converges.
\end{proposition}

\begin{proposition}\label{thm:absolutely_convergent_series_is_convergent}
  An absolutely convergent series is convergent.
\end{proposition}
\begin{proof}
  Suppose that \eqref{def:convergent_series/absolute_series} converges.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \norm{\sum_{k=0}^n x_k} \leq \sum_{k=0}^n \norm{x_k} \leq \sum_{k=0}^\infty \norm{x_k}.
  \end{equation*}

  Thus, the sequence \( \left\{ \norm{\sum_{k=0}^{n} x_k} \right\}_{n=0}^\infty \) is a bounded (by \( \sum_{k=0}^\infty \norm{x_k} \)) monotone sequence, which by \fullref{thm:real_monotone_sequence_converges_iff_bounded} is convergent.

  Therefore, the series \eqref{def:convergent_series/series} is convergent.
\end{proof}

\begin{remark}\label{rem:establish_series_convergence_by_absolute_series}
  Convergence of the series \eqref{def:convergent_series/series} can be established using the convergence of the nonnegative series \eqref{def:convergent_series/absolute_series}.

  The convergence of the latter can be established using techniques in \fullref{sec:real_series} like \fullref{thm:cauchys_root_test} or \fullref{thm:dalamberts_ratio_test}.
\end{remark}

\begin{proposition}\label{thm:infinitary_triangle_inequality}
  For every series \eqref{def:convergent_series/series} we have
  \begin{equation}\label{thm:infinitary_triangle_inequality/inequality}
    \norm{\sum_{k=0}^\infty x_k} \leq \sum_{k=0}^\infty \norm{x_k},
  \end{equation}
  where both limits are allowed to be infinite.
\end{proposition}
\begin{proof}
  If the series on the right diverges, the inequality is obviously true.

  Suppose that it is convergent. By \fullref{thm:absolutely_convergent_series_is_convergent}, the limit
  \eqref{def:convergent_series/series} exists.

  By the triangle inequality, for each index \( n \) we have
  \begin{equation*}
    \norm{\sum_{k=0}^n x_k} \leq \sum_{k=0}^n \norm{x_k}.
  \end{equation*}

  By \fullref{thm:one_sided_squeeze_lemma}, since both sequences are convergent, we obtain \fullref{thm:infinitary_triangle_inequality/inequality}.
\end{proof}

\begin{proposition}\label{thm:convergent_series_terms_vanish}
  The terms of the convergent series \eqref{def:convergent_series/series} vanish as \( k \to \infty \), that is,
  \begin{equation*}
    \lim_{k \to \infty} x_k = 0.
  \end{equation*}
\end{proposition}
\begin{proof}
  Since the series is convergent, its sequence of partial sums converges, i.e. the partial sums get arbitrarily close to each other. Then
  \begin{equation*}
    \norm{x_n} = \norm{S_n - S_{n-1}} \to 0.
  \end{equation*}
\end{proof}

\begin{theorem}\label{thm:product_of_series_convergence}
  Consider two convergent series
  \begin{equation}\label{thm:product_of_series_convergence/a}
    A \coloneqq \sum_{k=0}^\infty x_k
  \end{equation}
  and
  \begin{equation}\label{thm:product_of_series_convergence/b}
    B \coloneqq \sum_{k=0}^\infty y_k.
  \end{equation}

  If either \fullref{thm:product_of_series_convergence/a} or \fullref{thm:product_of_series_convergence/b} converges absolutely, then
  \begin{equation}\label{thm:product_of_series_convergence/prod}
    \sum_{k=0}^\infty \sum_{m=0}^k x_m y_{k-m} = AB.
  \end{equation}
\end{theorem}


\paragraph{Geometric series}

\begin{definition}\label{def:geometric_series}\mcite[61]{Rudin1976AnalysisPrinciples}
  A \term{geometric series} is \hyperref[def:convergent_series]{series} whose terms come from a complex-valued \hyperref[def:geometric_progression]{geometric progression} with initial value \( 1 \):
  \begin{equation}\label{eq:def:geometric_series}
    \sum_{k=0}^\infty z^k.
  \end{equation}
\end{definition}
\begin{comments}
  \item Rudin defines the series only for real numbers, for the generalization is straightforward.
\end{comments}

\begin{proposition}\label{thm:def:geometric_series}
  The geometric series \eqref{eq:def:geometric_series} has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:geometric_series/finite_sum} For all \( z \in \BbbC \setminus \set{ 1 } \), the geometric series \eqref{eq:def:geometric_series} has partial sums
    \begin{equation}\label{eq:thm:def:geometric_series/finite_sum}
      \sum_{k=0}^n z^k = \frac {1 - z^{n+1}} {1 - z}.
    \end{equation}

    \thmitem{thm:def:geometric_series/degenerate} In the degenerate case \( z = 1 \), the progression itself is constant, and its partial sums are instead
    \begin{equation}\label{eq:thm:def:geometric_series/degenerate}
      \sum_{k=0}^n z^k = n + 1.
    \end{equation}

    \thmitem{thm:def:geometric_series/series_sum_exterior} The series diverges when \( \abs{z} \geq 1 \).

    \thmitem{thm:def:geometric_series/series_sum_interior} For \( 0 < \abs{z} < 1 \), the series converges absolutely with limit
    \begin{equation}\label{eq:thm:def:geometric_series/series_sum_interior}
      \sum_{k=0}^\infty z^k = \frac 1 {1 - z}.
    \end{equation}
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:geometric_series/finite_sum} Follows from \fullref{thm:xn_minus_yn_factorization}.

  \SubProofOf{thm:def:geometric_series/degenerate} Obvious.

  \SubProofOf{thm:def:geometric_series/series_sum_exterior}

  \SubProof*{Proof for \( z = 1 \)} If \( z = 1 \), \fullref{thm:def:geometric_series/degenerate} implies that the series diverges because it grows indefinitely.

  \SubProof*{Proof for \( \abs{z} = 1 \) and \( z \neq 1 \)} In this case the integer powers \( z^k \) are rotations around the complex plane unit circle, which do not tend to a limit. Hence, the series diverges again.

  \SubProof*{Proof for \( \abs{z} > 1 \)} In this case \( \abs{z^n} \) grows indefinitely with \( n \), and it follows that
  \begin{equation*}
    \sum_{k=m}^n z^k
    =
    z^m \sum_{k=0}^{n-m} z^k
    =
    z^m \frac {1 - z^{n-m+1}} {1 - z}
    =
    \frac {z^m - z^{n+1}} {1 - z}.
  \end{equation*}
  can get arbitrarily far from \( 0 \). Therefore, in this case the series also diverges.

  \SubProofOf{thm:def:geometric_series/series_sum_interior} Fix \( z \in B(0, 1) \). Since only \( z^{n + 1} \) depends on \( n \) in \eqref{eq:thm:def:geometric_series/finite_sum}, we obtain \eqref{eq:thm:def:geometric_series/series_sum_interior} by simply noting that \( z^n \to 0 \) when \( n \to \infty \).
\end{proof}

\begin{example}\label{ex:def:geometric_series}
  We list some examples of \hyperref[def:geometric_series]{geometric series}:
  \begin{thmenum}
    \thmitem{ex:def:geometric_series/two} A surprisingly useful series occurs for \( z = 1 / 2 \), where
    \begin{equation}\label{eq:ex:def:geometric_series/two}
      \sum_{k=0}^\infty \frac 1 {2^k}
      \reloset {\eqref{eq:thm:def:geometric_series/series_sum_interior}} =
      \frac 1 {1 - 1 / 2}
      =
      2.
    \end{equation}

    Its usefulness comes from the fact that
    \begin{equation}\label{eq:ex:def:geometric_series/two/one}
      \sum_{k=1}^\infty \frac 1 {2^k}
      =
      \sum_{k=0}^\infty \frac 1 {2^k} - 1
      =
      1,
    \end{equation}
    hence we can use the terms for generalized \hyperref[def:convex_hull]{convex combinations}.

    \thmitem{ex:def:geometric_series/interest} In this example we will exploit the equivalence between the closed form representations in \fullref{def:arithmetic_progression} and \fullref{def:geometric_progression} and the corresponding inductive definitions. The equivalences are obvious from a mathematical standpoint, however outside of mathematics they have highly nontrivial consequences. Indeed, they highlight the difference between simple interest and compound interest.

    Consider a savings account with \( 1000\$ \). A simple monthly interest of \( 2\% \) will earn \( 240\$ \) over a year:
    \begin{equation*}
      1000 (1 + 12 \cdot 2 / 100) = 1240.
    \end{equation*}

    The same account with a compound monthly interest of \( 2\% \) will earn a bit more - about \( 268\$ \):
    \begin{equation*}
      1000 (1 + 2 / 100)^{12} \approx 1268.24.
    \end{equation*}

    Over the course of ten years, however, simple interest will earn a total of \( 2400\$ \), while compound interest will earn \( \approx 9765\$ \).

    The difference between linear and exponential growth appears staggering in a real-world situation even though the difference may not be very noticeable in the short-term.

    \thmitem{ex:def:geometric_series/cube_root} Let \( z \) be a complex cube root of \( 1 \). We can compute
    \begin{equation*}
      (1 + z) (1 + z^2) (1 + \underbrace{z^3}_2) (1 + \underbrace{z^4}_z) (1 + \underbrace{z^5}_{z^2}) (1 + \underbrace{z^6}_1)
      =
      [2 (1 + z) (1 + z^2)]^2
      =
      4 [1 + z + z^2 + z^3]^2
    \end{equation*}
    by using \fullref{thm:def:geometric_series/finite_sum}:
    \begin{equation*}
      4 [1 + z + z^2 + z^3]^2
      =
      4 \parens*{ \frac {1 - z^4} {1 - z} }^2.
    \end{equation*}

    Since \( 1 - z^4 = 1 - z \), the result is \( 4 \).
  \end{thmenum}
\end{example}

\paragraph{...}

\begin{proposition}[Cauchy's series convergence criterion]\label{thm:cauchy_series_convergence_criterion}\mcite[3.22]{Rudin1976AnalysisPrinciples}
  The series \eqref{def:convergent_series/series} converges if and only if for every \( \varepsilon > 0 \) there exists an index \( k_0 \) such that
  \begin{equation*}
    \norm{\sum_{k=m}^n x_k} < \varepsilon \quad\forall m, n \geq k_0.
  \end{equation*}
\end{proposition}
\begin{proof}
  This is simply a restatement of \fullref{thm:cauchys_net_convergence_criterion}.
\end{proof}

\begin{proposition}[Cauchy's series continuity criterion]\label{thm:cauchy_series_continuity_criterion}\mcite[\S 265]{Фихтенгольц1968ОсновыАнализаТом2}
  Fix a topological space \( A \) and a set \( S \subseteq A \). Let \( \{ f_k \}_{k=0}^\infty \) be a sequence of continuous functions from \( S \) to \( X \).

  Define the function \( f: S \to X \) as
  \begin{equation}\label{thm:cauchy_series_continuity_criterion/function}
    f(x) \coloneqq \sum_{k=0}^\infty f_k(x).
  \end{equation}

  A sufficient condition for \( f \) to be continuous in \( S \) is that for every \( \varepsilon > 0 \) there exists an index \( K \) such that
  \begin{equation*}
    \norm{\sum_{k=m}^n f(x)} < \varepsilon \quad\forall m, n \geq K
  \end{equation*}
  simultaneously for all \( x \in S \).
\end{proposition}
\begin{proof}
  This is simply a restatement of \fullref{thm:uniform_limit_of_continuous_functions} in the style of \fullref{thm:cauchy_series_convergence_criterion}.
\end{proof}

\begin{corollary}[Weierstrass' series criterion]\label{thm:weierstrass_series_criterion}\mcite[\S 265]{Фихтенгольц1968ОсновыАнализаТом2}
  Let \( S \) be any set and \( \{ f_k \}_{k=0}^\infty \) be a sequence of functions from \( S \) to \( X \). Consider the series \fullref{thm:cauchy_series_continuity_criterion/function}. If
  \begin{equation*}
    \forall k \in \BbbZ^{>0} \ \exists M_k \in \BbbR^{>0} \ \forall x \in S : \norm{f_k(x)} < M_k
  \end{equation*}
  and if the series
  \begin{equation}\label{thm:weierstrass_series_criterion/dominating}
    \sum_{k=0}^\infty M_k
  \end{equation}
  converges, then the limit \fullref{thm:cauchy_series_continuity_criterion/function} exists for every \( x \in S \) and, furthermore, the series converges absolutely and uniformly.

  In analogy to \fullref{thm:positive_series_comparison}, we say that the series \fullref{thm:weierstrass_series_criterion/dominating} \term{dominates} the series \fullref{thm:cauchy_series_continuity_criterion/function}.

  In particular, if \( S \) has a topology and the functions \( f_k(x), k = 0, 1, \ldots \) are continuous (resp. uniformly continuous), so is \( f(x) \).
\end{corollary}
\begin{proof}
  By \fullref{thm:positive_series_comparison}, the series
  \begin{equation*}
    \sum_{k=0}^\infty \norm{f_k(x)}
  \end{equation*}
  converges for any \( x \in S \), hence \fullref{thm:cauchy_series_continuity_criterion/function} converges absolutely for any \( x \in S \).

  Furthermore, each of the functions \( f_k(x) \) is bounded by \( B(0, M_k) \) and \( M_k \) does not depend on \( x \), hence the convergence is uniform.

  The rest of the theorem follows from \fullref{thm:uniform_limit_of_continuous_functions}.
\end{proof}

\begin{corollary}\label{thm:continuous_function_series_powers_of_two}
  Let \( X \subseteq \BbbR \) be a nonempty set. Consider the series of real-valued real functions
  \begin{equation}\label{thm:continuous_function_series_powers_of_two/series}
    f(x) \coloneqq \sum_{k=0}^\infty \frac {f_k(x)} {2^k},
  \end{equation}
  where \( \{ f_k \}_{k=0}^\infty \subseteq B_{C(X)} \) is a sequence of continuous functions bounded in \( [-1, 1] \).

  Then \( f(x) \) is defined and continuous for all \( x \in X \).
\end{corollary}
\begin{proof}
  For \( \abs{x} \leq 1 \), the series is dominated by the geometric series \eqref{ex:def:geometric_series/two}, which sums to \( 2 \), hence by \fullref{thm:weierstrass_series_criterion} \( f(x) \) is continuous in the interval \( [-1, 1] \).

  Note that
  \begin{equation*}
    f(2x) \coloneqq \sum_{k=0}^\infty \frac x {2^{k-1}} = 2 f(x),
  \end{equation*}
  hence the series \fullref{thm:continuous_function_series_powers_of_two/series} also converges for \( \abs{x} \leq 2 \).

  By induction on \( n \), we show that \( f(2^n x) = 2^n f(x) \) and thus \( f(x) \) is continuous in \( B(0, 2^n) \), therefore also on the entire real line \( \BbbR \).
\end{proof}

\begin{example}\label{thm:weierstrass_series_criterion/counterexample}\mcite[\S 266]{Фихтенгольц1968ОсновыАнализаТом2}
  Consider the real series
  \begin{equation*}
    f(x) \coloneqq \sum_{k=0}^\infty x^k (1 - x).
  \end{equation*}

  It converges for \( \abs{x} < 1 \) because it is dominated by a convergent geometric series.

  For \( x \in (0, 1) \),
  \begin{equation*}
    f(x)
    =
    \sum_{k=0}^\infty x^k (1 - x)
    =
    \sum_{k=0}^\infty x^k - \sum_{k=1}^\infty x^k
    =
    1.
  \end{equation*}

  But
  \begin{equation*}
    \lim_{t \uparrow 1} f(x) = 1 \neq 0 = f(1) = f(\lim_{t \uparrow 1} t).
  \end{equation*}

  This shows that \( f(x) \) is not continuous, despite every term being continuous.

  By contraposition to \fullref{thm:weierstrass_series_criterion}, it follows that no series that dominates \( f(x) \) converges.
\end{example}

\begin{theorem}\label{thm:uniform_limit_exchange}\mcite[\S 268]{Фихтенгольц1968ОсновыАнализаТом2}
  Fix a uniform space \( (A, \mscrU) \) and let \( S \subseteq A \). Let \( f_k: S \to X, k = 0, 1, \ldots \) be a sequence of functions and assume that \( x_0 \in M \) is a limit point of each of these functions.

  \begin{thmenum}
    \thmitem{thm:uniform_limit_exchange/sequence} If the sequence \( \{ f_k \}_{k=0}^\infty \) converges uniformly on \( S \), we can exchange the limits
    \begin{equation*}
      \lim_{x \to x_0} \lim_{k \to \infty} f_k(x)
      =
      \lim_{k \to \infty} \lim_{x \to x_0} f_k(x).
    \end{equation*}

    \thmitem{thm:uniform_limit_exchange/series} If the series \fullref{thm:cauchy_series_continuity_criterion/function} converges uniformly on \( S \), we can exchange the limits
    \begin{equation*}
      \lim_{x \to x_0} \sum_{k=0}^\infty f_k(x)
      =
      \sum_{k=0}^\infty \lim_{x \to x_0} f_k(x).
    \end{equation*}
  \end{thmenum}
\end{theorem}

\begin{remark}\label{rem:thm:uniform_limit_exchange_continuity}
  If the functions \( f_k \) in \fullref{thm:uniform_limit_exchange/series} are continuous at \( x_0 \), we have the additional equality
  \begin{equation}\label{thm:uniform_limit_exchange/continuous_equality}
    \lim_{x \to x_0} f(x)
    =
    \lim_{x \to x_0} \sum_{k=0}^\infty f_k(x)
    =
    \sum_{k=0}^\infty \lim_{x \to x_0} f_k(x)
    \reloset * =
    \sum_{k=0}^\infty f_k\left(\lim_{x \to x_0} x \right)
    =
    f\left(\lim_{x \to x_0} x \right),
  \end{equation}
  thus \( f \) is continuous at \( x_0 \). The continuity actually follows from \fullref{thm:cauchy_series_continuity_criterion} directly.
\end{remark}

\begin{corollary}\label{thm:riemann_intergral_limit_exchange}\mcite[\S 269]{Фихтенгольц1968ОсновыАнализаТом2}
  Let \( \{ f_k \}_{k=0}^\infty \subseteq C([a, b], \BbbR) \).

  \begin{thmenum}
    \thmitem{thm:riemann_intergral_limit_exchange/sequence} If the sequence \( \{ f_k \}_{k=0}^\infty \) converges uniformly, then
    \begin{equation*}
      \lim_{k \to \infty} \int_a^b f_k(x) dx = \int_a^b \lim_{k \to \infty} f_k(x) dx.
    \end{equation*}

    \thmitem{thm:riemann_intergral_limit_exchange/series} If the series \fullref{thm:cauchy_series_continuity_criterion/function} converges uniformly, then
    \begin{equation*}
      \int_a^b f(x) dx = \int_a^b \sum_{k=0}^\infty f_k(x) dx = \sum_{k=0}^\infty \int_a^b f_k(x) dx.
    \end{equation*}
  \end{thmenum}
\end{corollary}
\begin{proof}
  \SubProofOf{thm:riemann_intergral_limit_exchange/sequence} Assume that the sequence \( \{ f_k \}_{k=0}^\infty \) converges uniformly to \( f \). Then by \fullref{thm:uniform_limit_exchange}, we note that for any index \( k \), the difference \( r_k(x) \coloneqq f(x) - f_k(x) \) is continuous, hence integrable, and
  \begin{equation*}
    \int_a^b f(x) dx = \int_a^b f_k(x) dx + \int_a^b r_k(x) dx.
  \end{equation*}

  Because of the uniform convergence, for any \( \delta > 0 \) and there exist an index \( k_0 \) such that
  \begin{equation*}
    \abs{f(x) - f_k(x)} = \abs{r_k(x)} < \delta \quad\forall k \geq k_0, \forall x \in [a, b].
  \end{equation*}

  Then
  \begin{equation*}
    \abs{\int_a^b f(x) dx - \int_a^b f_k(x) dx} = \abs{\int_a^b r_k(x) dx} < (b - a) \delta.
  \end{equation*}

  Given \( \varepsilon > 0 \), we define \( \delta \coloneqq \frac \varepsilon {b - a} \) to obtain an index \( k_0 \) such that
  \begin{equation*}
    \abs{\int_a^b f(x) dx - \int_a^b f_k(x) dx} = \abs{\int_a^b r_k(x) dx} < \varepsilon \quad\forall k \geq k_0.
  \end{equation*}

  Thus, \fullref{def:net_limit_point} is satisfied and equality holds.

  \SubProofOf{thm:riemann_intergral_limit_exchange/series} This is a special case of \fullref{thm:riemann_intergral_limit_exchange/sequence}.
\end{proof}

\begin{corollary}\label{thm:derivative_limit_exchange}\mcite[thm. 7.17]{Rudin1976AnalysisPrinciples}
  Let \( \{ f_k \}_{k=0}^\infty \subseteq C^1([a, b], \BbbR) \). Suppose that the series \fullref{thm:cauchy_series_continuity_criterion/function} converges for at least one point \( x_0 \in [a, b] \).

  \begin{thmenum}
    \thmitem{thm:derivative_limit_exchange/sequence} If the sequence \( \{ D f_k \}_{k=0}^\infty \) of derivatives converges uniformly, then \( \{ f_k \}_{k=0}^\infty \) also converges uniformly, its limit is differentiable in \( (a, b) \) and
    \begin{equation*}
      D\left(\lim_{k \to \infty} f_k(x) \right) = \lim_{k \to \infty} D f_k(x).
    \end{equation*}

    \thmitem{thm:derivative_limit_exchange/series} If the series of derivatives
    \begin{equation}\label{thm:derivative_limit_exchange/derivative_series}
      \sum_{k=0}^\infty D f_k(x)
    \end{equation}
    converges uniformly, then \fullref{thm:cauchy_series_continuity_criterion/function} converges uniformly, is differentiable in \( (a, b) \) and
    \begin{equation*}
      D\left(\sum_{k=0}^\infty f_k(x)\right) = \sum_{k=0}^\infty D f_k(x).
    \end{equation*}
  \end{thmenum}
\end{corollary}
\begin{proof}
  \SubProofOf{thm:derivative_limit_exchange/sequence} Fix \( \varepsilon > 0 \). Since the sequence \( \{ f_k \}_{k=0}^\infty \) converges for \( x_0 \), there exists an index \( k_0 \) such that
  \todo{Prove complex case}
  \begin{equation*}
    \abs{f_m(x_0) - f_n(x_0)} < \varepsilon \quad\forall m, n \geq k_0.
  \end{equation*}

  Furthermore, there exists an index \( k_1 \) such that
  \begin{equation*}
    \abs{D f_m(x) - D f_n(x)} < \varepsilon \quad\forall x \in [a, b] \ \forall m, n \geq k_0.
  \end{equation*}

  Fix \( m, n \geq k_0 \) and \( x \in [a, b] \). Note that the function \( f_m - f_n \) is differentiable and thus by the mean value theorem, there exists \( \xi \) between \( x_0 \) and \( x \) such that
  \begin{equation*}
    \frac {[f_m(x) - f_n(x)] - [f_m(x_0) - f_n(x_0)]} {x - x_0} = D f_m(\xi) - D f_n(\xi).
  \end{equation*}

  Thus,
  \begin{balign*}
    \abs{f_m(x) - f_n(x)}
     & \leq
    \abs{f_m(x_0) - f_n(x_0)} + (x - x_0)\abs{D f_m(\xi) - D f_n(\xi)}
    <       \\ &<
    2 (x - x_0) \varepsilon
    \leq    \\ &\leq
    2 (b - a) \varepsilon.
  \end{balign*}

  Therefore, the limit \( \lim_{k\to\infty} f_k(x) \) exists. Since \( x \) was arbitrary and \( 2 (b - a) \varepsilon \) does not depend on \( x \), we conclude that
  \begin{equation*}
    f(x) \coloneqq \lim_{k\to\infty} f_k(x)
  \end{equation*}
  is uniformly convergent on \( [a, b] \).

  By the Newton-Leibniz theorem, for the sequence \( \{ D f_k \}_{k=0}^\infty \) of derivatives we have
  \begin{equation*}
    \lim_{k \to \infty} \int_a^x D f_k(t) dt
    =
    \lim_{k \to \infty} [f_k(x) - f_k(a)]
    =
    \lim_{k \to \infty} f_k(x) - \lim_{k \to \infty} f_k(a)
    =
    f(x) - f(a).
  \end{equation*}

  Differentiating both sides, we obtain
  \begin{equation*}
    D\left(\lim_{k \to \infty} \int_a^x D f_k(t) dt \right)
    =
    D\left(\lim_{k \to \infty} f_k(x) dt \right)
    =
    D f(x).
  \end{equation*}

  \Fullref{thm:riemann_intergral_limit_exchange/sequence} allows us to conclude that
  \begin{equation*}
    D f(x)
    =
    D\left(\lim_{k \to \infty} \int_a^x D f_k(t) dt \right)
    =
    D \int_a^x \lim_{k \to \infty} D f_k(t) dt
    =
    \lim_{k \to \infty} D f_k(x).
  \end{equation*}

  \SubProofOf{thm:derivative_limit_exchange/series} This is a special case of \fullref{thm:riemann_intergral_limit_exchange/sequence}.
\end{proof}

\begin{example}\label{ex:harmonic_series}
  We list several important series related to harmonic progressions.

  \begin{thmenum}
    \thmitem{ex:harmonic_series/harmonic} The series
    \begin{equation}\label{eq:ex:harmonic_series/harmonic}
      \sum_{k=1}^\infty \frac 1 k = 1 + \frac 1 2 + \frac 1 3 + \frac 1 4 + \cdots
    \end{equation}
    is called \hi{the} \term{harmonic series}. It diverges as shown in \fullref{thm:harmonic_series_diverges}, which make it much less useful in practice, however it is an important enough example that it has a dedicated name.

    \thmitem{ex:harmonic_series/alternating} The series
    \begin{equation}\label{eq:ex:harmonic_series/alternating}
      \sum_{k=1}^\infty \frac {(-1)^k} k
      =
      \sum_{m=1}^\infty \parens*{ \frac 1 {2m - 1} - \frac 1 {2m} }
      =
      1 - \frac 1 2 + \frac 1 3 - \frac 1 4 + \cdots
    \end{equation}
    is called the \term{alternating harmonic series}. It converges, but not absolutely --- \fullref{thm:alternating_harmonic_series_convergence}.

    \thmitem{ex:harmonic_series/hyperharmonic} For any \( s \in \BbbC \), the series
    \begin{equation}\label{eq:ex:harmonic_series/hyperharmonic}
      \sum_{k=1}^\infty \frac 1 {k^s}.
    \end{equation}
    is called the \term{hyperharmonic series}.

    Unlike the harmonic series, the hyperharmonic series sometimes converges --- see \fullref{thm:hyperharmonic_series_convergence}.
  \end{thmenum}
\end{example}

\begin{proposition}\label{thm:harmonic_series_diverges}
  The harmonic series \eqref{eq:ex:harmonic_series/harmonic} diverges.
\end{proposition}
\begin{proof}
  Define the series
  \begin{equation*}
    1 + \frac 1 2 + \underbrace{\frac 1 4 + \frac 1 4}_{1 / 2} + \underbrace{\frac 1 8 + \frac 1 8 + \frac 1 8 + \frac 1 8}_{1 / 2} + \underbrace{\frac 1 {16} + \cdots + \frac 1 {16}}_{1 / 2} + \cdots
  \end{equation*}

  It is divergent as the sum of infinitely many \( 1 / 2 \). Furthermore, it is dominated by the harmonic series:
  \begin{align*}
    &1 + \frac 1 2 + \frac 1 3 + \frac 1 4 + \frac 1 5 + \frac 1 6 + \frac 1 7 + \frac 1 8 + \frac 1 9 \thinspace + \cdots + \frac 1 {16} + \cdots
    \\
    &1 + \frac 1 2 + \overbrace{ \frac 1 4 + \frac 1 4 }^{1 / 2} + \overbrace{ \frac 1 8 + \frac 1 8 + \frac 1 8 + \frac 1 8 }^{1 / 2} + \overbrace{ \frac 1 {16} + \cdots + \frac 1 {16} }^{1 / 2} + \cdots
  \end{align*}

  Thus, by \fullref{thm:positive_series_comparison}, the harmonic series also diverges.
\end{proof}

\begin{proposition}\label{thm:alternating_harmonic_series_convergence}\mcite[\S 247]{Фихтенгольц1968ОсновыАнализаТом2}
  Consider the alternating harmonic series \eqref{eq:ex:harmonic_series/alternating}.

  Compare the series with \eqref{eq:ex:harmonic_series/harmonic}. Note that, by \fullref{thm:leibniz_alternating_series_test}, the series is convergent. It is not absolutely convergent, because the harmonic series \eqref{eq:ex:harmonic_series/harmonic} is divergent.
\end{proposition}

\begin{proposition}\label{thm:hyperharmonic_series_convergence}
  The hyperharmonic series \eqref{ex:harmonic_series/hyperharmonic} converges all \( s \in \BbbC \) with \( \real(s) > 1 \).
\end{proposition}
\begin{proof}
  Let \( s = (1 + \varepsilon) + bi \). We use the integral test on the series \( \sum_{k=1}^\infty \abs{k}^{-s} \):
  \begin{equation*}
    \int_1^\infty \frac 1 {\abs{x^s}} \dl x
    =
    \int_1^\infty \frac 1 {x^{1 + \varepsilon} \underbrace{\abs{x^{bi}}}_{1}} \dl x
    =
    -\frac 1 {\varepsilon x^\varepsilon}\Big\restr_{x=1}^\infty
    =
    \frac 1 \varepsilon \lim_{x \to \infty} \parens*{ 1 - \frac 1 {x^\varepsilon} }
    =
    \frac 1 \varepsilon.
  \end{equation*}

  The integral is finite, hence the hyperharmonic series is absolutely convergent.
\end{proof}
