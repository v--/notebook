\subsection{Formal languages}\label{subsec:formal_languages}

\paragraph{Languages}

Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:set_definition_recursion}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.

\begin{definition}\label{def:formal_language}\mcite[3; 4]{Salomaa1987}
  \hfill
  \begin{thmenum}
    \thmitem{def:formal_language/alphabet} Fix a nonempty set \( \mscrA \), which we will call an \term[ru=алфавит (\cite[19]{Гладкий1973Языки})]{alphabet}. Unless explicitly noted otherwise, like in \fullref{subsec:free_groups}, we will assume that \( \mscrA \) is finite.

    \thmitem{def:formal_language/symbol} We call each element of \( \mscrA \) a \term[ru=символ (\cite[19]{Гладкий1973Языки})]{symbol}.

    \thmitem{def:formal_language/word} We call a \hyperref[def:sequence]{finite sequence} of symbols a \term[ru=слово (\cite[19]{Гладкий1973Языки})]{word} or \term[ru=цепочка (\cite[19]{Гладкий1973Языки})]{string}. If \( (a, b, c) \) is a word, for convenience we use the notation \( abc \). This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    \thmitem{def:formal_language/empty_word} We denote the empty word via \( \varepsilon \)\fnote{This notation is used, for example, by \incite[9]{Savage1998}. \incite[3]{Salomaa1987} uses \( \lambda \) instead, while \incite[19]{Гладкий1973Языки} uses \( \Lambda \).}.

    \thmitem{def:formal_language/word_length} We define the \term[ru=длина (\cite[19]{Гладкий1973Языки})]{length} \( \len(w) \) of a word \( w \) as the number of elements of the corresponding tuple.

    \thmitem{def:formal_language/concatenation} We define \term[ru=конкатенация (\cite[19]{Гладкий1973Языки})]{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) as the word
    \begin{equation*}
      v \cdot w \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \smash{\overbrace{w \ldots w}^{k \T*{times}}} \) as \( w^k \).\fnote{This is only a notational shortcut within the metalogic. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).}

    \thmitem{def:formal_language/reverse}\mimprovised We define the \term{reverse word} of \( w = (w_1, \ldots, w_n) \) as
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:formal_language/prefix}\mimprovised We say that word \( p = (p_1, \ldots, p_m) \) is a \term[ru=начало (\cite[20]{Гладкий1973Языки})]{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:formal_language/suffix}\mimprovised We say that the word \( s \) is a \term[ru=конец (\cite[20]{Гладкий1973Языки})]{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:formal_language/subword} We say that the word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = p v s.
    \end{equation*}

    \thmitem{def:formal_language/kleene_star}\mcite[158]{Savage1998} We define the \term{Kleene star}\fnote{The Kleene star is a monoid --- see \fullref{def:free_monoid}.} \( \mscrA^* \) of \( \mscrA \) as the set of all words over \( \mscrA \). If we wish to exclude the empty word, like we often do, we instead write \( \mscrA^+ \) for the set of all non-empty words over \( \mscrA \).

    \thmitem{def:formal_language/language} We call any subset of \( \mscrA^* \) a \term{language} over \( \mscrA \).
  \end{thmenum}
\end{definition}
\begin{comments}
  \item Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic}, the term \enquote{language} may refer to the alphabet itself.
\end{comments}

\begin{example}\label{ex:def:formal_language}
  We list several examples of \hyperref[def:formal_language]{formal languages}:
  \begin{thmenum}
    \thmitem{ex:def:formal_language/full} The simplest examples are the empty language and the Kleene star itself.

    \thmitem{ex:def:formal_language/an} For any alphabet, we can pick one letter \( a \) and form the language
    \begin{equation*}
      \mscrL \coloneqq \set{ a^n \given n \geq 0 }
    \end{equation*}
    consisting of all finite repetitions of the symbol \( a \).

    We can redefine all operations from \fullref{subsec:natural_numbers} to hold for words in \( \mscrL \). For example, addition of \( a^n \) and \( a^m \) is their concatenation \( a^{n + m} \), while the exponentiation \( (a^n)^m \) corresponds to \( m \) repetitions of the word \( a^n \), that is, to \( a^{nm} \).

    We can identify the language with the \hyperref[def:labeled_set]{edge-labeled} \hyperref[def:directed_graph]{directed graph}
    \begin{equation}\label{eq:def:formal_language/an}
      \begin{aligned}
        \includegraphics[page=1]{output/ex__def__formal_language}
      \end{aligned}
    \end{equation}

    Each word in \( \mscrL \) corresponds to a \hyperref[def:graph_walk/directed]{walk} in \eqref{eq:def:formal_language/an} and vice versa.

    \thmitem{ex:def:formal_language/anbn} A slightly more complicated language is
    \begin{equation*}
      \mscrL \coloneqq \set{ a^n b^n \given n \geq 0 }.
    \end{equation*}

    It can encode natural number operations just as well. It cannot, however, be represented via a directed graph like \eqref{eq:def:formal_language/an}. This will be made precise and proved in \fullref{ex:def:finite_automaton/anbn}.

    \thmitem{ex:def:formal_language/even} Even numbers in binary notation are described by the language
    \begin{equation*}
      \mscrL \coloneqq \set[\Big]{ w0 \given w \in \set{ 0, 1 }^* }.
    \end{equation*}

    \thmitem{ex:def:formal_language/leucine}\mcite{codon_charts} The \term{Leucine} amino-acid is encoded by the language
    \begin{equation*}
       \mscrL \coloneqq \set{ \texttt{TTA}, \texttt{TTG}, \texttt{CTT}, \texttt{CTC}, \texttt{CTA}, \texttt{CTG} }.
    \end{equation*}
  \end{thmenum}
\end{example}

\paragraph{Word distance}

\begin{definition}\label{def:hamming_distance}\mcite[993]{Rosen1999}
  The \term{Hamming distance} between two \hyperref[def:formal_language/word]{words} \( a_1 \cdots a_n \) and \( b_1 \cdots b_n \) of the same length is simply the number of indices for which \( a_k \neq b_k \).
\end{definition}

\begin{definition}\label{def:levenshtein_distance}\mcite[4]{Левенштейн1965}
  The \term{Levenshtein distance} from the \hyperref[def:formal_language/word]{word} \( v \) to \( w \) is the minimum number of single-symbol insertions, deletions and substitutions needed to obtain \( w \) from \( v \).

  In this context, following \incite[168]{WagnerFischer1974}, we will refer to these operations as \enquote{edit operations}.
\end{definition}
\begin{comments}
  \item We give here Levenshtein's definition, but we will conflate it with the recursively-defined function from \fullref{thm:levenshtein_distance_characterization}. The latter makes it clear that the distance is well-defined and symmetric.

  \item \incite[2]{Левенштейн1965} also discusses a similar distance function, but without allowing substitutions. We use here the more established version, called \enquote{edit distance} by \incite[168]{WagnerFischer1974}.
\end{comments}

\begin{proposition}\label{thm:levenshtein_distance_characterization}
  The following function describes the \hyperref[def:levenshtein_distance]{Levenshtein distance} between two words:
  \begin{equation}\label{eq:thm:levenshtein_distance_characterization}
    l(v, w) \coloneqq \begin{cases}
      \len(w),                                             &v = \varepsilon, \\
      \len(v),                                             &w = \varepsilon, \\
      l(v', w'),                                           &v = av' \T{and} w = bw' \T{and} a = b, \\
      1 + \min\set[\Big]{ l(v, w'), l(v', w), l(v', w') }, &v = av' \T{and} w = bw' \T{and} a \neq b.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{comments}
  \item In order for this definition to be precise, we must define \( l \) as a function over the Kleene star of some alphabet.
  \item If we wish to disallow substitution, following Levenshtein's original discussion in \cite[2]{Левенштейн1965}, we must replace the last case with
  \begin{equation*}
    \min\set[\Big]{ 1 + l(v, w'), 1 + l(v', w), 2 + l(v', w') }.
  \end{equation*}

  See the proof for the corresponding reasoning.
\end{comments}
\begin{proof}
  We use natural number induction on the minimum of the lengths of \( v \) and \( w \):
  \begin{itemize}
    \item If \( v = \varepsilon \), then \( w \) can be obtained from \( v \) only by appending every symbol of \( w \), hence the Levenshtein distance is the length of \( w \).

    \item If \( w = \varepsilon \), then \( w \) can be obtained from \( v \) only by removing every symbol of \( v \), hence the Levenshtein distance is the length of \( v \).

    \item If \( v = av' \) and \( w = bw' \) and \( a = b \), then the Levenshtein distance from \( v \) to \( w \) is the distance of \( v' \) to \( w' \). Assuming the inductive hypothesis holds for \( \min\set{ \len(v'), \len(w') } \), we conclude that \( l(v', w') \) is the corresponding Levenshtein distance.

    \item If again \( v = av' \) and \( w = bw' \) but \( a \neq b \), assuming the inductive hypothesis holds for pairs whose minimum length is less than that of \( v \) and \( w \), we have several possibilities:
    \begin{itemize}
      \item We can delete the first symbol of \( w \) and then obtain \( w' \) from \( v \). The inductive hypothesis holds for \( v \) and \( w' \), hence this requires \( 1 + l(v, w') \) operations.

      \item We can delete the first symbol from \( v \) and then obtain \( w \) from \( v' \). This requires \( 1 + l(v', w) \) operations.

      \item We can substitute the first symbol of \( v \) with that of \( w \) and then obtain \( w' \) from \( v' \). This requires \( 1 + l(v', w') \) operations.

      \item If we wish to avoid substitution and only work with addition and deletion, the last case would require \( 2 + \len(v', w') \) operations because we must first remove the initial symbol from \( w \) and add \( a \) instead.
    \end{itemize}
  \end{itemize}

  Summarizing the above, we obtain the piecewise recursive definition \eqref{eq:thm:levenshtein_distance_characterization}.
\end{proof}

\begin{proposition}\label{thm:levenshtein_distance_metric}
  As an operator on the Kleene star of some alphabet, the \hyperref[def:levenshtein_distance]{Levenshtein distance} is a \hyperref[def:metric_space]{metric}.
\end{proposition}
\begin{proof}
  \SubProofOf{def:metric_space/M1} No edit operations are needed if and only if the two strings match, that is, \( l(v, w) = 0 \) if and only if \( v = w \).

  \SubProofOf{def:metric_space/M2} It is clear from \eqref{eq:thm:levenshtein_distance_characterization} that Levenshtein distance is symmetric.

  \SubProofOf{def:metric_space/M3} For any three words \( u \), \( v \) and \( w \), the minimum number of edit operations needed to convert \( u \) to \( w \) is bounded by the number of operations needed for \( u \) to \( v \) and then \( v \) to \( w \).
\end{proof}

\begin{example}\label{ex:def:levenshtein_distance}
  We list examples of \hyperref[def:levenshtein_distance]{Levenshtein distances}:
  \begin{thmenum}
    \thmitem{ex:def:levenshtein_distance/shift} We only need two edit operations to convert \( a b^n c \) to \( b^n c a \) --- one for deleting \( a \) from the start and another for inserting it at the end. The Levenshtein distance is thus \( 2 \) for any nonnegative integer \( n \).

    The \hyperref[def:hamming_distance]{Hamming distance} is \( 2 \) if \( n = 0 \) and otherwise it is
    \begin{equation*}
      l(a b^n c, b^n c a) = l(a b^{n-1} b c, b b^{n-1} c a) = 3.
    \end{equation*}

    \thmitem{ex:def:levenshtein_distance/spelling} A useful application of the Levenshtein metric is to perform \enquote{fuzzy search}, that is, to find the closest matching word from a list.

    For example, a spelling correction program that works on the dictionary
    \begin{equation*}
      \set{ \texttt{junction}, \texttt{conjunction}, \texttt{disjunction} }
    \end{equation*}
    will be able to correct the word \( \texttt{conunction} \) to \( \texttt{conjunction} \) because
    \begin{equation*}
      l(\texttt{conunction}, \texttt{con}\oline{\texttt{j}}\texttt{unction}) = 1,
    \end{equation*}
    while
    \begin{equation*}
      l(\hi{\texttt{con}}\texttt{unction}, \oline{\texttt{j}}\texttt{unction}) = 1 + l(\hi{\texttt{co}}\oline{\texttt{j}}\texttt{unction}, \oline{\texttt{j}}\texttt{unction}) = 3
    \end{equation*}
    and
    \begin{equation*}
      l(\hi{\texttt{con}}\texttt{unction}, \hi{\texttt{dis}}\oline{\texttt{j}}\texttt{unction}) = 1 + l(\hi{\texttt{con}}\oline{\texttt{j}}\texttt{unction}, \hi{\texttt{dis}}\oline{\texttt{j}}\texttt{unction}) = 4.
    \end{equation*}

    On the other hand, \( \texttt{subjunction} \) is at a distance of \( 3 \) from all three words.
  \end{thmenum}
\end{example}

\begin{algorithm}[Wagner-Fisher algorithm for Levenshtein distance]\label{alg:wagner_fisher}\mcite[171; 172]{WagnerFischer1974}
  Fix two words
  \begin{align*}
    v = a_1 \cdots a_n && w = b_1 \cdots b_m.
  \end{align*}

  The \hyperref[def:levenshtein_distance]{Levenshtein distance} from the prefix \( a_1 \cdots a_j \) to the prefix \( b_1 \cdots b_i \) can be computed recursively as follows:
  \begin{equation*}
    d_{i,j} = \begin{cases}
      j,                                                         &i = 0, \\
      i,                                                         &j = 0, \\
      \min\set{ 1 + d_{i-1,j}, 1 + d_{i,j-1}, 0 + d_{i-1,j-1} }, &i > 0 \T{and} j > 0 \T{and} a_i = b_i, \\
      \min\set{ 1 + d_{i-1,j}, 1 + d_{i,j-1}, 1 + d_{i-1,j-1} }, &i > 0 \T{and} j > 0 \T{and} a_i \neq b_i.
    \end{cases}
  \end{equation*}

  The algorithm itself consists of arranging these values into a \( (m + 1) \times (n + 1) \) matrix.
\end{algorithm}
\begin{comments}
  \item Unlike in \fullref{subsec:matrices_over_rings}, both the row and the column index here must start at zero.
  \item This algorithm can be found as \texttt{lang.distance.wagner\_fisher} in \cite{code}.
\end{comments}

\paragraph{Formal grammars}

\begin{definition}\label{def:formal_grammar}\mcite[def. 4.9.1]{Savage1998}
  Let \( \Sigma \) and \( V \) be disjoint nonempty subsets of some \hyperref[def:formal_language]{alphabet}, whose members we call \term[ru=основные (символы) (\cite[27]{Гладкий1973Языки})]{terminals} and \term[ru=вспомогательные (символы) (\cite[27]{Гладкий1973Языки})]{nonterminals}, respectively. Fix some \term{starting nonterminal} \( S \in V \).

  Let \( \to \) be some \hyperref[def:binary_relation]{binary relation} over \( (V \cup \Sigma)^* \), whose members we call \term[ru=правила (\cite[27]{Гладкий1973Языки})]{production rules}. We impose the restriction that, for every rule \( v \to w \), the word \( v \) contains at least one nonterminal.

  We call the quadruple \( (V, \Sigma, \to, S) \) a \term[ru=(формальная) генеративная грамматика (\cite[10]{Гладкий1973Языки})]{formal generative grammar}.

  \begin{thmenum}
    \thmitem{def:formal_grammar/derivation} We define the binary relation \( \Rightarrow \) on the Kleene star \( (V \cup \Sigma)^* \) by declaring that, for every two \hyperref[def:formal_language/word]{words} \( p \) and \( s \) over \( V \cup \Sigma \) and every production rule \( v \to w \), we have \( pvs \Rightarrow pws \). We call this an \term[ru=непосредственный (вывод) (\cite[28]{Гладкий1973Языки})]{immediate derivation}.

    A \term[ru=вывод (\cite[27]{Гладкий1973Языки})]{derivation} of length \( m \) of the word \( w_m \) from \( w_0 \) is a finite sequence of words such that
    \begin{equation}\label{eq:def:formal_grammar/derivation}
      w_0
      \Rightarrow
      w_1
      \Rightarrow
      \cdots
      \Rightarrow
      w_{n-1}
      \Rightarrow
      w_m.
    \end{equation}

    We say that \( w_m \) is (immediately) \term[ru=выводимая (цепочка) (\cite[27]{Гладкий1973Языки})]{derivable} from \( w_0 \) if there exists a corresponding derivation

    We denote the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \Rightarrow \) by \( \reloset + \Rightarrow \) and the \hyperref[def:relation_closures/reflexive]{reflexive} closure of \( \reloset + \Rightarrow \) by \( \reloset {*} \Rightarrow \). Clearly \( w_1 \) is derivable from \( w_n \) if and only if \( w_1 \reloset {*} \Rightarrow w_m \).

    \thmitem{def:formal_grammar/language} We associate the following language with the grammar \( G \):
    \begin{equation*}
      \mscrL(G) \coloneqq \set{ w \in \Sigma^* \given S \reloset + \Rightarrow w }.
    \end{equation*}

    It consists of all words that are derivable from \( S \) and contain only terminals.

    We say that words in \( \mscrL(G) \) are \term{generated} by \( G \).

    \thmitem{def:formal_grammar/equivalent} We say that two grammars are \term{equivalent} if they generate the same language.

    \thmitem{def:formal_grammar/graph}\mimprovised We can regard the derivation relation \( \Rightarrow \) as a set of \hyperref[def:directed_graph/arcs]{arcs} over the grammar language \( \mscrL(G) \). Thus, \( (\mscrL(G), \Rightarrow) \) is a \hyperref[def:directed_graph]{directed graph}\fnote{It is possible for multiple rules to produce the same immediate derivation, however \( \Rightarrow \) is only concerted that at least one exists.}, whose nonempty walks are precisely the derivations in \( G \). Furthermore, we can \hyperref[def:labeled_set]{label} each arc with the rule applied.

    We call it the \term{derivation graph} of \( G \).

    \thmitem{def:formal_grammar/schema}\mcite[27]{Гладкий1973Языки} There are different grammars sharing the same alphabet and rules, but having different starting nonterminals. We will call the set of rules a \term[ru=схема]{grammar schema}.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:derivation_graph_connected}
  Every \hyperref[def:formal_grammar/graph]{derivation graph} is \hyperref[def:graph_connectedness/weak]{weakly connected}.
\end{proposition}
\begin{proof}
  A \hyperref[def:formal_grammar/language]{grammar's language} is defined as the set of all words that can be derived from the starting nonterminal.
\end{proof}

\begin{example}\label{ex:natural_number_arithmetic_grammar/schema}
  We define a \hyperref[def:formal_grammar/schema]{grammar schema} for arithmetic of \hyperref[def:natural_numbers]{natural numbers}. We will use binary notation for simplicity.

  Let \( V \coloneqq \set{ N, O, E } \) and \( \Sigma \coloneqq \set{ 0, 1, +, \times, (, ) } \). Consider the derivation rules
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/schema/simple}
    \begin{aligned}
      N &\to 0   & \quad B &\to 0   & \quad O &\to +      & \quad E &\to N \\
      N &\to 1   & \quad B &\to 0 B & \quad O &\to -      & \quad E &\to (E O E) \\
      N &\to 1 B & \quad B &\to 1   & \quad   &           &         & \\
        &        & \quad B &\to 1 B & \quad   &           &         & \\
    \end{aligned}
  \end{equation}

  It is convenient to use the following shorthands:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/schema/shorthand}
    \begin{aligned}
      N &\to 0 \mid 1 \mid 1 B \\
      B &\to 0 \mid B 0 \mid 1 \mid B 1 \\
      O &\to + \mid \times \\
      E &\to N \mid (E O E)
    \end{aligned}
  \end{equation}

  Choosing a different starting nonterminal generates different languages. The symbol \( N \) corresponds to numbers, \( O \) corresponds to operations, and \( E \) can be either a number or a binary expression.

  \begin{figure}[!ht]
    \centering
    \includegraphics[page=1]{output/ex__natural_number_arithmetic_grammar__rules}
    \caption{A fragment of the \hyperref[def:formal_grammar/graph]{derivation graph} of the binary natural number arithmetic grammar from \fullref{ex:natural_number_arithmetic_grammar/schema}.}
    \label{fig:ex:natural_number_arithmetic_grammar/schema}
  \end{figure}
\end{example}

\paragraph{Length-increasing grammars}

\begin{remark}\label{rem:length_increasing_grammar}
  Given a finite set of grammar rules, there may be \hyperref[def:formal_grammar/derivation]{derivations} of arbitrary length. This can happen even if we remove cycles from the \hyperref[def:formal_grammar/graph]{derivation graph} --- see \fullref{ex:unboudned_grammar_derivation_length}. We will discuss a way to restrict this behavior and ensure that it is possible to determine whether a derivation exists in finitely many steps.

  In general, given the grammar rule \( v \to w \), it is possible that \( \len(v) \geq \len(w) \). This is always true for \hyperref[def:epsilon_free_grammar]{\( \varepsilon \) rules}, for example.

  Noam Chomsky in \cite[361]{MathPsychology1963Vol2} defines \enquote{type 1} grammars as those satisfying the inequality \( \len(v) \leq \len(w) \) for every rule \( v \to w \). These grammars still have cycles like \( A \to B \to A \), but they avoid more convoluted cases and lead to \Fullref{alg:length_increasing_grammar}.

  This restriction excludes the empty string from the grammar's language. \incite[15]{Salomaa1987} additionally allows the rule \( S \to \varepsilon \), but only if \( S \) does not occur on the right side of any derivation. \Fullref{ex:unboudned_grammar_derivation_length} highlights the importance of the latter assumption.

  Salomaa calls these grammars \enquote{length-increasing}, preferring to use \enquote{type 1} for what we call \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammars. The latter are, up to nuances of \( \varepsilon \) rules, called \enquote{type 1} grammars by Chomsky earlier in \cite[142]{Chomsky1959}. John Savage in \cite[def. 4.9.2]{Savage1998} defines \enquote{context-sensitive grammars} as what Salomaa calls length-increasing. We introduce the term \enquote{essentially length-increasing} in \fullref{def:length_increasing_grammar} and generally avoid \enquote{type 1} when referring to grammars or languages to circumvent ambiguity.

  (What we call) context-sensitive \hi{grammars} is a strict subset of the essentially length-increasing grammars, but \fullref{thm:context_sensitive_languages} shows that context-sensitive \hi{languages} and length-increasing languages coincide. Hence, the term \enquote{type 1 language} makes sense, although we prefer \enquote{context-sensitive language}.
\end{remark}

\begin{definition}\label{def:epsilon_free_grammar}\mcite[54]{Salomaa1987}
  Fix a formal grammar \( G = (V, \Sigma, \to, S) \). Rules of the form \( A \to \varepsilon \), where \( A \) is a nonterminal, play a special role. We call them \term{\( \varepsilon \) rules}.

  We say that \( G \) is \term{\( \mathbf{\varepsilon} \)-free} if there are no \( \varepsilon \) rules.

  This condition sometimes turns out to be too restrictive because it disallows the grammar to generate empty words. Thus, we introduce another concept. We say that \( G \) is \term{essentially \( \mathbf{\varepsilon} \)-free} if \( S \to \varepsilon \) is the only \( \varepsilon \) rule allowed, and if it is present, \( S \) must not be on the right side of any rule.
\end{definition}
\begin{comments}
  \item This definition for essentially \( \varepsilon \)-free grammars is our own generalization of the concept of essentially length-increasing grammars defined in \fullref{def:length_increasing_grammar}.
\end{comments}

\begin{definition}\label{def:length_increasing_grammar}\mcite[15]{Salomaa1987}
  We say that the grammar \( G = (V, \Sigma, \to, S) \) is \term[ru=неукорачивающая (граматика) (\cite[83]{Гладкий1973Языки})]{length-increasing} if \( \len(v) \leq \len(w) \) for every rule \( v \to w \) and \term{essentially length-increasing} if it is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and if \( \len(v) \leq \len(w) \) for any non-\( \varepsilon \) rule.
\end{definition}

\begin{lemma}\label{thm:length_increasing_grammar}
  Fix an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar \( G = (V, \Sigma, \to, S) \). Let \( m \) be the cardinality of \( \Sigma \cup V \).

  If the word \( w \) over \( \Sigma \) of length \( n \) is derivable, there exists a derivation of length at most
  \begin{equation*}
    \sum_{k=0}^n m^k.
  \end{equation*}
\end{lemma}
\begin{comments}
  \item If \( m > 1 \), we have
  \begin{equation*}
    \sum_{k=0}^n m^k
    \reloset {\ref{thm:geometric_series_properties/finite_sum}} =
    \frac {1 - m^{n+1}} {1 - m}.
  \end{equation*}

  \item Chomsky introduced length-increasing grammars in \cite[360]{MathPsychology1963Vol2} and on the same page hinted at this property of theirs, which we will use in \fullref{alg:length_increasing_grammar}.
\end{comments}
\begin{proof}
  Suppose that the word \( w \) of length \( n \) is derivable in \( G \) and consider the derivation
  \begin{equation*}
    S = w_0 \Rightarrow w_1 \Rightarrow \cdots \Rightarrow w_r = w.
  \end{equation*}

  The case where \( w \) is empty should be handled separately. Since \( G \) is essentially \( \varepsilon \)-free, the only possible derivation of \( \varepsilon \) follows the rule \( S \to \varepsilon \) and thus has length
  \begin{equation*}
    1 = m^0 = \sum_{k=0}^0 m^k.
  \end{equation*}

  Now suppose that \( n > 0 \). Let \( i_0 \coloneqq 0 \) and, for every \( s = 1, \ldots, n \), let \( i_s \) be the index of the last word of length \( s \) in the derivation (if no word of length \( s \) exists, let \( i_s \) match \( i_{s-1} \)). Note that there are exactly \( m^s \) possible words of length \( s \), and thus there must exist a derivation of \( w_{i_s} \) from \( w_{i_{s-1} + 1} \) in at most \( m^s - 1 \) steps. Any derivation longer than that necessarily follows a \hyperref[def:graph_cycle]{cycle} in the \hyperref[def:formal_grammar/graph]{derivation graph}.

  Therefore, \( w_{i_s} \) can be derived from \( w_{i_0} = S \) in at most
  \begin{equation*}
    \sum_{k=0}^s (m^k - 1) \leq \sum_{k=0}^s m^k
  \end{equation*}
  steps.
\end{proof}

\begin{example}\label{ex:unboudned_grammar_derivation_length}
  Consider the grammar
  \begin{equation}\label{eq:ex:unboudned_grammar_derivation_length/bad}
    \begin{aligned}
      S &\to \varepsilon \\
      S &\to a, \\
      S &\to SS.
    \end{aligned}
  \end{equation}

  It is not \hyperref[def:epsilon_free_grammar]{essentially epsilon-free}, hence also not \hyperref[def:length_increasing_grammar]{essentially length-increasing}, and thus \fullref{thm:length_increasing_grammar} does not apply. The lemma would imply that the acyclic derivation length should be bounded by \( 2 \), while there exist countably many acyclic derivations of the word \( a \):
  \begin{equation*}
    \begin{aligned}
      S &\Rightarrow a \\
      S &\Rightarrow SS \Rightarrow Sa \Rightarrow a \\
      S &\Rightarrow SS \Rightarrow SSS \Rightarrow SSa \Rightarrow Sa \Rightarrow a \\
        &\vdots
    \end{aligned}
  \end{equation*}

  This is problematic for parsing algorithms because we cannot check in finitely many steps whether a grammar generates a word. \Fullref{alg:epsilon_rule_removal} suggests instead the essentially length-increasing grammar
  \begin{equation*}
    \begin{aligned}
      S &\to \varepsilon \\\
      S &\to A, \\
      A &\to a, \\
      A &\to AA,
    \end{aligned}
  \end{equation*}
  which disallows the aforementioned derivations.
\end{example}

\begin{algorithm}[Word membership in context-sensitive languages]\label{alg:length_increasing_grammar}
  Let \( G = (V, \Sigma, \to, S) \) be an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar for \( \mscrL \). Denote by \( m \) the cardinality of \( V \cup \Sigma \). Fix some upper bound \( n \) on lengths of words. We can construct a set \( L_n \) that contains all words in \( \mscrL(G) \) of length at most \( n \) (it may also contain longer words).

  \begin{thmenum}
    \thmitem{alg:length_increasing_grammar/start} Start with a set \( W_0 \coloneqq \set{ S } \) of words derivable in zero steps.

    \thmitem{alg:length_increasing_grammar/step} Given \( W_k \), define the set of words derivable in \( k + 1 \) steps:
    \begin{equation*}
      W_{k+1} \coloneqq \set{ p v s \given p u s \in W_k \T{and} u \to v }.
    \end{equation*}

    \thmitem{alg:length_increasing_grammar/union} \Fullref{thm:length_increasing_grammar} gives us an upper bound on the derivation length of words of length \( n \). Denote this bound by \( u \). We can thus take the union of all words derivable in at most \( u \) steps and ignore those that contain nonterminals:
    \begin{equation*}
      L_n \coloneqq \bigcup_{k=1}^u \set{ w \in W_k \given w \T{has only terminals} }.
    \end{equation*}

    \thmitem{alg:length_increasing_grammar/membership} If we are interested in whether a particular word \( w \) of length at most \( n \) is in \( \mscrL(G) \), we can simply check if it is in \( L_n \), or, even better, at every step of the algorithm check if it is in \( W_k \).
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be used to test whether a word belongs to a \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive language}, hence the name.

  \item Compare this to the more complicated \fullref{alg:brute_force_parsing} that is intended for more restricted cases, but also handles \( \varepsilon \) rules.
\end{comments}

\paragraph{Hierarchy of grammars}

\begin{definition}\label{def:chomsky_hierarchy}\mcite[15]{Salomaa1987}
  We can classify \hyperref[def:formal_grammar]{formal grammars} and \hyperref[def:formal_language]{languages} to form the \term{Chomsky hierarchy}. Chomsky himself in \cite[def. 6]{Chomsky1959} defined a hierarchy of grammars consisting of four types --- \enquote{type 0} through \enquote{type 3}. He also defined a parallel hierarchy of languages, in which \( \mscrL \) is a \enquote{type \( i \) language} if there exists a type \( i \) grammar \hyperref[def:formal_grammar/language]{generating it}.

  Unfortunately, these definitions later evolved to be inconsistent across authors, and even among different publications by Chomsky. We thus entirely avoid numeric grammar and language types, and use more descriptive names instead. The grammars no longer form a hierarchy, but the corresponding languages do.

  \begin{thmenum}
    \thmitem{def:chomsky_hierarchy/unrestricted} When no additional restrictions are imposed on the rules of the grammar, we call it \term{unrestricted}. We call the corresponding languages \term{recursively enumerable} following \cite[thm 5.4.1; thm 5.4.2]{Savage1998}.

    \thmitem{def:chomsky_hierarchy/context_sensitive} We say that the grammar is \term[ru=грамматика составляющих (\cite[29]{Гладкий1973Языки})]{context-sensitive} if it is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and if every non-\( \varepsilon \) rule has the form
    \begin{equation*}
      p A s \to p w s
    \end{equation*}
    for a nonterminal \( A \), arbitrary words \( p \) and \( s \) and a nonempty\footnote{Since \( w \) is nonempty, a context-sensitive grammar is \hyperref[def:length_increasing_grammar]{essentially length-increasing}.} word \( w \). Of course, there may be multiple such representations for a single rule.

    We call the corresponding languages \term{context-sensitive}. The kerfuffle surrounding the term \enquote{context-sensitive} is discussed in \fullref{rem:length_increasing_grammar}. \Fullref{thm:context_sensitive_languages} better characterizes these languages.

    \thmitem{def:chomsky_hierarchy/context_free} We say that the grammar is \term[ru=безконтекстная / контекстно-свободная (грамматика) (\cite[29]{Гладкий1973Языки})]{context-free} if every rule has the form
    \begin{equation*}
      A \to w,
    \end{equation*}
    where \( A \) is a nonterminal and \( w \) is an arbitrary word.

    We call the corresponding languages \term{context-free}. While it is possible for a context-free \hi{grammar} to not be \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and hence not context-sensitive, a context-free \hi{language} is context-sensitive. This is shown in \fullref{thm:context_free_languages_are_context_sensitive} and discussed in \fullref{rem:chomsky_hierarchy_failure}.

    \thmitem{def:chomsky_hierarchy/regular}\mcite[44]{Salomaa1987} Finally, we call the grammar \term{left linear} if every rule has one of the forms
    \begin{itemize}
      \item \( A \to w \),
      \item \( A \to B w \),
    \end{itemize}
    where \( w \) is an arbitrary word consisting entirely of terminals. Similarly, it is \term{right linear} if every rule has one of the forms
    \begin{itemize}
      \item \( A \to w \),
      \item \( A \to w B \).
    \end{itemize}

    We refer to the two types of grammars collectively as \term[ru=автоматная (грамматика) (\cite[29]{Гладкий1973Языки})]{regular grammars}.

    We call the language \term{regular} if it can be generated by a regular grammar. \Fullref{thm:regular_languages} better characterizes these languages.
  \end{thmenum}
\end{definition}
\begin{comments}
  \item In \cite[142]{Chomsky1959}, Chomsky calls context-free languages \enquote{type 2} and regular languages \enquote{type 3}, while in \cite[366]{MathPsychology1963Vol2} he calls context-free languages \enquote{type 4} and gives no number for regular languages.
\end{comments}

\begin{proposition}\label{thm:non_recursively_enumerable_language}\mcite[thm. 5.7.4]{Savage1998}
  There exists a formal language that cannot be generated by a grammar.
\end{proposition}

\begin{example}\label{ex:def:chomsky_hierarchy}
  We give several examples of grammars in the \hyperref[def:chomsky_hierarchy]{Chomsky hierarchy}.

  \begin{thmenum}
    \thmitem{ex:def:chomsky_hierarchy/non_enumerable} While every grammar is an unrestricted grammar, \fullref{thm:non_recursively_enumerable_language} shows that not every language is recursively enumerable.

    \thmitem{ex:def:chomsky_hierarchy/an} The \hyperref[def:chomsky_hierarchy/regular]{right linear grammar}
    \begin{equation*}
      \begin{aligned}
        S &\to aS \mid \varepsilon
      \end{aligned}
    \end{equation*}
    describes the language \( \mscrL = \set{ a^n \given n \geq 0 } \) discussed in \fullref{ex:def:formal_language/an}.

    It can also be described via the left linear grammar
    \begin{equation*}
      \begin{aligned}
        S &\to Sa \mid \varepsilon.
      \end{aligned}
    \end{equation*}

    Neither of these grammars is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free}. \Fullref{ex:alg:epsilon_rule_removal/an} proposes using \Fullref{alg:epsilon_rule_removal} to obtain the essentially length-increasing grammar
    \begin{equation*}
      \begin{aligned}
        S &\to A \mid \varepsilon, \\
        A &\to aA \mid a.
      \end{aligned}
    \end{equation*}

    \thmitem{ex:def:chomsky_hierarchy/anbn} Consider the \hyperref[def:chomsky_hierarchy/context_free]{context-free grammar}
    \begin{equation*}
      \begin{aligned}
        S &\to A \mid \varepsilon, \\
        A &\to aAb \mid ab
      \end{aligned}
    \end{equation*}
    describing \( \mscrL = \set{ a^n b^n \given n \geq 0 } \) from \fullref{ex:def:formal_language/anbn}.

    We have shown in \fullref{ex:def:finite_automaton/anbn} that this language cannot be recognized by a finite automaton. In \fullref{subsec:regular_languages} we will prove \fullref{thm:regular_languages}, which suggests that \( \mscrL \) is not \hyperref[def:chomsky_hierarchy/regular]{regular}.

    Hence, \( \mscrL \) is a context-free language that is not regular.

    \thmitem{ex:def:chomsky_hierarchy/length_increasing_not_context_sensitive} In a \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive grammar}, the only possible production rules replace a nonterminal with some nonempty word. In general, it is possible to replace terminal symbols with arbitrary words. For example, consider the grammar
    \begin{equation*}
      \begin{aligned}
         S &\to aA, \\
        aA &\to BB \\
         B &\to b \\
      \end{aligned}
    \end{equation*}

    The language generated by this grammar is \( \mscrL = \set{ bb } \). The entirety of \( aA \) gets replaced by a new word not starting with \( a \), while in a context-sensitive grammar the second rule would need to include the terminal \( a \) as the first symbol --- only the nonterminal \( A \) would get replaced, and only when it is preceded by \( a \). Of course, the grammar can be vastly simplified:
    \begin{equation*}
      S \to bb.
    \end{equation*}

    It is reasonable to expect that grammars are context-sensitive, i.e. that terminals should never get replaced. Unfortunately, as we just saw, this is not so general \hyperref[def:length_increasing_grammar]{length-increasing} grammars. \Fullref{alg:length_increasing_to_context_sensitive} however allows us to convert general (essentially) length-increasing grammars to equivalent context-sensitive grammars.
  \end{thmenum}
\end{example}

\paragraph{Context-sensitive languages}

\begin{algorithm}[Length-increasing to context-sensitive grammar]\label{alg:length_increasing_to_context_sensitive}\mcite[thm. 9.2]{Salomaa1987}
  Fix an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} (essentially length-increasing) \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammar \( G' = (V', \Sigma, \to', S) \) with the same terminals.

  Enumerate all non-\( \varepsilon \) rules of \( \to \) from \( 1 \) to \( n \).

  \begin{thmenum}
    \thmitem{alg:length_increasing_to_context_sensitive/init} For every terminal \( a \) in \( \Sigma \), let \( a' \) be a new nonterminal not in \( V \). Let
    \begin{equation*}
      V_0 \coloneqq V \cup \set{ a' \given a \in \Sigma }.
    \end{equation*}

    For every nonterminal \( A \) in \( V_0 \), let \( A' \) refer to \( A \) itself.

    Let \( {\to_0} \) consist only of the rules \( a' \mapsto a \) for every terminal \( a \) in \( \Sigma \).

    \thmitem{alg:length_increasing_to_contexs_sensitive/step} At step \( k \), we consider the rule
    \begin{equation*}
      r_1 \cdots r_{m_k} \to s_1 \cdots s_{l_k},
    \end{equation*}
    where \( r_1 \cdots r_{m_k} \) and \( s_1 \cdots s_{l_k} \) are either terminal or nonterminal symbols.

    Let \( C_1, \ldots, C_{m_k} \) be new nonterminal symbols, and let
    \begin{equation*}
      V_k \coloneqq V_{k-1} \cup \set{ C_1, \ldots, C_{m_k} }.
    \end{equation*}

    Define \( \to'_k \) as \( \to'_{k-1} \) with the following additional rules:
    \begin{align*}
      r_1' r_2' \cdots r_{m_k}'                                      &\to'_k C_1 r_2' \cdots r_{m_k}', \\
      C_1 r_2' \cdots r_{m_k}'                                       &\to'_k C_1 C_2 \cdots r_{m_k}', \\
                                                                     &\vdots, \\
      C_1 C_2 \cdots C_{m_k-1} r_{m_k}'                              &\to'_k C_1 C_2 \cdots C_{m_k-1} C_{m_k} s_{m_k+1}' \cdots s_{l_k}', \\
      C_1 C_2 \cdots C_{m_k-1} C_{m_k} s_{m_k+1}' \cdots s_{l_k}'    &\to'_k s_1' C_2 \cdots C_{m_k-1} C_{m_k} s_{m_k+1}' \cdots s_{l_k}', \\
                                                                     &\vdots, \\
      s_1' s_2' \cdots s_{m_k-1}' C_{m_k} s_{m_k+1}' \cdots s_{l_k}' &\to'_k s_1' s_2' \cdots s_{m_k-1}' B_{m_k} s_{m_k+1}' \cdots s_{l_k}'.
    \end{align*}

    Each of these rules replaces exactly one nonterminal with a nonempty word.

    \thmitem{alg:length_increasing_to_context_sensitive/finish} Finally, let \( V' \coloneqq V'_n \) and \( {\to'} \coloneqq {\to'_n} \). In the case where \( S \to \varepsilon \), let \( S \to' \varepsilon \). Then \( G' = (V', \Sigma, \to', S) \) is the desired grammar.
  \end{thmenum}
\end{algorithm}

\begin{proposition}\label{thm:context_sensitive_languages}
  The class of languages generated by \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive grammars} and by \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammars coincide.
\end{proposition}
\begin{comments}
  \item As discussed in \fullref{rem:length_increasing_grammar} and \fullref{def:chomsky_hierarchy/context_sensitive}, we call this class of languages \enquote{context-sensitive languages}.
\end{comments}
\begin{proof}
  Every context-sensitive grammar is, by definition, essentially length-increasing. \Fullref{alg:length_increasing_to_context_sensitive} shows that every essentially length-increasing grammar has an equivalent context-sensitive grammar.
\end{proof}

\begin{remark}\label{rem:chomsky_hierarchy_failure}
  Every \hyperref[def:chomsky_hierarchy/regular]{regular grammar} is \hyperref[def:chomsky_hierarchy/context_free]{context-free}, but not every context-free grammar is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive}. Chomsky disallowed \( \varepsilon \) rules in \cite[def. 6]{Chomsky1959}, and this led to a tidy hierarchy because it made context-free grammars necessarily context-sensitive.

  Fortunately, context-free \hi{languages} are context-sensitive as a consequence of \fullref{thm:context_free_languages_are_context_sensitive}.

  Unfortunately, for an arbitrary context-free grammar, \fullref{thm:length_increasing_grammar} does not hold, and neither does \fullref{alg:length_increasing_grammar}. This is not a problem because:
  \begin{itemize}
    \item For theoretical purposes, we can use \fullref{alg:epsilon_rule_removal} to adapt context-free languages to \fullref{alg:length_increasing_grammar}.

    \item For practical purposes, parsing context-free languages is a topic in itself. These algorithms are mostly restricted to certain classes of context-free grammars; see e.g. \cite[ch. 6]{Salomaa1987}. General algorithms for parsing all context-free grammars are scarcer; several are discussed in \cite{Economopoulos2006}. We present \fullref{alg:brute_force_parsing}, which handles arbitrary context-free grammars, but is too inefficient to use in practice.
  \end{itemize}
\end{remark}

\paragraph{Context-free languages}

\begin{algorithm}[Epsilon rule removal]\label{alg:epsilon_rule_removal}\mcite[thm. 6.2]{Salomaa1987}
  Fix a \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} context-free grammar \( G' = (V', \Sigma, \to', S') \) with the same terminals, such that \( G' \) is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free}, and thus context-sensitive.

  \begin{thmenum}
    \thmitem{alg:epsilon_rule_removal/init} We will recursively construct a set \( U \) so that \( A \reloset {*} \Rightarrow \varepsilon \) if and only if \( A \in U \).

    First, define
    \begin{equation*}
      U_k \coloneqq \begin{cases}
        \set[\Big]{ A \in V \given A \to \varepsilon },                               &k = 0, \\
        U_{k-1} \cup \set[\Big]{ A \in V \given \qexists*{w \in U_{k-1}^*} A \to w }, &k > 0.
      \end{cases}
    \end{equation*}

    At each step, we \( U_k \) is a subset of \( V \). Since \( V \) has only finitely many nonterminals, the sequence \hyperref[def:stabilizing_sequence]{stabilizes} --- there exists some index \( m \) such that \( U_m = U_k \) for any \( k > m \). Denote \( U_m \) via \( U \).

    Then \( A \reloset {*} \Rightarrow \varepsilon \) if and only if \( A \in U \).

    \thmitem{alg:epsilon_rule_removal/rules} Now our goal is to define the rules of \( G' \) based on the rules of \( G \), but with zero or more \enquote{nullable} nonterminals removed from the right side of any rule.

    Let \( S' \) be an entirely new start symbol and let \( V' \coloneqq V \cup \set{ S' } \). Define the production relation \( A \to' w \) to hold if \( w \) is \hi{nonempty} and if there exist words \( w_0, \ldots, w_n \) over \( V \cup \Sigma \) and nonterminals \( B_1, \ldots, B_n \) from \( U \) such that
    \begin{equation*}
      A \to w_0 B_1 w_1 B_2 w_2 \cdots B_n w_n.
    \end{equation*}
    and
    \begin{equation*}
      w = w_0 w_1 w_2 \cdots w_n.
    \end{equation*}

    \thmitem{alg:epsilon_rule_removal/finish} Define \( S' \to S \). If \( S \reloset {*} \Rightarrow \varepsilon \), also add the rule \( S' \to \varepsilon \). Then \( G' = (V', \Sigma, \to', S') \) is the desired grammar.
  \end{thmenum}
\end{algorithm}

\begin{example}\label{ex:alg:epsilon_rule_removal}
  We list several examples demonstrating the operation of \fullref{alg:epsilon_rule_removal}:
  \begin{thmenum}
    \thmitem{ex:alg:epsilon_rule_removal/an} We discussed the grammar
    \begin{equation*}
      S \to aS \mid \varepsilon
    \end{equation*}
    in \fullref{ex:def:chomsky_hierarchy/an}.

    Using \fullref{alg:epsilon_rule_removal}, we conclude that the only nonterminal \( S \) belongs to \( U_0 \). Thus, \fullref{alg:epsilon_rule_removal/rules} suggests instead the rules
    \begin{equation*}
      S \to' aS \mid a
    \end{equation*}
    and \fullref{alg:epsilon_rule_removal/finish} suggests
    \begin{equation*}
      S' \to' S \mid \varepsilon,
    \end{equation*}
    where \( S' \) is the new starting nonterminal.

    The obtained grammar is essentially \( \varepsilon \)-free.

    \thmitem{ex:alg:epsilon_rule_removal/natural} Given the rules
    \begin{equation*}
      \begin{aligned}
        N &\to 0 \mid 1 B, \\
        B &\to \varepsilon \mid 0 B \mid 1 B
      \end{aligned}
    \end{equation*}
    and starting nonterminal \( N \), the algorithm suggests instead
    \begin{equation*}
      \begin{aligned}
        S' &\to' N, \\
        N  &\to' 0 \mid 1 \mid 1 B, \\
        B  &\to' 0 \mid 0 B \mid 1 \mid 1 B.
      \end{aligned}
    \end{equation*}

    The only member of \( U \) is \( B \), and we add a new rule of every instance of \( B \) where it is removed.

    This motivated our choice for rules in \fullref{ex:natural_number_arithmetic_grammar/schema}. The obtained grammar is \( \varepsilon \)-free, not merely essentially \( \varepsilon \)-free.

    \thmitem{ex:alg:epsilon_rule_removal/dead} It is possible to obtain \enquote{dead} rules via \fullref{alg:epsilon_rule_removal}. For example, for
    \begin{equation*}
      \begin{aligned}
        S &\to A B, \\
        A &\to \varepsilon \mid a, \\
        B &\to \varepsilon
      \end{aligned}
    \end{equation*}
    with starting nonterminal \( S \), the algorithm produces
    \begin{equation*}
      \begin{aligned}
        S' &\to S \mid \varepsilon, \\
        S &\to A B \mid A \mid B, \\
        A &\to a. \\
      \end{aligned}
    \end{equation*}

    The derivations
    \begin{equation*}
      S' \Rightarrow S \Rightarrow B
    \end{equation*}
    and
    \begin{equation*}
      S' \Rightarrow S \Rightarrow A B \Rightarrow a B
    \end{equation*}
    cannot be expanded further in order to reach a word consisting entirely of terminals.

    Thus, the rules \( S \to B \) and \( S \to A B \) are essentially useless, but do no harm unless the number of rules matters as in \fullref{alg:brute_force_parsing}.
  \end{thmenum}
\end{example}

\begin{proposition}\label{thm:context_free_languages_are_context_sensitive}
  \hyperref[def:chomsky_hierarchy/context_free]{Context-free} \hi{languages} are \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive}.
\end{proposition}
\begin{proof}
  \Fullref{alg:epsilon_rule_removal} shows that every context-free grammar can be converted to another context-free grammar that is also context-sensitive.
\end{proof}

\begin{definition}\label{def:renaming_rule}\mimprovised
  A \term{renaming rule} in a formal grammar is a production rule \( A \to B \), where both \( A \) and \( B \) are nonterminals.
\end{definition}

\begin{algorithm}[Renaming rule collapse]\label{alg:renaming_rule_collapse}
  Fix an \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} context-free grammar \( G' = (V, \Sigma, \to', S) \) without \hyperref[def:renaming_rule]{renaming rules}.

  \begin{thmenum}
    \thmitem{alg:renaming_rule_collapse/rules} For every rule \( A \to w \), we define a \hyperref[def:function]{set-valued map} \( C(A \to w, U) \) whose values are words \( v \) over \( V \cup \Sigma \) for which \( A \to v \) is a non-renaming rule. The parameter \( U \) is a set of nonterminals \enquote{already traversed} during recursion, we use it to avoid unbounded recursion like in the case of \( A \to B \to A \). Let
    \begin{equation*}
      C(A \to w, U) \coloneqq \begin{cases}
        \varnothing,                                    &A \in U, \\
        \bigcup_{B \to v} C(B \to v, U \cup \set{ A }), &w = B, \\
        \set{ w },                                      &\T{otherwise.}
      \end{cases}
    \end{equation*}

    \thmitem{alg:renaming_rule_collapse/new_grammar} Let \( A \to' v \) hold if and only if \( v \in C(A \to w, \varnothing) \) for some rule \( A \to w \). The obtained quadruple \( G' = (V', \Sigma, \to', S) \) is the desired grammar without renaming rules.
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \texttt{grammars.renaming\_rules.collapse\_renaming\_rules} in \cite{code}.
  \item Our goal is to \enquote{collapse} derivations like \( A \to B \to C \to w \) into \( A \to' w \).
\end{comments}

\begin{remark}\label{rem:backus_normal_form}\mcite[14]{Backus1958}
  Practice requires introducing a more convenient metasyntax (a syntax for describing language syntax).

  For \hyperref[def:chomsky_hierarchy/context_free]{context-free grammars}, we can use the \term{Backus normal form} (BNF; used by \incite[61]{Salomaa1987}), sometimes also called \term{Backus-Naur form} (also BNF; used by \incite[40]{Aho2006}). Backus himself in \cite[14]{Backus1958} described it via examples.

  For \fullref{ex:natural_number_arithmetic_grammar/schema}, one possible BNF is
  \begin{bnf*}
    \bnfprod{expression}     {\bnfpn{number} \bnfor \bnftsq{(} \bnfsp \bnfpn{number} \bnfsp \bnfpn{operation} \bnfsp \bnfpn{number} \bnfsp \bnftsq{)}} \\
    \bnfprod{operation}      {\bnftsq{\( + \)} \bnfor \bnftsq{\( \times \)}} \\
    \bnfprod{natural number} {\bnftsq{\( 0 \)} \bnfor \bnftsq{\( 1 \)} \bnfor \bnftsq{\( 1 \)} \bnfsp \bnfpn{digit string}} \\
    \bnfprod{digit string}   {\bnftsq{\( 0 \)} \bnfor \bnftsq{\( 0 \)} \bnfsp \bnfpn{digit string} \bnfor \bnftsq{\( 1 \)} \bnfor \bnftsq{\( 1 \)} \bnfsp \bnfpn{digit string}}
  \end{bnf*}

  Compared to \eqref{eq:ex:natural_number_arithmetic_grammar/schema/simple}, some differences are:
  \begin{itemize}
    \item Variables are denoted by \( \langle \)words enclosed in angle brackets\( \rangle \), so that we can name variables more descriptively using more than one symbol.
    \item Terminals are put in \enquote{quotes}.
    \item The symbol \( \Coloneqq \) is used instead of \( \to \) for specifying transition rules.
    \item Different rules with the same source are combined as in \eqref{eq:ex:natural_number_arithmetic_grammar/schema/shorthand}.
    \item In order to fully describe a context-free grammar, we must only specify its Backus-Naur form and its starting variable.
  \end{itemize}
\end{remark}
\begin{comments}
  \item We will use Backus normal forms in more complicated grammars like \fullref{def:propositional_syntax/grammar_schema} and \fullref{def:first_order_syntax/grammar_schema}, while preferring more the primitive notation \eqref{eq:ex:natural_number_arithmetic_grammar/schema/simple} for generic examples relating to grammars.
  \item Note that we have placed the (only) \hyperref[rem:abstract_syntax_tree/syntactic]{syntactic rule} on top.
\end{comments}

\begin{remark}\label{rem:decimal_notation_grammar}
  Our series of examples ending with \fullref{rem:backus_normal_form} describes natural number arithmetic in binary notation. We made the restriction because decimal notation requires more complicated rules. One such set of rules is
  \begin{bnf*}
    \bnfprod{nonzero digit}  {\bnftsq{1} \bnfor \bnftsq{2} \bnfor \cdots \bnfor \bnftsq{9}} \\
    \bnfprod{digit}          {\bnftsq{0} \bnfor \bnfpn{nonzero digit}} \\
    \bnfprod{digit string}   {\bnfpn{digit} \bnfor \bnfpn{digit} \bnfsp \bnfpn{digit string}} \\
    \bnfprod{natural number} {\bnfpn{digit} \bnfor \bnfpn{nonzero digit} \bnfsp \bnfpn{digit string}}
  \end{bnf*}
\end{remark}
