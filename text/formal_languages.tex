\subsection{Formal languages}\label{subsec:formal_languages}

Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:set_definition_recursion}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.

\begin{definition}\label{def:formal_language}\mcite[3]{Salomaa1987}
  Fix a nonempty set \( \mscrA \), which we will call an \term{alphabet}. Unless explicitly noted otherwise, like in \fullref{subsec:free_groups}, we will assume that \( \mscrA \) is finite.

  \begin{thmenum}
    \thmitem{def:formal_language/symbol} We call each element of \( \mscrA \) a \term{symbol}.

    \thmitem{def:formal_language/word} We call a \hyperref[def:sequence]{finite sequence} of symbols a \term{word} or \term{string}. If \( (a, b, c) \) is a word, for convenience we use the notation \( abc \). This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    \thmitem{def:formal_language/empty_word} We denote the empty word via \( \varepsilon \)\footnote{This notation is used, for example, by \cite[9]{Savage1998}. Other authors like Arto Salomaa in \cite[3]{Salomaa1987} use \( \lambda \) instead.}.

    \thmitem{def:formal_language/word_length} We define the \term{length} \( \len(w) \) of a word \( w \) as the number of elements of the corresponding tuple.

    \thmitem{def:formal_language/concatenation} We define \term{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) as the word
    \begin{equation*}
      v \cdot w \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \smash{\overbrace{w \ldots w}^{k \T*{times}}} \) as \( w^k \)\footnote{This is only a notational shortcut within the metalogic. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).}.

    \thmitem{def:formal_language/reverse}\mcite[example 2.7]{Salomaa1987} We define the \term{reverse word} of \( w = (w_1, \ldots, w_n) \) as
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:formal_language/prefix} We say that word \( p = (p_1, \ldots, p_m) \) is a \term{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:formal_language/suffix} We say that the word \( s \) is a \term{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:formal_language/subword} We say that the word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = p v s.
    \end{equation*}

    \thmitem{def:formal_language/kleene_star} We define the \term{Kleene star}\footnote{The Kleene star is also called the free monoid on \( \mscrA \) --- see \fullref{thm:free_monoid_universal_property}.} \( \mscrA^* \) of \( \mscrA \) as the set of all words over \( \mscrA \). If we wish to exclude the empty word, like we often do, we instead write \( \mscrA^+ \) for the set of all non-empty words over \( \mscrA \).

    \thmitem{def:formal_language/language} We call any subset of \( \mscrA^* \) a \term{language} over \( \mscrA \).
  \end{thmenum}
\end{definition}
\begin{comments}
  \item Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic}, the term \enquote{language} may refer to the alphabet itself.
\end{comments}

\begin{example}\label{ex:def:formal_language}
  We list several examples of \hyperref[def:formal_language]{formal languages}:
  \begin{thmenum}
    \thmitem{ex:def:formal_language/full} The simplest examples are the empty language and the Kleene star itself. Both are useless in practice, however.

    \thmitem{ex:def:formal_language/an} For any alphabet, we can pick one letter \( a \) and form the language
    \begin{equation*}
      \mscrL \coloneqq \set{ a^n \given n \geq 0 },
    \end{equation*}
    consisting of all finite repetitions of the symbol \( a \).

    We can redefine all operations from \fullref{subsec:natural_numbers} to hold for words in \( \mscrL \). For example, addition of \( a^n \) and \( a^m \) is their concatenation \( a^{n + m} \), while the exponentiation \( (a^n)^m \) is a repetition of the word \( a^n \).

    We can identify the language with the \hyperref[def:labeled_set]{edge-labeled} \hyperref[def:directed_graph]{directed graph}
    \begin{equation}\label{eq:def:formal_language/an}
      \begin{aligned}
        \includegraphics[page=1]{output/ex__def__formal_language}
      \end{aligned}
    \end{equation}

    Each word in \( \mscrL \) corresponds to a \hyperref[def:graph_walk/directed]{walk} in \eqref{eq:def:formal_language/an} and vice versa.

    \thmitem{ex:def:formal_language/anbn} A slightly more complicated language is
    \begin{equation*}
      \mscrL \coloneqq \set{ a^n b^n \given n \geq 0 }.
    \end{equation*}

    It can encode natural number operations just as well. It cannot, however, be represented via a directed graph like \eqref{eq:def:formal_language/an}. This will be made precise and proved in \fullref{ex:def:finite_automaton/anbn}.

    \thmitem{ex:def:formal_language/even} Even numbers in binary notation are described by the language
    \begin{equation*}
      \mscrL \coloneqq \set[\Big]{ w0 \given w \in \set{ 0, 1 }^* }.
    \end{equation*}

    \thmitem{ex:def:formal_language/leucine}\mcite{codon_charts} The \term{Leucine} amino-acid is encoded by the language
    \begin{equation*}
       \mscrL \coloneqq \set{ \texttt{TTA}, \texttt{TTG}, \texttt{CTT}, \texttt{CTC}, \texttt{CTA}, \texttt{CTG} }.
    \end{equation*}
  \end{thmenum}
\end{example}

\begin{definition}\label{def:finite_automaton}\mcite[def. 4.1.1]{Savage1998}
  Let \( \Sigma \) be some \hyperref[def:formal_language]{alphabet}. Let \( Q \) be a finite nonempty set, whose members we will call \term{states}. Let \( \delta: Q \times \Sigma \to \pow(Q) \) be a \hyperref[def:function]{set-valued map}, which we will call a \term{transition function} because, depending on a state in \( Q \) and a symbol in \( \Sigma \), \( \delta \) gives us the possible states towards we can transition.

  Finally, let \( S \) and \( T \) be nonempty sets of vertices, which we call an \term{initial} and \term{terminal states}, correspondingly.

  We call this entire contraption \( (\Sigma, Q, \delta, I, T) \) a \term{finite automaton}. It models a real-world device that starts its work from some initial state and, via a sequence of state transitions, reaches some terminal state.

  \begin{figure}[!ht]
    \hfill
    \includegraphics[page=1]{output/def__finite_automaton}
    \hfill
    \includegraphics[page=2]{output/def__finite_automaton}
    \hfill\hfill
    \caption{A \hyperref[def:finite_automaton/determinism]{nondeterministic finite automaton} and its \hyperref[alg:determinization_of_finite_automata]{determinization} accepting the language \( \set{ a } \cup \set{ b^n \given n > 0 } \cup \set{ aa b^n \given n > 0 } \).}
    \label{fig:def:finite_automaton}
  \end{figure}

  \begin{thmenum}
    \thmitem{def:finite_automaton/graph} Consider \( \delta \) as a set of triples \( (h_0, l_0, t_0) \). Denote by \( h: \delta \to Q \), \( l: \delta \to \Sigma \) and \( t: \delta \to Q \) the functions that take the corresponding entry out of each triple.

    Then the quadruple \( (Q, \delta, h, t) \) is a \hyperref[def:directed_multigraph]{directed multigraph}, whose arcs are \hyperref[def:labeled_set]{labeled} by \( l \).

    We often identify the automaton with its (multi)graph. When drawing this graph, for example in \cref{fig:def:finite_automaton}, we denote initial states via inward arrows without a source and terminal states via double circles.

    \thmitem{def:finite_automaton/determinism} If there is only one initial state and if \( \delta \) is a \hyperref[def:set_valued_map/partial]{single-valued partial function}, we say that the automata is \term{deterministic}.

    Determinism ensures that there is at most one possible state to transition to, given a current state and a symbol.

    \thmitem{def:finite_automaton/recognition} We say that the automaton \term{accepts} or \term{recognizes} the \hyperref[def:formal_language/word]{word} \( a_1 \cdots a_n \) over \( \mscrA \) if there exists a \hyperref[def:graph_walk/directed]{walk}
    \begin{equation*}
      s \reloset {e_1} \to \anon \reloset {e_2} \to \cdots \reloset {e_{n-1}} \to \anon \reloset {e_n} \to \anon.
    \end{equation*}
    such that
    \begin{itemize}
      \item The label \( l(e_k) \) is \( a_k \) for every \( k = 1, \ldots, n \).
      \item The tail \( t(e_n) \) of the walk is a terminal state from \( T \).
    \end{itemize}

    \thmitem{def:finite_automaton/language} The set of all words recognized by the automaton is called the language \term{accepted} or \term{recognized} by the automaton. We denote this language via \( \mscrL(F) \).

    \thmitem{def:finite_automaton/equivalent} We say that two finite automata are \term{equivalent} if they recognize the same language.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:reverse_language}\mcite[17]{Salomaa1987}
  We define the \term{reverse language} of \( \mscrL \) as
  \begin{equation*}
    \op{rev}(\mscrL) \coloneqq \set{ \op{rev}(w) \given w \in \mscrL }.
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:reverse_language_involution}
  The \hyperref[def:reverse_language]{reverse} of the reverse of \( \mscrL \) is \( \mscrL \) itself.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{definition}\label{def:reverse_finite_automaton}\mimprovised
  We define the \term{reverse automaton} of \( F = (\Sigma, Q, \delta, I, T) \) as
  \begin{equation*}
    \op{rev}(F) \coloneqq (\Sigma, Q, \op{rev}(\delta), T, I),
  \end{equation*}
  where
  \begin{equation*}
    \op{rev}(\delta)(B, a) \coloneqq A \T{if} \delta(A, a) \coloneqq B.
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:reverse_finite_automaton_graph}
  The \hyperref[def:finite_automaton/graph]{graph} of the \hyperref[def:reverse_finite_automaton]{reverse automaton} \( \op{rev}(F) \) is the \hyperref[def:opposite_directed_multigraph]{opposite graph}.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{proposition}\label{thm:reverse_finite_automaton_language}
  For a given \hyperref[def:finite_automaton]{finite automaton} \( F = (\Sigma, Q, \delta, I, T) \), we have
  \begin{equation*}
    \mscrL(\op{rev}(F)) = \op{rev}(\mscrL(F)).
  \end{equation*}
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{example}\label{ex:def:finite_automaton}
  We list several examples of \hyperref[def:finite_automaton]{finite automata}:
  \begin{thmenum}
    \thmitem{ex:def:finite_automaton/even} Consider the language form \fullref{ex:def:formal_language/leucine} describing even binary numbers. The language can be recognized by
    \begin{equation*}
      \includegraphics[page=2]{output/ex__def__finite_automaton}
    \end{equation*}

    \thmitem{ex:def:finite_automaton/leucine} Consider the language form \fullref{ex:def:formal_language/leucine} describing Leucine. It can be recognized by the nondeterministic finite automaton
    \begin{equation*}
      \includegraphics[page=1]{output/ex__def__finite_automaton}
    \end{equation*}

    \thmitem{ex:def:finite_automaton/anbn} Consider the language
    \begin{equation*}
      \mscrL \coloneqq \set{ a^n b^n \given n \geq 0 }
    \end{equation*}
    from \fullref{ex:def:formal_language/anbn}.

    As we will see in \fullref{alg:determinization_of_finite_automata}, a deterministic automaton exists accepting a language if and only if a nondeterministic one exists. Aiming at a contradiction, suppose that there exists some deterministic finite automaton \( F = (\Sigma, Q, \delta, \set{ s }, T) \) whose language is \( \mscrL \). Let \( G \) be its multigraph.

    Since \( s \) is the only initial state, and since \( \mscrL \) contains the empty string, then \( s \) must also be a terminal state.

    Furthermore, \( \mscrL \) contains the word \( ab \), hence there must exist a terminal state \( t_1 \) and an intermediate state \( q_1 \) such that
    \begin{equation*}
      \includegraphics[page=3]{output/ex__def__finite_automaton}
    \end{equation*}

    Furthermore, the above is a full subgraph of \( G \) --- none of the states above are interconnected by any additional arcs.

    Then, in order for \( F \) to accept \( aabb \), it must have more states. Since the automaton is deterministic, there cannot be another arc with label \enquote{\( a \)} starting at \( s \). Hence, \( q_1 \) is the only node where it is possible to have another arc with label \enquote{\( a \)}.

    Hence, \( G \) either has as a subgraph either
    \begin{equation*}
      \includegraphics[page=4]{output/ex__def__finite_automaton}
    \end{equation*}
    or
    \begin{equation*}
      \includegraphics[page=5]{output/ex__def__finite_automaton}
    \end{equation*}

    In particular, \( F \) must have at least five states in order to recognize \( a^2 b^2 \).

    Continuing by induction, we conclude that in order for \( F \) to recognize \( a^n b^n \), it must have at least \( 2n + 1 \) states. For example, the following automaton recognizes \( a^n b^n \):
    \begin{equation*}
      \includegraphics[page=6]{output/ex__def__finite_automaton}
    \end{equation*}

    But \( \mscrL \) contains word of arbitrary length. Therefore, no finite automaton is able to recognize \( \mscrL \).
  \end{thmenum}
\end{example}

\begin{algorithm}[Determinization of finite automata]\label{alg:determinization_of_finite_automata}
  Let \( N = (\Sigma, Q, \delta, I, T) \) be a \hyperref[def:finite_automaton]{finite automaton}. We will build an \hyperref[def:finite_automaton/equivalent]{equivalent} \hyperref[def:finite_automaton/determinism]{deterministic automaton} \( \det(N) \).

  This can be achieved by grouping states that would otherwise make the automaton nondeterministic. We will first recursively construct the operator \( \mscrD(A, V) \), which, given a set of states \( A \) and a family of \enquote{visited} sets of states \( V \), produces a family of triples describing the transitions of the deterministic automaton. The family \( V \) helps us avoid cycles when traversing \( N \).

  \begin{thmenum}
    \thmitem{alg:determinization_of_finite_automata/step} Suppose we are given a set \( A \) of vertices and a family \( V \) of sets of visited states. Let
    \begin{equation*}
      K \coloneqq \set{ l(e) \given e \in E \T{and} h(e) \in A }
    \end{equation*}
    be the set of all labels of arcs going out from \( A \), and, for each \( k \in K \), let
    \begin{equation*}
      O_k \coloneqq \set{ t(e) \given e \in E \T{and} h(e) \in A \T{and} l(e) = k }
    \end{equation*}
    be the set of all terminal vertices \( b \) of arcs going out from \( A \) that have label \( k \).

    Define the set of triples
    \begin{equation*}
      E_A \coloneqq \set{ (A, O_k, k) \given k \in K }.
    \end{equation*}

    Finally, define
    \begin{equation*}
      \mscrD(A, V) \coloneqq E_A \cup \bigcup \set[\Big]{ \mscrD\parens*{ O_k , V \cup \set{ A } } \given* k \in K \T{and} O_k \not\in V }.
    \end{equation*}

    Note how we used \( V \) to filter out only those sets \( O_k \) that have not yet been visited.

    \thmitem{alg:determinization_of_finite_automata/run} Let \( \delta' \coloneqq \mscrD(I, \varnothing) \). Define
    \begin{equation*}
      Q' \coloneqq \set{ A \given (A, O_k, k) \in \delta' } \cup \set{ O_k \given (A, O_k, k) \in \delta' }.
    \end{equation*}

    Define also the set of initial states \( I' \coloneqq \set{ I } \) and of terminal states
    \begin{equation*}
      T' \coloneqq \set{ A \given A \T{is a vertex of} G' \T{and} A \cap T \neq \varnothing }.
    \end{equation*}

    Then \( \det(N) \coloneqq (\Sigma, Q', \delta', I', T') \) is the desired finite automaton.
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \texttt{automata.finite.determinize} in \cite{code}.
\end{comments}
\begin{defproof}
  We have explicitly made \( I \) the only initial state, and we have grouped arcs with identical labels. Hence, \( F \) is indeed deterministic.

  We must show that \( \mscrL(N) = \mscrL(F) \). We have introduced a special state for every occurrence of several vertices that have incoming arcs with identical labels. Hence, we replace every such group of arcs with a single arc. The two automata should then accept identical languages.
\end{defproof}

\begin{definition}\label{def:formal_grammar}\mcite[9]{Salomaa1987}
  Let \( \Sigma \) and \( V \) be disjoint nonempty subsets of some \hyperref[def:formal_language]{alphabet}, whose members we call \term{terminals} and \term{variables}, respectively. Fix some \term{start symbol} \( S \in V \).

  Let \( \to \) be some \hyperref[def:binary_relation]{binary relation} over \( (V \cup \Sigma)^* \), whose members we call \term{production rules}. We impose the restriction that, for every rule \( v \to w \), the word \( v \) contains at least one terminal.

  We call the quadruple \( (V, \Sigma, \to, S) \) a \term{formal grammar}.

  \begin{thmenum}
    \thmitem{def:formal_grammar/derivation} We define the binary relation \( \Rightarrow \) on the Kleene star \( (V \cup \Sigma)^* \) by declaring that, for every two \hyperref[def:formal_language/word]{words} \( p \) and \( s \) over \( V \cup \Sigma \) and every production rule \( v \to w \), we have \( pvs \Rightarrow pws \).

    A \term{derivation} of the word \( w_m \) from \( w_1 \) is a finite sequence of words such that
    \begin{equation}\label{eq:def:formal_grammar/derivation}
      w_1
      \Rightarrow
      w_2
      \Rightarrow
      \cdots
      \Rightarrow
      w_{n-1}
      \Rightarrow
      w_m.
    \end{equation}

    We say that \( w_m \) is \term{derivable} from \( w_1 \) if there exists a derivation from \( w_1 \) to \( w_m \).

    We denote the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \Rightarrow \) by \( \reloset + \Rightarrow \) and the \hyperref[def:relation_closures/reflexive]{reflexive} closure of \( \reloset + \Rightarrow \) by \( \reloset {*} \Rightarrow \). Clearly \( w_1 \) is derivable from \( w_n \) if and only if \( w_1 \reloset {*} \Rightarrow w_m \).

    \thmitem{def:formal_grammar/language} We associate the following language with the grammar \( G \):
    \begin{equation*}
      \mscrL(G) \coloneqq \set{ w \in \Sigma^* \given S \reloset + \Rightarrow w }.
    \end{equation*}

    It consists of all words that are derivable from \( S \) and contain only terminals.

    We say that words in \( \mscrL(G) \) are \term{generated} by \( G \).

    \thmitem{def:formal_grammar/equivalent} We say that two grammars are \term{equivalent} if they generate the same language.

    \thmitem{def:formal_grammar/graph}\mimprovised We can regard the derivation relation \( \Rightarrow \) as a set of \hyperref[def:directed_multigraph/arcs]{arcs} over the grammar language \( \mscrL(G) \). Thus, \( (\mscrL(G), \Rightarrow) \) is a \hyperref[def:directed_graph]{directed graph}, whose nonempty walks are precisely the derivations in \( G \). Furthermore, we can \hyperref[def:labeled_set]{label} each arc with the rule applied.

    We call it the \term{derivation graph} of \( G \).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:derivation_graph_connected}
  Every \hyperref[def:formal_grammar/graph]{derivation graph} is \hyperref[def:graph_connectedness/strong]{strongly connected}.
\end{proposition}
\begin{proof}
  A \hyperref[def:formal_grammar/language]{grammar's language} is defined as the set of all words that can be derived from the starting symbol.
\end{proof}

\begin{example}\label{ex:natural_number_arithmetic_grammar/rules}
  We define a grammar for arithmetic of \hyperref[def:natural_numbers]{natural numbers}. We will use binary notation for simplicity.

  Let \( V \coloneqq \set{ N, O, E } \) and \( \Sigma \coloneqq \set{ 0, 1, +, \times, (, ) } \). Consider the derivation rules
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/rules/simple}
    \begin{aligned}
      N &\to 0   & \quad B &\to 0   & \quad O &\to +      & \quad E &\to N \\
      N &\to 1   & \quad B &\to 0 B & \quad O &\to -      & \quad E &\to (E O E) \\
      N &\to 1 B & \quad B &\to 1   & \quad   &           &         & \\
        &        & \quad B &\to 1 B & \quad   &           &         & \\
    \end{aligned}
  \end{equation}

  It is convenient to use the following shorthands:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/rules/shorthand}
    \begin{aligned}
      N &\to 0 \mid 1 \mid 1 B \\
      B &\to 0 \mid B 0 \mid 1 \mid B 1 \\
      O &\to + \mid \times \\
      E &\to N \mid (E O E)
    \end{aligned}
  \end{equation}

  We can choose different non-terminals as the starting symbol. The symbol \( N \) corresponds to numbers, \( O \) corresponds to operations, and \( E \) can be either a number or a binary expression. We say that \eqref{eq:ex:natural_number_arithmetic_grammar/rules/shorthand} specifies a \term{grammar schema}.

  \begin{figure}[!ht]
    \centering
    \includegraphics[page=1]{output/ex__natural_number_arithmetic_grammar__rules}
    \caption{A fragment of the \hyperref[def:formal_grammar/graph]{derivation graph} of the binary natural number arithmetic grammar from \fullref{ex:natural_number_arithmetic_grammar/rules}.}
    \label{fig:ex:natural_number_arithmetic_grammar/rules}
  \end{figure}
\end{example}

\begin{remark}\label{rem:length_increasing_grammar}
  Given a finite set of grammar rules, there may \hyperref[def:formal_grammar/derivation]{derivations} of arbitrary length. This can happen even if we remove cycles from the \hyperref[def:formal_grammar/graph]{derivation graph} --- see \fullref{ex:thm:length_increasing_grammar}. We will discuss a way to restrict this behavior and ensure that it is possible to determine whether a derivation exists in finitely many steps.

  In general, given the grammar rule \( v \to w \), it is possible that \( \len(v) \geq \len(w) \). This is always true for \hyperref[def:epsilon_free_grammar]{\( \varepsilon \)-rules}, for example.

  Noam Chomsky in \cite[361]{MathPsychology1963Vol2} defines \enquote{type 1} grammars as those satisfying the inequality \( \len(v) \leq \len(w) \) for every rule \( v \to w \). These grammars still have cycles like \( A \to B \to A \), but they avoid more convoluted cases and lead to \Fullref{alg:length_increasing_grammar}.

  This restriction excludes the empty string from the grammar's language. Arto Salomaa in \cite[15]{Salomaa1987} additionally allows the rule \( S \to \varepsilon \), but only if \( S \) does not occur on the right side of any derivation. \Fullref{ex:thm:length_increasing_grammar} highlights the importance of the latter assumption.

  Salomaa calls these grammars \enquote{length-increasing}, preferring to use \enquote{type 1} for what we call \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammars. The latter are, up to nuances of \( \varepsilon \)-rules, called \enquote{type 1} grammars by Chomsky earlier in \cite[142]{Chomsky1959}. John Savage in \cite[def. 4.9.2]{Savage1998} defines \enquote{context-sensitive grammars} as what Salomaa calls length-increasing. We introduce the term \enquote{essentially length-increasing} in \fullref{def:length_increasing_grammar} and generally avoid \enquote{type 1} when referring to grammars or languages to circumvent ambiguity.

  (What we call) context-sensitive \hi{grammars} are a strict subset of the essentially length-increasing grammars, but \fullref{thm:context_sensitive_languages} shows that context-sensitive \hi{languages} and length-increasing languages coincide. Hence, the term \enquote{type 1 language} makes sense, although we prefer \enquote{context-sensitive language}.
\end{remark}

\begin{definition}\label{def:epsilon_free_grammar}\mimprovised
  Fix a formal grammar \( G = (V, \Sigma, \to, S) \). Rules of the form \( A \to \varepsilon \), where \( A \) is a non-terminal, play a special role. We call them \( \varepsilon \)-rules.

  We say that \( G \) is \term{\( \mathbf{\varepsilon} \)-free} if there are no \( \varepsilon \) rules.

  This condition turns out to be too restrictive because it disallows the grammar to generate empty words. Thus, we introduce another concept. We say that \( G \) is \term{essentially \( \mathbf{\varepsilon} \)-free} if \( S \to \varepsilon \) is the only \( \varepsilon \)-rule allowed, and if it is present, \( S \) must not be on the right side of any rule.
\end{definition}

\begin{definition}\label{def:length_increasing_grammar}\mcite[15]{Salomaa1987}
  We say that the grammar \( G = (V, \Sigma, \to, S) \) is \term{length-increasing} if \( \len(v) \leq \len(w) \) for every rule \( v \to w \) and \term{essentially length-increasing} if it is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and if \( \len(v) \leq \len(w) \) for any non-\( \varepsilon \)-rule.
\end{definition}

\begin{lemma}\label{thm:length_increasing_grammar}
  Fix an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar \( G = (V, \Sigma, \to, S) \). Let \( m \) be the cardinality of \( \Sigma \cup V \).

  If the word \( w \) over \( \Sigma \) of length \( n \) is derivable, there exists a derivation of length at most \( m^{n+1} \).
\end{lemma}
\begin{comments}
  \item This is only a rough bound on the derivation length. With minimal changes to the proof, we can reduce the bound to
  \begin{equation*}
    \sum_{k=0}^n m^k
    \reloset {\ref{thm:geometric_series_properties/finite_sum}} =
    \frac {1 - m^{n+1}} {1 - m}
  \end{equation*}
  and perhaps further, but we are only interested in a \hi{finite} upper bound.

  \item Chomsky introduced length-increasing grammars in \cite[360]{MathPsychology1963Vol2} and on the same page hinted at this property of theirs, which we will use in \fullref{alg:length_increasing_grammar}.
\end{comments}
\begin{proof}
  We will use \hyperref[rem:induction/peano_arithmetic]{natural number induction} on \( n \) to show a slightly more general statement, in which the word \( w \) is over \( \Sigma \cup V \) and not only over \( \Sigma \).

  \begin{itemize}
    \item The case where \( w \) is empty is handled separately. Either \( S \to \varepsilon \) is a rule in \( G \) or not, hence if \( \varepsilon \) is derivable, it has exactly one possible derivation, whose length is \( 1 = m^0 \).

    \item Suppose that \( w \) consists of a single letter \( a \).

    There are \( m \) terminals and non-terminals in \( G \). Hence, there are at most \( m - 1 \) non-terminals, and thus at most \( m - 1 \) steps from one single-symbol word to another. This follows from \fullref{def:pigeonhole_principle} --- any longer derivation would result in a \hyperref[def:graph_cycle]{cycle} in the \hyperref[def:formal_grammar/graph]{derivation graph}. Thus, if we can derive \( w \), we can derive it in at most \( m - 1 \) steps by potentially eliminating cycles.

    In the simplest case, there is a rule \( S \to a \), while in the most complicated case there is a chain
    \begin{equation*}
      S \to A_1 \to \cdots \to A_{m-2} \to a.
    \end{equation*}

    \item Let \( \len(w) = n > 1 \) and suppose that the lemma holds for words of smaller length. Consider the derivation
    \begin{equation*}
      S \Rightarrow w_1 \Rightarrow \cdots \Rightarrow w_r = w.
    \end{equation*}

    Let \( s \) be the last index for which \( w_s \) has length strictly less than \( n \). Let \( n_0 \) be the length of the word \( w_s \).

    By the inductive hypothesis, the derivation of \( w_s \) from \( S \) has length \( s \leq m^{n_0 + 1} \).

    There are exactly \( m^n \) words of length \( n \) over \( \Sigma \cup V \). Hence, again by \fullref{def:pigeonhole_principle}, there are at most \( m^n \) steps between \( w_s \) and \( w_k \). Therefore,
    \begin{equation*}
      r
      \leq
      s + m^n
      =
      m^{n_0 + 1} + m^n
      \leq
      m^{n+1},
    \end{equation*}
    where we have used that \( \card(m) \geq 2 \).
  \end{itemize}
\end{proof}

\begin{example}\label{ex:thm:length_increasing_grammar}
  Consider the grammar
  \begin{equation}\label{eq:ex:thm:length_increasing_grammar/bad}
    \begin{aligned}
      S &\to \varepsilon \\
      S &\to a, \\
      S &\to SS.
    \end{aligned}
  \end{equation}

  It is not \hyperref[def:epsilon_free_grammar]{essentially epsilon-free}, hence also not \hyperref[def:length_increasing_grammar]{essentially length-increasing}, and thus \fullref{thm:length_increasing_grammar} does not apply. The lemma would imply that the acyclic derivation length should be bounded by \( 2 \), while there exist countably many acyclic derivations of the word \( a \):
  \begin{equation*}
    \begin{aligned}
      S &\Rightarrow a \\
      S &\Rightarrow SS \Rightarrow Sa \Rightarrow a \\
      S &\Rightarrow SS \Rightarrow SSS \Rightarrow SSa \Rightarrow Sa \Rightarrow a \\
        &\vdots
    \end{aligned}
  \end{equation*}

  This is problematic for parsing algorithms because we cannot check in finitely many steps whether a grammar generates a word. \Fullref{alg:epsilon_rule_removal} suggests instead the essentially length-increasing grammar
  \begin{equation*}
    \begin{aligned}
      S &\to \varepsilon \\\
      S &\to A, \\
      A &\to a, \\
      A &\to AA,
    \end{aligned}
  \end{equation*}
  which disallows the aforementioned derivations.
\end{example}

\begin{algorithm}[Word membership in context-sensitive languages]\label{alg:length_increasing_grammar}
  Let \( G = (V, \Sigma, \to, S) \) be an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar for \( \mscrL \), and let \( w \) be a word of length \( n \) over \( \Sigma \).

  We will construct a derivation of \( w \), if one exists. The algorithm itself is na\"ive --- generate all derivations from \( S \) of length at most \( \card(V \cup \Sigma)^{n+1} \), and check if any of them ends with \( w \).
\end{algorithm}
\begin{comments}
  \item This algorithm can be used to test whether a word belongs to a \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive language}, hence the name.

  \item Compare this to the more complicated \fullref{alg:brute_force_parsing} that handled more restricted cases, but also handles \( \varepsilon \)-rules.
\end{comments}
\begin{proof}
  As a consequence of \fullref{thm:length_increasing_grammar}, \( w \) belongs to \( \mscrL \) if and only if some derivation from \( S \) of length at most \( \card(V \cup \Sigma)^{n+1} \) ends with \( w \).
\end{proof}

\begin{definition}\label{def:chomsky_hierarchy}\mcite[15]{Salomaa1987}
  We can classify \hyperref[def:formal_grammar]{formal grammars} and \hyperref[def:formal_language]{languages} to form the \term{Chomsky hierarchy}. Chomsky himself in \cite[def. 6]{Chomsky1959} defined a hierarchy of grammars consisting of four types --- \enquote{type 0} through \enquote{type 3}. He also defined a parallel hierarchy of languages, in which \( \mscrL \) is a \enquote{type \( i \) language} if there exists a type \( i \) grammar \hyperref[def:formal_grammar/language]{generating it}.

  Unfortunately, these definitions later evolved to be inconsistent across authors, and even among different publications by Chomsky. We thus entirely avoid numeric grammar and language types, and use more descriptive names instead. The grammars no longer form a hierarchy, but the corresponding languages do.

  \begin{thmenum}
    \thmitem{def:chomsky_hierarchy/unrestricted} When no additional restrictions are imposed on the rules of the grammar, we say that it is \term{unrestricted}. We call the corresponding languages \term{recursively enumerable}.

    \thmitem{def:chomsky_hierarchy/context_sensitive} We say that the grammar is \term{context-sensitive} if it is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and if every non-\( \varepsilon \)-rule has the form
    \begin{equation*}
      p A s \to p w s
    \end{equation*}
    for a non-terminal \( A \), arbitrary words \( p \) and \( s \) and a nonempty word \( w \). Of course, there may be multiple such representations for a single rule.

    We call the corresponding languages \term{context-sensitive}. The kerfuffle surrounding the term \enquote{context-sensitive} is discussed in \fullref{rem:length_increasing_grammar}. \Fullref{thm:context_sensitive_languages} better characterizes these languages.

    \thmitem{def:chomsky_hierarchy/context_free} We say that the grammar is \term{context-free} if every rule has the form
    \begin{equation*}
      A \to w,
    \end{equation*}
    where \( A \) is a non-terminal and \( w \) is an arbitrary word.

    We call the corresponding languages \term{context-free}. While it is possible for a context-free \hi{grammar} to not be \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and hence not context-sensitive, a context-free \hi{language} is context-sensitive. This is shown in \fullref{thm:context_free_languages_are_conext_sensitive} and discussed in \fullref{rem:chomsky_hierarchy_failure}.

    \thmitem{def:chomsky_hierarchy/regular} Finally, we call the grammar \term{left-linear} if every rule has one of the forms
    \begin{itemize}
      \item \( A \to w \),
      \item \( A \to B w \),
    \end{itemize}
    where \( w \) is an arbitrary word consisting entirely of terminals. Similarly, it is \term{right-linear} if every rule has one of the forms
    \begin{itemize}
      \item \( A \to w \),
      \item \( A \to w B \).
    \end{itemize}

    We refer to the two types of grammars collectively as \term{regular grammars}.

    We call the language \term{regular} if it can be generated by either a left-linear or a right-linear grammar. \Fullref{thm:regular_languages} better characterizes these languages.
  \end{thmenum}
\end{definition}
\begin{comments}
  \item In \cite[142]{Chomsky1959}, Chomsky called context-free languages \enquote{type 2} and regular languages \enquote{type 3}, while in \cite[366]{MathPsychology1963Vol2} he called context-free languages \enquote{type 4} and gave no number for regular languages.
\end{comments}

\begin{proposition}\label{thm:non_recursively_enumerable_language}\mcite[thm. 5.7.4]{Savage1998}
  There exists a formal language that cannot be generated by a grammar.
\end{proposition}

\begin{example}\label{ex:def:chomsky_hierarchy}
  We give several examples of grammars in the \hyperref[def:chomsky_hierarchy]{Chomsky hierarchy}.

  \begin{thmenum}
    \thmitem{ex:def:chomsky_hierarchy/non_enumerable} While every grammar is an unrestricted grammar, \fullref{thm:non_recursively_enumerable_language} shows that not every language is recursively enumerable.

    \thmitem{ex:def:chomsky_hierarchy/an} The \hyperref[def:chomsky_hierarchy/regular]{right-linear grammar}
    \begin{equation*}
      \begin{aligned}
        S &\to aS \mid \varepsilon
      \end{aligned}
    \end{equation*}
    describes the language \( \mscrL = \set{ a^n \given n \geq 0 } \) discussed in \fullref{ex:def:formal_language/an}.

    It can also be described via the left-linear grammar
    \begin{equation*}
      \begin{aligned}
        S &\to Sa \mid \varepsilon.
      \end{aligned}
    \end{equation*}

    Neither of these grammars is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free}. \Fullref{ex:alg:epsilon_rule_removal/an} proposes using \Fullref{alg:epsilon_rule_removal} to obtain the essentially length-increasing grammar
    \begin{equation*}
      \begin{aligned}
        S &\to A \mid \varepsilon, \\
        A &\to aA \mid a.
      \end{aligned}
    \end{equation*}

    \thmitem{ex:def:chomsky_hierarchy/anbn} Consider the \hyperref[def:chomsky_hierarchy/context_free]{context-free grammar}
    \begin{equation*}
      \begin{aligned}
        S &\to A \mid \varepsilon, \\
        A &\to aAb \mid ab
      \end{aligned}
    \end{equation*}
    describing \( \mscrL = \set{ a^n b^n \given n \geq 0 } \) from \fullref{ex:def:formal_language/anbn}.

    We have shown in \fullref{ex:def:finite_automaton/anbn} that this language cannot be recognized by a finite automaton. \Fullref{thm:regular_languages} suggests that it is not \hyperref[def:chomsky_hierarchy/regular]{regular}.

    Hence, \( \mscrL \) is a context-free language that is not regular.
  \end{thmenum}
\end{example}

\begin{algorithm}[Length-increasing to context-sensitive grammar]\label{alg:length_increasing_to_context_sensitive}\mcite[thm. 9.2]{Salomaa1987}
  Fix an \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammar \( G' = (V', \Sigma, \to', S) \) with the same terminals.

  \begin{thmenum}
    \thmitem{alg:length_increasing_to_context_sensitive/intermediate} Build an intermediate grammar \( G_I = (V_I, \Sigma, \to_I, S) \) as follows:
    \begin{itemize}
      \item Let \( \Sigma_I \) be a set of new non-terminals, one for each terminal in \( \Sigma \), and let \( \varphi: \Sigma \to \Sigma_I \) be an explicit bijective mapping between the two.
      \item Let \( V_I \coloneqq V \cup \Sigma_I \).
      \item For each terminal \( a \in \Sigma \), add to \( G_I \) a new rule \( \varphi(a) \to a \).
      \item For each rule \( v \to w \), add a corresponding rule to \( G_I \) by replacing all terminals in \( v \) and \( w \) with the corresponding new non-terminals.
    \end{itemize}

    \thmitem{alg:length_increasing_to_context_sensitive/init} Let \( V_0 \coloneqq V_I \) and let \( \to'_0 \) be the set of context-sensitive rules of \( G_I \), excluding \( S \to \varepsilon \). Enumerate all non-context-sensitive rules in \( G_I \) as \( v_k \to w_k \) for \( k = 1, \ldots, m \).

    \thmitem{alg:length_increasing_to_context_sensitive/rules} For each \( k = 1, \ldots, m \), let \( v_k = A_1 \cdots A_r \) and \( w_k = B_1 \cdots B_s \). Clearly \( r \leq s \). Let \( C_1, \ldots, C_r \) be new non-terminals.

    \begin{thmenum}
      \thmitem{alg:length_increasing_to_context_sensitive/rules/non_terminals} Define \( V_k \coloneqq V_{k-1} \cup \set{ C_1, \ldots, C_r } \).
      \thmitem{alg:length_increasing_to_context_sensitive/rules/new} Define \( \to'_k \) as \( \to'_{k-1} \) with the following additional rules:
      \begin{align*}
        A_1 A_2 \cdots A_r                            &\to'_k C_1 A_2 \cdots A_r, \\
        C_1 A_2 \cdots A_r                            &\to'_k C_1 C_2 \cdots A_r, \\
                                                      &\vdots, \\
        C_1 C_2 \cdots C_{r-1} A_r                    &\to'_k C_1 C_2 \cdots C_{r-1} C_r B_{r+1} \cdots B_s, \\
        C_1 C_2 \cdots C_{r-1} C_r B_{r+1} \cdots B_s &\to'_k B_1 C_2 \cdots C_{r-1} C_r B_{r+1} \cdots B_s, \\
                                                      &\vdots, \\
        B_1 B_2 \cdots B_{r-1} B_r B_{r+1} \cdots B_s &\to'_k B_1 B_2 \cdots B_{r-1} B_r B_{r+1} \cdots B_s
      \end{align*}
    \end{thmenum}

    \thmitem{alg:length_increasing_to_context_sensitive/finish} Define \( V' \coloneqq V'_m \) and \( {}\to'{} \coloneqq {}\to'_m{} \).

    Then \( G' = (V', \Sigma, \to', S) \) is the desired grammar.
  \end{thmenum}
\end{algorithm}

\begin{proposition}\label{thm:context_sensitive_languages}
  The class of languages generated by \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive grammars} and by \hyperref[def:length_increasing_grammar]{essentially length-increasing} grammars coincide.
\end{proposition}
\begin{comments}
  \item As discussed in \fullref{rem:length_increasing_grammar} and \fullref{def:chomsky_hierarchy/context_sensitive}, we call this class of languages \enquote{context-sensitive languages}.
\end{comments}
\begin{proof}
  Every context-sensitive grammar is, by definition, essentially length-increasing. \Fullref{alg:length_increasing_to_context_sensitive} shows that every essentially length-increasing grammar has an equivalent context-sensitive grammar.
\end{proof}

\begin{remark}\label{rem:chomsky_hierarchy_failure}
  Every \hyperref[def:chomsky_hierarchy/regular]{regular grammar} is \hyperref[def:chomsky_hierarchy/context_free]{context-free}, but not every context-free grammar is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} and hence \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive}. Chomsky disallowed \( \varepsilon \)-rules in \cite[def. 6]{Chomsky1959}, and this led to a tidy hierarchy because it made context-free grammars necessarily context-sensitive.

  Fortunately, context-free \hi{languages} are context-sensitive as a consequence of \fullref{thm:context_free_languages_are_conext_sensitive}.

  Unfortunately, for an arbitrary context-free grammar, \fullref{thm:length_increasing_grammar} does not hold, and neither does \fullref{alg:length_increasing_grammar}. This is not a problem because:
  \begin{itemize}
    \item For theoretical purposes, we can use \fullref{alg:epsilon_rule_removal} to adapt context-free languages to \fullref{alg:length_increasing_grammar}.

    \item For practical purposes, parsing context-free languages is a topic in itself. These algorithms are mostly restricted to certain classes of context-free grammars; see e.g. \cite[ch. 6]{Salomaa1987}. General algorithms for parsing all context-free grammars are scarcer; several are discussed in \cite{Economopoulos2006}. We present \fullref{alg:brute_force_parsing}, which handles arbitrary context-free grammars, but is too inefficient to use in practice.
  \end{itemize}
\end{remark}

\begin{algorithm}[Epsilon rule removal]\label{alg:epsilon_rule_removal}\mcite[thm. 6.2]{Salomaa1987}
  Fix a \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} context-free grammar \( G' = (V', \Sigma, \to', S') \) with the same terminals, such that \( G' \) is \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free}, and thus context-sensitive.

  \begin{thmenum}
    \thmitem{alg:epsilon_rule_removal/init} Define recursively the sequence of sets
    \begin{equation*}
      U_k \coloneqq \begin{cases}
        \set{ A \in V \given A \to \varepsilon },                                                          &k = 0, \\
        U_{k-1} \cup \set{ A \in V \given \qexists{B_1, \ldots, B_n \in U_{k-1}^*} A \to B_1 \cdots B_n }, &k > 0.
      \end{cases}
    \end{equation*}

    Since \( V \) has only finitely many non-terminals, the sequence \hyperref[def:stabilizing_chain]{stabilizes} --- there exists some index \( m \) such that \( U_m = U_k \) for any \( k > m \).

    We have constructed \( U_m \) so that \( A \reloset {*} \Rightarrow \varepsilon \) if and only if \( A \in U_m \).

    \thmitem{alg:epsilon_rule_removal/rules} Now our goal is to define the rules of \( G' \) based on the rules of \( G \), but with zero or more \enquote{nullable} non-terminals removed from the right side of any rule.

    Let \( S' \) be an entirely new start symbol and let \( V' \coloneqq V \cup \set{ S' } \). Define the production relation \( A \to' w \) to hold if \( w \) \hi{is nonempty} and there exist words \( w_0, \ldots, w_n \) over \( V \cup \Sigma \) and non-terminals \( B_1, \ldots, B_n \) from \( U_m \) such that
    \begin{equation*}
      A \to w_0 B_1 w_1 B_2 w_2 \cdots B_n w_n.
    \end{equation*}
    and
    \begin{equation*}
      w = w_0 w_1 w_2 \cdots w_n.
    \end{equation*}

    \thmitem{alg:epsilon_rule_removal/finish} Define \( S' \to S \). If \( \varepsilon \in \mscrL(G) \), also add the rule \( S' \to \varepsilon \).

    Then \( G' = (V', \Sigma, \to', S') \) is the desired grammar.
  \end{thmenum}
\end{algorithm}

\begin{example}\label{ex:alg:epsilon_rule_removal}
  We list several examples demonstrating the operation of \fullref{alg:epsilon_rule_removal}:
  \begin{thmenum}
    \thmitem{ex:alg:epsilon_rule_removal/an} We discussed the grammar
    \begin{equation*}
      S \to aS \mid \varepsilon
    \end{equation*}
    in \fullref{ex:def:chomsky_hierarchy/an}.

    Using \fullref{alg:epsilon_rule_removal}, we conclude that the only non-terminal \( S \) belongs to \( U_0 \). Thus, \fullref{alg:epsilon_rule_removal/rules} suggests instead the rules
    \begin{equation*}
      S \to' aS \mid a
    \end{equation*}
    and \fullref{alg:epsilon_rule_removal/finish} suggests
    \begin{equation*}
      S' \to' S \mid \varepsilon,
    \end{equation*}
    where \( S' \) is the new starting non-terminal.

    The obtained grammar is essentially \( \varepsilon \)-free.

    \thmitem{ex:alg:epsilon_rule_removal/natural} Given the rules
    \begin{equation*}
      \begin{aligned}
        N &\to 0 \mid 1 B, \\
        B &\to \varepsilon \mid 0 B \mid 1 B
      \end{aligned}
    \end{equation*}
    and starting symbol \( N \), the algorithm suggests instead
    \begin{equation*}
      \begin{aligned}
        S' &\to' N, \\
        N  &\to' 0 \mid 1 \mid 1 B, \\
        B  &\to' 0 \mid 0 B \mid 1 \mid 1 B.
      \end{aligned}
    \end{equation*}

    The only member of \( U_m \) is \( B \), and we add a new rule of every instance of \( B \) where it is removed.

    This motivated our choice for rules in \fullref{ex:natural_number_arithmetic_grammar/rules}. The obtained grammar is \( \varepsilon \)-free; not merely essentially \( \varepsilon \)-free.

    \thmitem{ex:alg:epsilon_rule_removal/dead} It is possible to obtain \enquote{dead} rules via \fullref{alg:epsilon_rule_removal}. For example, for
    \begin{equation*}
      \begin{aligned}
        S &\to A B, \\
        A &\to \varepsilon \mid a, \\
        B &\to \varepsilon
      \end{aligned}
    \end{equation*}
    with starting symbol \( S \), the algorithm produces
    \begin{equation*}
      \begin{aligned}
        S' &\to S \mid \varepsilon, \\
        S &\to A B \mid A \mid B, \\
        A &\to a. \\
      \end{aligned}
    \end{equation*}

    The derivations
    \begin{equation*}
      S' \Rightarrow S \Rightarrow B
    \end{equation*}
    and
    \begin{equation*}
      S' \Rightarrow S \Rightarrow A B \Rightarrow a B
    \end{equation*}
    cannot be expanded further and reach a word consisting entirely of terminals.

    Thus, the rules \( S \to B \) and \( S \to A B \) are essentially useless, but do no harm unless the number of rules matters as in \fullref{alg:brute_force_parsing}.
  \end{thmenum}
\end{example}

\begin{proposition}\label{thm:context_free_languages_are_conext_sensitive}
  \hyperref[def:chomsky_hierarchy/context_free]{Context-free} \hi{languages} are \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive}.
\end{proposition}
\begin{proof}
  \Fullref{alg:epsilon_rule_removal} shows that every context-free grammar can be converted to another context-free grammar that is also context-sensitive.
\end{proof}

\begin{algorithm}[Renaming rule collapse]\label{alg:renaming_rule_collapse}
  Fix an \hyperref[def:epsilon_free_grammar]{essentially \( \varepsilon \)-free} \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar \( G = (V, \Sigma, \to, S) \). We will build an \hyperref[def:formal_grammar/equivalent]{equivalent} context-free grammar \( G' = (V, \Sigma, \to', S) \) in which there are no rules of the form \( A \to B \). We call such rules \term{renaming rules}.

  Out goal is to \enquote{collapse} derivations like \( A \to B \to C \to w \) into \( A \to' w \).

  \begin{thmenum}
    \thmitem{alg:renaming_rule_collapse/rules} For every rule \( A \to w \), we define a \hyperref[def:function]{set-valued map} \( C(A \to w, U) \) whose values are words over \( V \cup \Sigma \). The parameter \( U \) is a set of non-terminals \enquote{already traversed} during recursion, we use it to avoid unbounded recursion like in the case of \( A \to B \to A \). Let
    \begin{equation*}
      C(A \to w, U) \coloneqq \begin{cases}
        \varnothing,                  &A \in U, \\
        C(B \to v, U \cup \set{ A }), &w = B \T{and} B \to v, \\
        \set{ v },                    &\T{otherwise.}
      \end{cases}
    \end{equation*}

    \thmitem{alg:renaming_rule_collapse/new_grammar} Let \( A \to' v \) hold if and only if \( v \in C(A \to w, \varnothing) \) for some rule \( A \to w \).
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \texttt{grammars.renaming\_rules.collapse\_renaming\_rules} in \cite{code}.
\end{comments}

\begin{definition}\label{def:reverse_grammar}\mcite[17]{Salomaa1987}
  We define the \term{reverse grammar} of the \hyperref[def:chomsky_hierarchy/context_free]{context-free} \( G = (V, \Sigma, \to, S) \) as
  \begin{equation*}
    \op{rev}(G) \coloneqq (V, \Sigma, \to_{\op{rev}}, S),
  \end{equation*}
  where
  \begin{equation*}
    A \to_{\op{rev}} \op{rev}(w) \T{if} A \to w.
  \end{equation*}
\end{definition}
\begin{comments}
  \item For example, the rule \( A \to Ba_1 \cdots a_n \) becomes \( A \to_{\op{rev}} a_n \cdots a_1 B \).
\end{comments}

\begin{proposition}\label{thm:reverse_linear_grammar}
  The \hyperref[def:reverse_grammar]{reverse} of a \hyperref[def:chomsky_hierarchy/regular]{left-linear grammar} is \hyperref[def:chomsky_hierarchy/regular]{right-linear} and vice versa.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{proposition}\label{thm:reverse_grammar_language}
  For a given \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar \( G = (V, \Sigma, \to, S) \), we have
  \begin{equation*}
    \mscrL(\op{rev}(G)) = \op{rev}(\mscrL(G)).
  \end{equation*}
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{algorithm}[Finite automaton from regular grammar]\label{alg:finite_automaton_from_regular_grammar}
  Let \( G = (V, \Sigma, \to, S) \) be a \hyperref[def:chomsky_hierarchy/regular]{regular grammar}. We will construct a \hyperref[def:finite_automaton]{finite automaton} that \hyperref[def:finite_automaton/language]{accepts} \( \mscrL(G) \).

  \begin{thmenum}
    \thmitem{alg:finite_automaton_from_regular_grammar/init} Let \( G_1 = (V, \Sigma, \to_1, S) \) be \( G_1 \) if it is right-linear and \( \op{rev}(G) \) if it is left-linear. Then \( G_1 \) is necessarily right-linear.

    \thmitem{alg:finite_automaton_from_regular_grammar/epsilon} Let \( G_2 = (V_2, \Sigma, \to_2, S_2) \) be the grammar obtained from \( G_1 \) by removing \( \varepsilon \)-rules via \Fullref{alg:epsilon_rule_removal}.

    \thmitem{alg:finite_automaton_from_regular_grammar/collapse} Let \( G_3 = (V_2, \Sigma, \to_3, S_2) \) be the grammar obtained from \( G_2 \) by collapsing renaming rules via \fullref{alg:renaming_rule_collapse}.

    \thmitem{alg:finite_automaton_from_regular_grammar/intermediate} Build another intermediate grammar \( G_4 = (V_4, \Sigma, \to_4, S_2) \) by replacing
    \begin{itemize}
      \item each rule \( A \to_3 w \), \( w = a_1 \cdots a_n \), with a sequence of rules
      \begin{align*}
        A       &\to_4 a_1 A_1, \\
        A_1     &\to_4 a_2 A_2, \\
                &\vdots \\
        A_{n-1} &\to_4 a_n,
      \end{align*}
      where \( A_1, \ldots, A_{n-1} \) are new non-terminals.

      \item each rule \( A \to_3 wB \), \( \len(w) > 0 \), with a similar sequence, but the last rule being \( A_{n-1} \to_4 a_n B \).
    \end{itemize}

    Thus, every rule in \( G_4 \) has one of the forms \( A \to_4 a \) or \( A \to_4 a B \) or \( A \to_4 B \).

    \thmitem{alg:finite_automaton_from_regular_grammar/automaton}\mcite[thm. 4.10.1]{Savage1998} Let \( F \) be some new non-terminal symbol. Then the following is a finite automaton that accepts \( \mscrL(G_4) \), and hence also \( G_2 \) and \( G_1 \):
    \begin{itemize}
      \item \( \Sigma \) is the alphabet.
      \item \( V_4 \cup \set{ F } \) is the set of states.
      \item \( S_2 \) the only starting state.
      \item \( F \) is a final state. \( S_2 \) is also a final state if \( \varepsilon \in \mscrL(G) \).
      \item Add the following transitions:
      \begin{itemize}
        \item \( \delta(A, a) \coloneqq F \) if \( A \to_4 a \).
        \item \( \delta(A, a) \coloneqq B \) if \( A \to_4 aB \).
      \end{itemize}
    \end{itemize}

    \thmitem{alg:finite_automaton_from_regular_grammar/reverse} If \( G \) is right-linear, then \( F \) is the desired automaton because
    \begin{equation*}
      \mscrL(F) = \mscrL(G) = \mscrL(G_4).
    \end{equation*}

    Otherwise, we take the \hyperref[def:reverse_finite_automaton]{reverse automaton} \( \op{rev}(F) \) because
    \begin{equation*}
      \mscrL(\op{rev}(F))
      \reloset {\ref{thm:reverse_finite_automaton_language}} =
      \op{rev}(\mscrL(F))
      =
      \op{rev}(\mscrL(G_4))
      =
      \op{rev}(\mscrL(\op{rev}(G)))
      \reloset {\ref{thm:reverse_grammar_language}} =
      \op{rev}(\op{rev}(\mscrL(G)))
      \reloset {\ref{thm:reverse_language_involution}} =
      \mscrL(G).
    \end{equation*}
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \texttt{grammars.regular.to\_finite\_automaton} in \cite{code}.
\end{comments}

\begin{algorithm}[Right-linear grammar from finite automaton]\label{alg:right_linear_grammar_from_finite_automaton}\mcite[thm. 4.10.1]{Savage1998}
  Let \( F = (\Sigma, Q, \delta, I, T) \) be a \hyperref[def:finite_automaton]{finite automaton}. We will build a \hyperref[def:chomsky_hierarchy/regular]{right-linear grammar} \( G = (V, \Sigma, \to, S) \) that \hyperref[def:formal_grammar/language]{generates} \( \mscrL(F) \).

  \begin{thmenum}
    \thmitem{alg:right_linear_grammar_from_finite_automaton/determinize} Use \fullref{alg:determinization_of_finite_automata} to obtain a deterministic automaton \( \det(F) = (\Sigma, Q', \delta', \set{ I }, T') \) equivalent to \( F \).

    \thmitem{alg:right_linear_grammar_from_finite_automaton/grammar} The following describes the desired grammar:
    \begin{itemize}
      \item \( \Sigma \) is the set of terminals.
      \item \( Q' \) is the set of non-terminals.
      \item \( I \) is the starting non-terminal.
      \item The following are rules:
      \begin{itemize}
        \item \( A \to aB \) if \( \delta'(A, a) = B \).
        \item \( A \to \varepsilon \) for each terminal state \( A \in T' \).
      \end{itemize}
    \end{itemize}
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \texttt{grammars.regular.from\_finite\_automaton} in \cite{code}.
\end{comments}

\begin{proposition}\label{thm:regular_languages}
  The following are equivalent for a given \hyperref[def:formal_language/language]{language}:
  \begin{thmenum}
    \thmitem{thm:regular_languages/right} It is \hyperref[def:formal_grammar/language]{generated} by a \hyperref[def:chomsky_hierarchy/regular]{right-linear grammar}.
    \thmitem{thm:regular_languages/left} It is \hyperref[def:formal_grammar/language]{generated} by a \hyperref[def:chomsky_hierarchy/regular]{left-linear grammar}.
    \thmitem{thm:regular_languages/automata} It is \hyperref[def:finite_automaton/language]{recognized} by a \hyperref[def:finite_automaton]{finite automaton}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  \ImplicationSubProof{thm:regular_languages/right}{thm:regular_languages/left} Let \( G = (V, \Sigma, \to, S) \) be a right-regular grammar. We will describe a procedure for obtaining an equivalent left-regular grammar.

  \begin{itemize}
    \item \Fullref{alg:finite_automaton_from_regular_grammar} gives us a finite automaton \( F = (\Sigma, Q, \delta, \set{ S }, T) \) such that \( \mscrL(F) = \mscrL(G) \).

    \item Take the \hyperref[def:reverse_finite_automaton]{reverse automaton} \( \op{rev}(F) \) of \( F \).

    \item Determinize \( \op{rev}(F) \) via \fullref{alg:determinization_of_finite_automata}.

    \item Use \fullref{alg:right_linear_grammar_from_finite_automaton} to convert \( \det(\op{rev}(F)) \) to a right-regular grammar \( G' \). At this point, we have
    \begin{equation*}
      \mscrL(G')
      =
      \mscrL(\det(\op{rev}(F)))
      =
      \mscrL(\op{rev}(F))
      \reloset {\ref{thm:reverse_finite_automaton_language}} =
      \op{rev}(\mscrL(F)).
    \end{equation*}

    \item Finally, take the \hyperref[def:reverse_grammar]{reverse grammar} \( \op{rev}(G') \). It is a left-regular grammar as a consequence of \fullref{thm:reverse_linear_grammar}. Furthermore,
    \begin{equation*}
      \mscrL(\op{rev}(G'))
      \reloset {\ref{thm:reverse_grammar_language}} =
      \op{rev}(\mscrL(G'))
      =
      \op{rev}(\op{rev}(\mscrL(F)))
      \reloset {\ref{thm:reverse_language_involution}} =
      \mscrL(F).
    \end{equation*}

    Hence, \( \op{rev}(G') \) is the desired left-linear grammar.
  \end{itemize}

  \ImplicationSubProof{thm:regular_languages/left}{thm:regular_languages/automata} \Fullref{alg:finite_automaton_from_regular_grammar} allows us to convert every left-linear grammar to a finite automaton.

  \ImplicationSubProof{thm:regular_languages/automata}{thm:regular_languages/right} \Fullref{alg:right_linear_grammar_from_finite_automaton} allows us to convert every finite automaton to a right-linear grammar.
\end{proof}
