\section{Modules}\label{sec:modules}

\paragraph{Modules over rings}

\begin{definition}\label{def:module}\mcite[def. III.5.2]{Aluffi2009Algebra}
  A \term[bg=модул (\cite[27]{КоцевСидеров2016КомутативнаАлгебра}, ru=модуль (\cite[def. 9.3.1]{Винберг2014КурсАлгебры})]{module} is a \hyperref[def:semimodule]{semimodule} over a \hyperref[def:ring]{ring} rather than a \hyperref[def:semiring]{semiring}.

  This makes the identity law \eqref{eq:def:semimodule/operation/scalar_multiplication_action/identity} redundant.

  Modules have the following metamathematical properties:
  \begin{thmenum}
    \thmitem{def:module/theory}\mimprovised The first-order theory is identical to the \hyperref[def:semimodule/theory]{theory of semimodules}.

    \thmitem{def:module/homomorphism}\mcite[160]{Aluffi2009Algebra} A \hyperref[def:first_order_homomorphism]{first-order homomorphism} between two \( R \)-modules \( M \) and \( N \) is simply a \hyperref[def:linear_function]{linear map}.

    \thmitem{def:module/submodel}\mcite[162]{Aluffi2009Algebra} The set \( A \subseteq M \) is a \hyperref[def:first_order_submodel]{first-order submodel} of \( M \) if it is a sub-semimodule of \( M \), i.e. a subgroup of \( M \) that is closed under scalar multiplication. We say that \( A \) is an \( R \)-\term{submodule} of \( M \).

    As a consequence of \fullref{thm:positive_formulas_preserved_under_homomorphism}, the image of a module homomorphism is a submodule of its codomain.

    \thmitem{def:module/category}\mimprovised For a fixed ring \( R \), we denote the \hyperref[def:category_of_small_first_order_models]{category of \( \mscrU \)-small models} by \( \ucat{Mod}_R \).

    It is a very well-behaved category, even more than the category \hyperref[def:group/category]{\( \ucat{Grp} \)} of \( \mscrU \)-small groups.
    \begin{itemize}
      \item The trivial module \( \set{ 0 } \) is a zero object. Therefore, we can define kernels and cokernels, and cokernels for modules are particularly simple.

      \item The \hyperref[def:free_semimodule]{free semimodules} over a ring are modules, and \fullref{thm:free_semimodule_universal_property} ensures that this is left adjoint to the forgetful functor \( U: \ucat{Mod}_R \to \ucat{Set} \). Therefore, by \fullref{thm:first_order_categorical_invertibility}, the monomorphisms are exactly the injective homomorphisms, and that the \hyperref[def:subobject_and_quotient]{categorical subobjects} correspond to submodules.

      \item Every epimorphism in \( \ucat{Mod}_R \) is surjective. This will be proved in \fullref{thm:module_epimorphisms_are_surjective}. Along with \fullref{thm:surjective_group_homomorphisms_are_cokernels}, this shows that the \hyperref[def:subobject_and_quotient]{categorical quotient objects} correspond to \hyperref[def:module/quotient]{quotient modules}, which we will discuss shortly.
    \end{itemize}

    \thmitem{def:module/trivial}\mimprovised Any single-element \( R \)-module, that is, every zero object in \( \ucat{Mod}_R \), is as trivial object in the sense of \fullref{def:trivial_object}. We will call it \enquote{the} trivial \( R \)-module.

    \thmitem{def:module/kernel}\mimprovised \Fullref{thm:module_zero_morphisms/kernel} implies that the \hyperref[def:zero_morphisms/kernel]{categorical kernel} of an \( R \)-linear map \( \varphi: M \to N \) between \( R \)-modules is the additive group kernel
    \begin{equation*}
      \ker \varphi \coloneqq \varphi^{-1}(0_T) = \set{ x \in R \given \varphi(x) = 0_T }.
    \end{equation*}

    It is a submodule as a consequence of \fullref{thm:kernel_is_submodule}. It is also called the \term[ru=нуль-пространство (матрицы) (\cite[112]{Тыртышников2007ЛинейнаяАлгебра}), en=null space (\cite[67]{FriedbergInselSpence2018LinearAlgebra})]{null space} of \( \varphi \), especially for \hyperref[def:vector_space]{vector spaces}, where it is a linear subspace.

    \thmitem{def:module/quotient}\mimprovised Similarly to groups, \hyperref[def:first_order_congruence]{first-order congruences} for modules are well-behaved. \Fullref{thm:submodules_and_congruences} shows that congruences correspond exactly to submodules.

    \thmitem{def:module/bimodule}\mimprovised An \( (R, T) \)-\term{bimodule} is simply an \( (R, T) \)-\hyperref[def:semimodule/bisemimodule]{bisemimodule} over a ring.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:abelian_group_is_module}
  We have an \hyperref[rem:category_similarity/isomorphism]{isomorphism of categories} \( \hyperref[def:abelian_group]{\cat{Ab}} \cong \hyperref[def:module]{\cat{Mod}_\BbbZ} \).

  More concretely, every abelian group \( G \) is a left module over \( \BbbZ \) with scalar multiplication given by \hyperref[con:additive_semigroup/multiplication]{recursively defined multiplication}
  \begin{equation}\label{eq:thm:abelian_group_is_module/operation}
    \begin{aligned}
      &\cdot: \BbbZ \times G \to G \\
      &n \cdot x \coloneqq \begin{cases}
        0_G,           &n = 0, \\
        n \cdot x + x, &n > 1, \\
        -(n \cdot x),  &n < 1.
      \end{cases}
    \end{aligned}
  \end{equation}

  Conversely, in every module over \( \BbbZ \), scalar multiplication matches the recursively defined multiplication.
\end{proposition}
\begin{comments}
  \item This result specializes a more general statement for semimodules over semirings in \fullref{thm:commutative_monoid_is_semimodule} and specializes to the case for algebras and integers in \fullref{thm:ring_is_integer_algebra}.
\end{comments}
\begin{proof}
  Simple refinement of \fullref{thm:commutative_monoid_is_semimodule}.
\end{proof}

\paragraph{Module quotients}

\begin{proposition}\label{thm:submodules_and_congruences}
  Fix an \( R \)-\hyperref[def:module]{module} \( M \). \hyperref[def:first_order_congruence]{First order congruences} on \( M \) and \( R \)-\hyperref[def:module/submodel]{submodules} of \( M \) are related as follows:
  \begin{thmenum}
    \thmitem{thm:submodules_and_congruences/cong_to_submodule} For every congruence in \( M \), the coset \( [0] \) of the zero element is an \( R \)-submodule of \( M \).

    \thmitem{thm:submodules_and_congruences/submodule_to_cong} Conversely, for every \( R \)-submodule \( N \), the relation \( x \cong y \) defined to hold if \( x - y \) is in \( N \), is a congruence.

    \thmitem{thm:submodules_and_congruences/inverse} The procedures for obtaining a congruence from a two-sided submodule and vice versa are inverses.
  \end{thmenum}
\end{proposition}
\begin{comments}
  \item This allows us to consider the quotient \( M / N \) with respect to an \( R \)-submodule rather than \( M / {\cong} \) with respect to a congruence.

  \item This is based on a similar statement for \hyperref[def:group]{groups} --- see \fullref{thm:normal_subgroups_and_congruences}. Another similar statement holds for \hyperref[def:ring]{rings} --- see \fullref{thm:ideals_and_congruences}
\end{comments}
\begin{proof}
  \SubProofOf{thm:submodules_and_congruences/cong_to_submodule} Since module congruences are also congruences of the additive group, \fullref{thm:normal_subgroups_and_congruences/cong_to_subgroup} implies that \( [0] \) is a \hyperref[def:normal_subgroup]{normal subgroup} of the additive group of \( M \).

  \Fullref{def:semimodule/operation/absorption} implies that \( 0 \) absorbs scalars, i.e. \( r \cdot 0 = 0 \) for every \( r \) in \( R \), thus \( [0] \) is indeed an \( R \)-submodule.

  \SubProofOf{thm:submodules_and_congruences/submodule_to_cong} Similarly, since every \( R \)-submodule is a normal subgroup of the additive group, it follows from \fullref{thm:normal_subgroups_and_congruences/subgroup_to_cong} that \( {\cong} \) defined as \( x \cong y \) if \( x - y \in I \) is a congruence on the additive group.

  To show that it is an \( R \)-module congruence, we must show that \( x \cong y \) implies \( rx \cong ry \) every scalar \( r \in R \)\fnote{This is conceptually different from \fullref{thm:submodules_and_congruences/submodule_to_cong} because, in terms of first-order logic, we quantify by functional symbols rather than individuals}. This holds because of distributivity:
  \begin{equation*}
    rx - ry
    \reloset {\eqref{eq:def:semimodule/operation/vector_addition_distributivity}} =
    r(\underbrace{x - y}_{N}).
  \end{equation*}

  Since \( N \) is closed under scalar multiplication, we conclude that \( rx - ry \in N \) and hence \( rx \cong ry \).

  \SubProofOf{thm:submodules_and_congruences/inverse} This is a special case of \fullref{thm:normal_subgroups_and_congruences/inverse}.
\end{proof}

\begin{proposition}\label{thm:kernel_is_submodule}
  The \hyperref[def:module/kernel]{kernel} of an \( R \)-\hyperref[def:module/homomorphism]{linear map} is an \( R \)-submodule of its domain.
\end{proposition}
\begin{proof}
  Follows from \fullref{thm:kernel_is_normal_subgroup} and absorption.
\end{proof}

\begin{proposition}\label{thm:module_zero_morphisms}
  Let \( M \) and \( N \) be \( R \)-modules and let \( \varphi: M \to N \) be an \( R \)-\hyperref[def:module/homomorphism]{linear map}.

  \begin{thmenum}
    \thmitem{thm:module_zero_morphisms/kernel} The \hyperref[def:zero_morphisms/kernel]{categorical kernel} \( \ker \varphi \) of \( \varphi \) is the preimage of \( 0_N \).

    \thmitem{thm:module_zero_morphisms/cokernel} The \hyperref[def:zero_morphisms/kernel]{categorical cokernel} \( \co\ker \varphi \) of \( \varphi \) is the \hyperref[def:group/quotient]{quotient} of \( N \) by the the \hyperref[def:set_valued_map/image]{set-theoretic image} \( \varphi[M] \).

    \thmitem{thm:module_zero_morphisms/image} The \hyperref[def:zero_morphisms/image]{categorical image} \( \img \varphi \) of \( \varphi \) is the \hyperref[def:set_valued_map/image]{set-theoretic image} \( \varphi[M] \).

    \thmitem{thm:module_zero_morphisms/coimage} The \hyperref[def:zero_morphisms/coimage]{categorical coimage} of \( \varphi \) is the \hyperref[def:module/quotient]{quotient} of \( M \) by the \hyperref[def:module/kernel]{kernel} \( \ker \varphi \).

    \thmitem{thm:module_zero_morphisms/isomorphism} The image and coimage of \( \varphi \) are isomorphic via the following map:
    \begin{equation}\label{eq:thm:module_zero_morphisms/isomorphism}
      \begin{aligned}
        &\psi: M / \ker \varphi \to \img \varphi, \\
        &\psi(\pi(x)) \coloneqq \varphi(x).
      \end{aligned}
    \end{equation}
  \end{thmenum}
\end{proposition}
\begin{comments}
  \item This is based on a similar statement for \hyperref[def:group]{groups} --- see \fullref{thm:group_zero_morphisms}. Another similar statement holds for (nonunital) \hyperref[def:ring]{rings} --- see \fullref{thm:ring_zero_morphisms}.
\end{comments}
\begin{proof}
  \SubProofOf{thm:module_zero_morphisms/kernel} Follows from \fullref{thm:zero_morphisms_pointed/kernel}.
  \SubProofOf{thm:module_zero_morphisms/cokernel} Analogously to \fullref{thm:group_zero_morphisms/cokernel}, the statement follows from \fullref{thm:zero_morphisms_pointed/cokernel} by noting that \( \braket{ \varphi[A] } \) is the submodule whose congruence \( \cong \) satisfies \( y \cong 0_N \) if and only if \( y \in \varphi[M] \).

  \SubProofOf{thm:module_zero_morphisms/image} Follows from \fullref{thm:zero_morphisms_pointed/image}.
  \SubProofOf{thm:module_zero_morphisms/coimage} Analogously to \fullref{thm:group_zero_morphisms/coimage}, we conclude that the coimage, defined as the cokernel of the kernel of \( \varphi \), is the quotient of \( M \) by \( \ker \varphi \), the latter being a submodule as a consequence of \fullref{thm:kernel_is_ideal}.

  \SubProofOf{thm:module_zero_morphisms/isomorphism} \Fullref{thm:group_zero_morphisms/isomorphism} implies that \( \psi \) as defined in \eqref{eq:thm:module_zero_morphisms/isomorphism} is an isomorphism between the additive groups of \( R / \ker \varphi \) and \( \img \varphi \). Furthermore, \( \psi \) is a ring isomorphism because \( \varphi \) is.
\end{proof}

\begin{proposition}\label{thm:module_epimorphisms_are_surjective}
  Every \hyperref[def:morphism_invertibility/right_cancellative]{epimorphism} in \hyperref[def:group/category]{\( \cat{Mod}_R \)} is \hyperref[def:function_invertibility/surjective]{surjective}.
\end{proposition}
\begin{proof}
  Let \( \varphi: M \to N \) be an \( R \)-module epimorphism. Consider the canonical projection \( \pi: N \to N / \img \varphi \) and the parallel \hyperref[def:zero_morphisms/morphism]{zero morphism} \( z: N \to N / \img \varphi \). Clearly
  \begin{equation*}
    \pi \bincirc \varphi = z \bincirc \varphi.
  \end{equation*}

  Since \( \varphi \) is an epimorphism, it follows that \( \pi = z \). Thus, the image of \( \pi \) is trivial. But the image of \( \pi \) is the quotient \( N / \img \varphi \). \Fullref{thm:group_homomorphism_zero_cokernel} then implies that \( \varphi \) is surjective.
\end{proof}

\begin{theorem}[Lattice theorem for submodules]\label{thm:lattice_theorem_for_submodules}
  Given an \( R \)-\hyperref[def:module/submodel]{submodule} \( N \) of the \( R \)-module \( M \), the function \( K \mapsto K / N \) is an \hyperref[def:lattice/homomorphism]{isomorphism of complete lattices} between the \hyperref[def:lattice_ideal/principal]{principal filter} of \( R \)-submodules of \( M \) containing \( N \) and the \hyperref[thm:semiring_of_ideals/lattice]{lattice of \( R \)-submodules} of the \hyperref[def:module/quotient]{quotient} \( M / N \).
\end{theorem}
\begin{comments}
  \item See \fullref{thm:lattice_theorem_for_substructures} for a very verbose formulation of this theorem in a general setting.

  \item This is based on a similar statement for \hyperref[def:group/submodel]{subgroups} --- see \fullref{thm:lattice_theorem_for_subgroups}. Another similar statement holds for \hyperref[def:ring]{ring} \hyperref[def:semiring_ideal]{ideals} --- see \fullref{thm:lattice_theorem_for_ideals}.
\end{comments}
\begin{proof}
  Fix an \( R \)-submodule \( N \) of \( M \) and let \( x \cong y \) if \( x - y \) is in \( N \).

  Note that every \( R \)-submodule of \( M \) is a subgroup of (the additive group of) \( M \) and that \( {\cong} \) is also a congruence on the additive group of \( M \). \Fullref{thm:lattice_theorem_for_subgroups} allows us to conclude that the \( R \)-submodule \( K \) of \( N \) contains \( N \) if and only if it is compatible with \( {\cong} \).

  The lattice isomorphism then follows from \fullref{thm:lattice_theorem_for_substructures}.
\end{proof}

\paragraph{Linear dependence}

\begin{definition}\label{def:linear_dependence}\mimprovised
  Let \( M \) be an \( R \)-\hyperref[def:module]{module} and fix a subset \( E \subseteq M \). We say that the elements of \( E \) are \term[bg=линейно независими (вектори) (\cite[94]{Обрешков1962ВисшаАлгебра}), ru=линейно независимые (векторы) (\cite[\S 3.4]{Тыртышников2007ЛинейнаяАлгебра}), en=linearly independent (indexed set) (\cite[def. VI.1.1]{Aluffi2009Algebra})]{linearly independent} if any of the following conditions hold:

  \begin{thmenum}
    \thmitem{def:linear_dependence/direct}\mcite[307]{Aluffi2009Algebra} A \hyperref[def:linear_combination]{linear combination} in \( E \) sums to zero if and only if it is \hyperref[def:free_semimodule]{trivial}.

    \thmitem{def:linear_dependence/evaluation}\mcite[def. VI.1.1]{Aluffi2009Algebra} The \hyperref[thm:free_semimodule_universal_property]{linear combination evaluation map}
    \begin{equation*}
      \begin{aligned}
        &\Phi_E: R^{\oplus E} \to M, \\
        &\Phi_E( \seq{ t_e }_{e \in E} ) \coloneqq \sum_{e \in E} t_e e
      \end{aligned}
    \end{equation*}
    is \hyperref[def:function_invertibility/injective]{injective}.
  \end{thmenum}

  Unsurprisingly, if the elements of \( E \) are not linearly independent, we say that they are \term{linearly dependent}.
\end{definition}
\begin{comments}
  \item Compare this concept to algebraic dependence defined in \fullref{def:algebraic_dependence}.
\end{comments}
\begin{defproof}
  \ImplicationSubProof{def:linear_dependence/direct}{def:linear_dependence/evaluation} Suppose that only the trivial linear combination of \( E \) sums to zero. If \( \sum_{e \in E} t_e e = \sum_{e \in E} r_e e \), then
  \begin{equation*}
    \sum_{e \in E} t_e e - \sum_{e \in E} r_e e
    \reloset {\eqref{eq:def:semiring/left_distributivity}} =
    \sum_{e \in E} (t_e - r_e) e
    =
    0_M,
  \end{equation*}
  implying that \( t_e = r_e \) for every \( e \in E \).

  Hence, \( \Phi_E \) is injective.

  \ImplicationSubProof{def:linear_dependence/evaluation}{def:linear_dependence/direct} Trivial.
\end{defproof}

\begin{proposition}\label{thm:def:linear_dependence}
  \hyperref[def:linear_dependence]{Linear (in)dependence} in an \( R \)-module \( M \) has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:linear_dependence/empty} The empty set is linearly independent.

    \thmitem{thm:def:linear_dependence/zero} The zero vector \( 0_M \) is by itself linearly dependent.

    \thmitem{thm:def:linear_dependence/monotonicity} If \( E \) is a linearly \hi{dependent} set and \( E \subseteq F \), then \( F \) is also a linearly dependent set.

    \thmitem{thm:def:linear_dependence/antimonotonicity} If \( F \) is a linearly \hi{independent} set and \( E \subseteq F \), then \( E \) is also a linearly independent set.

    \thmitem{thm:def:linear_dependence/dependent_combination} The set \( E \cup \set{ x } \) is linearly dependent if and only if \( x \in \linspan E \).

    \thmitem{thm:def:linear_dependence/span_dependent} For any set of vectors \( E \), if \( x \in (\linspan E) \setminus E \), then \( E \cup \set{ x } \) is a linearly dependent set.

    A partial converse is stated in \fullref{thm:def:vector_space/span_independent}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:linear_dependence/empty} The empty set cannot be linearly dependent because there are no possible linear combinations of its elements.

  \SubProofOf{thm:def:linear_dependence/zero} Trivial.

  \SubProofOf{thm:def:linear_dependence/monotonicity} Trivial.

  \SubProofOf{thm:def:linear_dependence/antimonotonicity} Trivial.

  \SubProofOf{thm:def:linear_dependence/span_dependent} By \fullref{thm:span_via_linear_combinations}, there exists a linear combination of members of \( E \) such that
  \begin{equation*}
    x = \sum_{k=1}^n t_k x_k.
  \end{equation*}

  If \( x = 0_M \), then \( E \cup \set{ x } \) is linearly dependent by \fullref{thm:def:linear_dependence/zero} and \fullref{thm:def:linear_dependence/monotonicity}.

  If \( x \neq 0_M \), then \( E \cup \set{ x } \) is linearly dependent because \( x \) is a nontrivial linear combination of other vectors of \( E \).
\end{proof}

\begin{example}\label{ex:def:linear_dependence}
  We list several (counter)examples for \hyperref[def:linear_dependence]{linear (in)dependence}:
  \begin{thmenum}
    \thmitem{ex:def:linear_dependence/irrational_numbers} Like all concepts related to \hyperref[def:linear_combination]{linear combinations}, linear dependence may behave differently depending on the underlying ring. For example, every irrational number is a linear combination of itself, but it is not a linear combination of rational numbers.

    For simplicity, we will not specify the ring explicitly unless this may cause confusion.

    \thmitem{ex:def:linear_dependence/unit_matrix_columns} We have
    \begin{equation*}
      2 \cdot
      \begin{pmatrix}
        1 \\ 3
      \end{pmatrix}
      =
      \begin{pmatrix}
        2 \\ 0
      \end{pmatrix}
      +
      3 \cdot
      \begin{pmatrix}
        0 \\ 2
      \end{pmatrix}
    \end{equation*}

    Thus, the three column vectors are linearly dependent.

    The above equality holds for matrices over any ring, however only if \( 2 \) is invertible we can express the first vector via the others:
    \begin{equation*}
      \begin{pmatrix}
        1 \\ 3
      \end{pmatrix}
      =
      \frac 1 2 \cdot
      \begin{pmatrix}
        2 \\ 0
      \end{pmatrix}
      +
      \frac 3 2 \cdot
      \begin{pmatrix}
        0 \\ 2
      \end{pmatrix}
    \end{equation*}
  \end{thmenum}
\end{example}

\paragraph{Hamel bases}

\begin{definition}\label{def:hamel_basis}\mimprovised
  Let \( M \) be a left \hyperref[def:module]{\( R \)-module} and fix a subset \( E \subseteq M \). We say that \( E \) is a \term{Hamel basis} or simply \term[bg=базис (\cite[100]{Обрешков1962ВисшаАлгебра}), ru=базис (\cite[\S 3.7]{Тыртышников2007ЛинейнаяАлгебра}), en=Hamel basis (\cite[example B-2.12]{Rotman2015AdvancedModernAlgebraPart1})]{basis} of \( M \) if any of the following equivalent conditions hold:

  \begin{thmenum}
    \thmitem{def:hamel_basis/independent}\mcite[307]{Aluffi2009Algebra} It is a \hyperref[thm:span_via_linear_combinations]{spanning set} of \hyperref[def:linear_dependence]{linearly independent} elements.

    \thmitem{def:hamel_basis/evaluation}\mcite[lemma VI.1.5]{Aluffi2009Algebra} The \hyperref[thm:free_semimodule_universal_property]{free semimodule evaluation map} is \hyperref[def:function_invertibility/bijective]{bijective}.

    \thmitem{def:hamel_basis/free} \( M \) is \hyperref[def:linear_function]{linearly isomorphic} to the \hyperref[def:free_semimodule]{free module} \( R^{\oplus E} \).
  \end{thmenum}
\end{definition}
\begin{comments}
  \item In relation to \fullref{def:hamel_basis/free}, we may refer to \( M \) itself is a free module.
\end{comments}
\begin{defproof}
  \ImplicationSubProof{def:hamel_basis/independent}{def:hamel_basis/evaluation} Suppose that \( E \) is a spanning set of linearly independent elements.

  \Fullref{def:linear_dependence/evaluation} is satisfied, hence the evaluation map is injective.

  Furthermore, \( E \) is spanning, meaning that \( \linspan E = M \). Hence, the evaluation map is also surjective.

  \ImplicationSubProof{def:hamel_basis/evaluation}{def:hamel_basis/free} If the evaluation map is bijective, it is itself a linear isomorphism.

  \ImplicationSubProof{def:hamel_basis/free}{def:hamel_basis/independent} Suppose that \( \Psi: R^{\oplus E} \to M \) is a linear isomorphism. By \fullref{def:linear_dependence/evaluation}, \( \Psi \) is surjective, and hence a spanning set of \( M \). Furthermore, it satisfies \fullref{def:linear_dependence/evaluation}, meaning that \( E \) is a linearly independent set.
\end{defproof}

\begin{remark}\label{rem:free_module}
  After discussing \hyperref[con:free_construction]{free constructions} in generality, and directly after showing that an \hyperref[def:module]{\( R \)-module} with a \hyperref[def:hamel_basis]{Hamel basis} \( \set{ e_1, \ldots, e_n } \)  is isomorphic to the \hyperref[def:free_semimodule]{free semimodule} \( R^n \), Nathan Jacobson writes in \cite[171]{Jacobson1985BasicAlgebraI} the following:
  \begin{displayquote}
    We have therefore shown that the existence of a base of \( n \) elements for a module \( M \) implies that \( M \cong R^{(n)} \). In this case we shall say that \( M \) is a \textit{free \( R \)-module of rank \( n \)}.
  \end{displayquote}

  We generalize this to \hyperref[con:transfinite]{transfinite} bases --- we will refer to any module with a basis as \enquote{free} since choosing a Hamel basis \( E \) for \( M \) gives us an explicit isomorphism from \( M \) to \( R^{\oplus E} \). This is in line with the \hyperref[con:univalence_principle]{univalence principle}, which, as stated in \Fullref{rem:free_construction_univalence}, leads to the practice of identifying isomorphic objects.

  We will define the rank of a free module in \fullref{def:module_rank}, after proving some coherence results.
\end{remark}
\begin{comments}
  \item The above convention is also used by other authors. A \enquote{free \( R \)-module} with basis \( E \) is defined as a module isomorphic to \( R^{\oplus A} \) by
  \incite[def. II.1.10]{Bourbaki1998Algebra1to3},
  \incite[135]{Lang2002Algebra},
  \incite[329]{Rotman2015AdvancedModernAlgebraPart1},
  \incite[169]{Aluffi2009Algebra},
  \incite[405]{Knapp2016BasicAlgebra} and
  \incite[47]{Шафаревич1999ОсновныеПонятияАлгебры}.
\end{comments}

\begin{example}\label{ex:def:hamel_basis}
  We list examples of \hyperref[def:hamel_basis]{Hamel bases}:
  \begin{thmenum}
    \thmitem{ex:def:hamel_basis/euclidean_space} The canonical example of a basis is the following set of column vectors of the \hyperref[eq:thm:matrix_algebra/matrix_multiplication/identity]{identity matrix} in the \hyperref[def:euclidean_space]{Euclidean space} \( \BbbR^n \), that is, the vectors
    \begin{equation*}
      \begin{pmatrix}
        1 \\ 0 \\ \ldots \\ 0 \\ 0
      \end{pmatrix}
      ,
      \begin{pmatrix}
        0 \\ 1 \\ \ldots \\ 0 \\ 0
      \end{pmatrix}
      ,
      \cdots
      ,
      \begin{pmatrix}
        0 \\ 0 \\ \ldots \\ 0 \\ 1
      \end{pmatrix}
    \end{equation*}

    \thmitem{ex:def:hamel_basis/polynomial_ring} In \fullref{def:polynomial_algebra}, we have defined a polynomial as a \hyperref[def:free_semimodule]{free \( R \)-module} over the set of all monomials.

    Hence, for a nontrivial commutative ring \( R \) and for indeterminates \( \mscrX \), the set
    \begin{equation*}
      \set*{ X_1 \cdots X_n \given X_1, \ldots, X_n \in \mscrX }
    \end{equation*}
    of all monomials is a \hyperref[def:hamel_basis]{basis} for \hyperref[def:polynomial_algebra]{polynomial ring} \( R[\mscrX] \).

    \thmitem{ex:def:hamel_basis/module_without_basis} As a \hyperref[thm:abelian_group_is_module]{\( \BbbZ \)-module}, the additive group of \( \BbbQ \) has no basis.

    Indeed, given any two rational numbers \( a / b \) and \( c / d \), we have
    \begin{equation*}
      cb \cdot \frac a b + (-da) \cdot \frac c d = 0.
    \end{equation*}

    Therefore, only singleton sets of rational numbers are linearly independent with respect to \( \BbbZ \). But no single integer generates \( \BbbQ \).
  \end{thmenum}
\end{example}

\begin{proposition}\label{thm:def:hamel_basis}
  \hyperref[def:hamel_basis]{Bases} of the \( R \)-module \( M \) have the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:hamel_basis/span} Every \hyperref[def:linear_dependence]{linearly independent} subset of \( M \) is a basis for its \hyperref[def:semimodule/submodel]{linear span}.

    \thmitem{thm:def:hamel_basis/maximal_independent} Every basis of \( M \) is maximal among \hyperref[thm:def:linear_dependence]{linearly independent} sets.

    The converse holds for vector spaces --- see \fullref{thm:def:vector_space/minimal_spanning}.

    \thmitem{thm:def:hamel_basis/minimal_spanning} Every basis of \( M \) is minimal among spanning sets.

    The converse holds for vector spaces --- see \fullref{thm:def:vector_space/minimal_spanning}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:hamel_basis/span} Trivial.

  \SubProofOf{thm:def:hamel_basis/maximal_independent} Follows from \fullref{thm:def:linear_dependence/span_dependent}.

  \SubProofOf{thm:def:hamel_basis/minimal_spanning} Let \( E \) be a basis of \( M \) and suppose that \( F \subsetneq E \) is also a spanning set of \( M \).

  Then there exists some vector \( x \in E \setminus F \). Since both sets are spanning, \( \linspan F = \linspan E \). By \fullref{thm:def:linear_dependence/span_dependent}, \( F \cup \set{ x } \) is linearly dependent, and by \fullref{thm:def:linear_dependence/antimonotonicity}, \( E \) is linearly dependent. This contradicts the assumption that \( E \) has a basis.

  Therefore, no proper subset of \( E \) is spanning for \( M \).
\end{proof}

\begin{proposition}\label{thm:basis_of_direct_sum}
  Consider the family of \( R \)-modules \( \seq{ M_k }_{k \in \mscrK} \). Suppose that \( \seq{ E_k }_{k \in \mscrK} \) are bases of the corresponding modules. Then the set
  \begin{equation*}
    E \coloneqq \bigcup_{k \in \mscrK} E_k
  \end{equation*}
  is a basis for the \hyperref[def:semimodule_direct_sum]{direct sum}
  \begin{equation*}
    \bigoplus_{k \in \mscrK} M_k.
  \end{equation*}
\end{proposition}
\begin{proof}
  Regard \( M_k \) as a subspace of the direct sum. The subspaces \( M_k \) and \( M_n \) are disjoint for \( k \neq n \). Thus, every vector from \( M \) is a unique sum of vectors from the subspaces.

  Since, for every \( k \in \mscrK \), every vector from \( M_k \) can further be uniquely represented as a linear combination of vectors from \( E_k \), we conclude that every vector from the direct sum is a linear combination of vectors from \( E \).
\end{proof}

\begin{definition}\label{def:basis_decomposition}\mimprovised
  If \( E \) is a basis of the \( R \)-\hyperref[def:module]{module} \( M \), the inverse of the linear isomorphism from \fullref{def:hamel_basis/evaluation} is
  \begin{equation*}
    \begin{aligned}
      &\pi_E: M \to R^{\oplus E} \\
      &\pi_E\parens[\Big]{ \sum_{e \in E} t_e \cdot e } \coloneqq \seq{ t_e }_{e \in E}.
    \end{aligned}
  \end{equation*}

  We denote the \( e \)-th component of this function by \( \pi_e: M \to R \). This is a linear map, which we call the \term{coordinate projection} onto \( e \).

  For every vector \( x \) in \( M \), we thus have
  \begin{equation*}
    x = \sum_{e \in E} \pi_e(x) \cdot e.
  \end{equation*}

  This linear combination is unique, and we call it the \term[ru=разложение по базису (\cite[sec. 12.1]{Тыртышников2007ЛинейнаяАлгебра})]{basis decomposition} of \( x \) along \( E \).
\end{definition}
\begin{comments}
  \item As in \fullref{def:linear_combination}, we sometimes take only the basis vectors with nonzero coefficients as \enquote{the} decomposition.
\end{comments}
\begin{defproof}
  The decomposition is indeed unique --- if
  \begin{equation*}
    x = \sum_{e \in E} t_e e = \sum_{e \in E} r_e e,
  \end{equation*}
  then
  \begin{equation*}
    \sum_{e \in E} (t_e - r_e) e = 0_M.
  \end{equation*}

  Since \( E \) is a basis, it is linearly independent and hence \( t_e = r_e \) for all \( e \) in \( E \).
\end{defproof}

\begin{proposition}\label{thm:basis_projection_orthonormal}
  Let \( E \) be a \hyperref[def:hamel_basis]{Hamel basis} of the \hyperref[rem:free_module]{free} \hyperref[def:module]{\( R \)-module} \( M \). Then the \hyperref[def:basis_decomposition]{projection functionals} satisfy:
  \begin{thmenum}
    \thmitem{thm:basis_projection_orthonormal/one} \( \pi_e(e) = 1 \) for every basis vector \( e \) in \( E \).
    \thmitem{thm:basis_projection_orthonormal/zero} \( \pi_e(f) = 0 \) for every pair of distinct basis vectors \( e \) and \( f \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  We have
  \begin{equation*}
    f = \sum_{e \in B} \pi_e(f) \cdot e.
  \end{equation*}

  Thus,
  \begin{equation*}
    0 = f - \sum_{e \in B} \pi_e(f) \cdot e = (1 - \pi_f(f)) \cdot f - \sum_{e \in E \setminus \set{ f }} \pi_e(f).
  \end{equation*}

  Since the vectors in \( E \) are linearly independent, \( \pi_f(f) = 1 \) and \( \pi_e(f) = 0 \) for \( e \in E \).
\end{proof}

\begin{definition}\label{def:sequence_space}\mimprovised
  Let \( R \) be a \hyperref[def:ring/commutative]{commutative ring} and let \( \alpha \) be either a finite \hyperref[def:ordinal]{ordinal} or the \hyperref[thm:omega_is_an_ordinal]{smallest infinite ordinal} \( \omega \). Following \fullref{rem:lemniscate_symbol}, we will use the symbol \( \infty \) rather than \( \omega \).

  We call the \hyperref[def:free_semimodule]{free module} \( R^\alpha \) a \term[ru=координатное пространство (\cite[443]{ИльинСадовничийСендов1985АнализТом1}), en=coordinate space (\cite[rem. 2.8]{Treil2017LinearAlgebraDoneWrong})]{coordinate space} if \( \alpha \) is finite and \term[ru=пространство последовательностей (вещественных чисел) (\cite[452]{Фихтенгольц1968ОсновыАнализаТом2}), en=sequence space (\cite[example 1.1.4]{Roman2005AdvancedLinearAlgebra})]{sequence space} if \( \alpha = \infty \).

  The \term{standard basis} of the \( R^\alpha \) is the \hyperref[def:transfinite_sequence]{transfinite sequence} \( \seq{ e_i }_{j < \alpha} \) whose \hyperref[def:basis_decomposition]{projection maps} satisfy \( \pi_i(e_i) \) for every \( i < \alpha \) and \( \pi_i(e_j) = 1 \) for \( i \neq j \).

  When \( \alpha \) is finite, the vectors in \( R^\alpha \) are \hyperref[def:sequence]{finite sequences}, and we often conflate them with \hyperref[def:array/column_vector]{column vectors} or, less often, \hyperref[def:array/row_vector]{row vectors}.
\end{definition}
\begin{comments}
  \item See \fullref{rem:vector_etymology} for a more detailed discussion of terminology for vectors.
  \item When \( \alpha = \omega \), we conflate the vectors with (infinite) \hyperref[def:sequence]{sequences}.
\end{comments}

\paragraph{Torsion}

\begin{definition}\label{def:module_torsion}\mcite[def. VI.4.1]{Aluffi2009Algebra}
  We say that the vector \( x \) in an \hyperref[def:module]{\( R \)-module} is a \term[ru=элемент кручения (\cite[57]{Шафаревич1999ОсновныеПонятияАлгебры})]{torsion element} if there exists some nonzero scalar \( t \) such that \( tx \) is the zero vector. A module without torsion elements is called \term{torsion-free}.
\end{definition}

\begin{example}\label{ex:def:module_torsion}
  We list examples of \hyperref[def:module_torsion]{torsion elements}:
  \begin{thmenum}
    \thmitem{ex:def:module_torsion/scalars} When regarded as a module over itself, every zero divisor of a ring is a torsion element. For example, in \( \BbbZ_6 \),
    \begin{equation*}
      2 \cdot 3 = 3 \cdot 2 = 0 \pmod 6,
    \end{equation*}
    hence both \( 2 \) and \( 3 \) are torsion elements.

    \thmitem{ex:def:module_torsion/matrices} The matrix
    \begin{equation*}
      \begin{pmatrix}
        2 & 0 \\
        0 & 4
      \end{pmatrix}
    \end{equation*}
    is a torsion element of the \hyperref[thm:matrix_algebra]{matrix algebra} \( \BbbZ_6^{2 \times 2} \) because
    \begin{equation*}
      3 \cdot 2 = 3 \cdot 4 = 0 \pmod 6.
    \end{equation*}
  \end{thmenum}
\end{example}

\begin{proposition}\label{thm:basis_implies_torsion_free}
  A \hyperref[rem:free_module]{free module}, it is \hyperref[def:module_torsion]{torsion-free}.
\end{proposition}
\begin{proof}
  Let \( E \) be a basis of the \( R \)-module \( M \).

  Suppose that \( tx \) for some nonzero scalar \( t \) and nonzero vector \( x \). Then the basis decomposition
  \begin{equation*}
    x = \sum_{e \in E} \pi_e(x) \cdot e
  \end{equation*}
  is a nontrivial linear combination that sums to zero.

  This contradicts the assumption that \( E \) is a basis, hence \( x \) cannot be a torsion element.
\end{proof}

\paragraph{Vector spaces}

\begin{definition}\label{def:vector_space}\mcite[def. III.5.5]{Aluffi2009Algebra}
  A \term[ru=линейно пространство (\cite[111]{Обрешков1962ВисшаАлгебра}), ru=векторное/линейное пространство (\cite[def. 1.6.1]{Винберг2014КурсАлгебры})]{vector space} is a \hyperref[def:module]{left module} over a \hyperref[def:field]{field}.

  We denote the category of vector spaces over \( \BbbK \) by \( \cat{Vect}_{\BbbK} \).
\end{definition}
\begin{comments}
  \item Because a field is a commutative ring, we may just as well define a vector space as a right module.
\end{comments}

\begin{proposition}\label{thm:def:vector_space}
  The \hyperref[def:vector_space]{vector space} \( V \) over \( \BbbK \) has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:vector_space/span_independent} For a linearly independent set \( A \), if \( x \in V \setminus \linspan A \), then \( A \cup \set{ x } \) is also a linearly independent set.

    A more general converse holds in \fullref{thm:def:linear_dependence/span_dependent}.

    \thmitem{thm:def:vector_space/maximal_independent} Every maximally \hyperref[thm:def:linear_dependence]{linearly independent} subset of \( V \) is a basis.

    The converse holds more generally --- see \fullref{thm:def:hamel_basis/maximal_independent}.

    \thmitem{thm:def:vector_space/minimal_spanning} Every minimal spanning subset of \( V \) is a basis.

    The converse holds more generally --- see \fullref{thm:def:hamel_basis/minimal_spanning}.

    \thmitem{thm:def:vector_space/expansion} Given a subspace \( U \) of \( V \), if \( A \) is a finite basis of \( U \) and if \( V \) has a finite basis, then we can extend \( A \) to a finite basis of \( V \). More precisely, there exists a finite basis \( E \) of \( V \) such that \( A \subseteq E \).

    \thmitem{thm:def:vector_space/dimension_lemma} If \( \linspan\set{ a_1, \ldots, a_n } \subseteq \linspan\set{ b_1, \ldots, b_m } \), then \( n \leq m \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:vector_space/span_independent} Suppose that \( x \in V \setminus \linspan A \) and that \( A \cup \set{ x } \) is linearly dependent, Then there exist coefficients \( t_0, t_1, \ldots, t_n \) such that
  \begin{equation*}
    t_0 x + \sum_{k=1}^n t_k a_k = 0_M.
  \end{equation*}

  If \( t_0 = 0_\BbbK \), then \( \sum_{k=1}^n t_k a_k \in \linspan A \) and thus \( t_1 = \cdots = t_n = 0_\BbbK \).

  Otherwise, we can divide by \( t_0 \) to obtain
  \begin{equation*}
    x = -\sum_{k=1}^n \frac {t_k} {t_0} a_k,
  \end{equation*}
  which implies that \( x \in \linspan A \), contradicting our choice of \( x \).

  Therefore, \( A \cup \set{ x } \) satisfies \fullref{def:linear_dependence}.

  \SubProofOf{thm:def:vector_space/maximal_independent} Let \( A \) be a maximally linearly independent set.

  Suppose that it is not a spanning set and let \( x \in V \setminus \linspan A \). By \fullref{thm:def:vector_space/span_independent}, the set \( A \cup \set{ x } \) is linearly independent, contradicting the maximality of \( A \).

  Therefore, \( A \) is a spanning set for \( V \).

  \SubProofOf{thm:def:vector_space/minimal_spanning} Let \( A \) be a minimal spanning set. Suppose that it is linearly dependent. Then there exist distinct vectors \( x_1, \ldots, x_n \) in \( A \) and scalars \( t_1, \ldots, t_n \), at least one of which is nonzero, such that
  \begin{equation*}
    \sum_{k=1}^n t_k x_k = 0_M.
  \end{equation*}

  Let \( k_0 \) be the smallest index such that \( t_{k_0} \neq 0_R \). Then
  \begin{equation*}
    x_{k_0} = -\sum_{k \neq k_0} \frac {t_k} {t_{k_0}} a_k.
  \end{equation*}

  Then \( \linspan A = \linspan A \setminus \set{ x_{k_0} } \), contradicting the minimality of \( A \).

  \SubProofOf{thm:def:vector_space/expansion} Let \( a_1, \ldots, a_n \) be a basis of \( U \) and let \( b_1, \ldots, b_m \) be a basis of \( V \).

  We use recursion on \( k \leq n \) to build linearly independent sets of the form
  \begin{equation*}
    \set{ a_1, \ldots, a_n, b_{i_1}, \ldots, b_{i_k} },
  \end{equation*}
  at least one of which will be a basis.

  The base case \( k = 0 \) is vacuous. Now suppose that the vectors \( a_1, \ldots, a_n, b_{i_1}, \ldots, b_{i_k} \) are linearly independent. If there exists an index \( i_{k+1} \) distinct from \( i_1, \ldots, i_k \) such that \( b_{i_{k+1}} \) is not in
  \begin{equation*}
    L_k \coloneqq \linspan\set{ a_1, \ldots, a_n, b_{i_1}, \ldots, b_{i_k} },
  \end{equation*}
  then, by \fullref{thm:def:vector_space/span_independent}, the vectors \( a_1, \ldots, a_n, b_{i_1}, \ldots, b_{i_k} \) are linearly independent. Otherwise, every basis vector \( b_1, \ldots, b_n \) belongs to \( L_k \), hence it is a spanning set of \( V \) of linearly independent vectors.

  Since the basis \( b_1, \ldots, b_n \) of \( V \) necessarily belongs to \( L_n \), it follows that \( L_k \) will be a basis of \( V \) for some \( k \leq n \).

  \SubProofOf{thm:def:vector_space/dimension_lemma} We will use induction on \( n \). The base case \( n = 0 \) holds because \( \set{ 0_V } \) is the only submodule of the linear span of zero vectors.

  Suppose that the statement holds for \( n - 1 \) and note that \( b_m \) can be \hyperref[def:basis_decomposition]{decomposed} as
  \begin{equation*}
    b_m = \sum_{k=1}^n t_k a_k.
  \end{equation*}

  Then
  \begin{equation*}
    a_k = \frac 1 {t_{k_0}} b_m - \sum_{k \neq k_0} \frac {t_k} {t_{k_0}} a_{k_0}.
  \end{equation*}

  Thus,
  \begin{equation*}
    \linspan\set{ a_1, \ldots, a_n } = \linspan\set{ a_1, \ldots, a_{k_0 - 1}, a_{k_0 + 1}, \ldots, a_n, b_m }.
  \end{equation*}

  We can thus remove \( b_m \) to obtain the inclusion
  \begin{equation*}
    \linspan\set{ b_1, \ldots, b_{m-1} } \subseteq \linspan\set{ a_1, \ldots, a_{k_0 - 1}, a_{k_0 + 1}, a_n }.
  \end{equation*}

  From the inductive hypothesis, we conclude that \( m - 1 \leq n - 1 \), and hence \( m \leq n \).
\end{proof}

\paragraph{Module ranks}

\begin{theorem}[Vector space basis existence]\label{thm:vector_space_basis_existence}
  Every \hyperref[def:vector_space]{vector space} has a \hyperref[def:hamel_basis]{basis}.
\end{theorem}
\begin{comments}
  \item Within \hyperref[def:zfc]{\logic{ZF}}, this theorem is equivalent to the \hyperref[def:zfc/choice]{axiom of choice} --- see \fullref{thm:axiom_of_choice_equivalences/vector_space_bases}.
\end{comments}
\begin{proof}
  \ImplicationSubProof[thm:zorns_lemma]{Zorn's lemma}[thm:vector_space_basis_existence]{vector space existence} Let \( V \) be a vector space over \( \BbbK \). Let \( \mathcal{B} \) be the family of all linearly independent \hyperref[def:linear_combination]{subsets} of \( V \).

  The family \( \mathcal{B} \) is nonempty since any \hyperref[def:singleton_set]{singleton} from \( V \) belongs to \( \mathcal{B} \). The union of any chain \( \mathcal{B}' \subseteq \mathcal{B} \) can then contain only linearly independent elements since otherwise we would have that some set in \( \mathcal{B}' \) is not linearly independent. Thus, \fullref{thm:zorns_lemma} shows the existence of a maximal linearly independent set \( E \). By \fullref{thm:def:vector_space/maximal_independent}, \( E \) is a basis.

  \ImplicationSubProof[thm:vector_space_basis_existence]{vector space existence}[def:zfc/choice]{the axiom of choice} Shown in \cite{Blass1984BasesImplyAOC}.
\end{proof}

\begin{proposition}\label{thm:vector_space_dimension}
  All \hyperref[def:hamel_basis]{bases} of a \hyperref[def:vector_space]{vector space} are \hyperref[def:equinumerosity]{equinumerous}.
\end{proposition}
\begin{proof}
  Let \( A \) and \( E \) be bases of \( V \).

  \SubProof{Proof for finite bases} Suppose that \( a_1, \ldots, a_n \) are the vectors of \( A \).

  \SubProof*{Proof in case \( E \) is infinite} Aiming at a contradiction, suppose that \( E \) is infinite.

  Every vector \( a_i \) of \( A \) can be \hyperref[def:basis_decomposition]{decomposed} along \( E \) as
  \begin{equation*}
    a_i = \sum_{j=1}^{m_i} t^{(i)}_j e^{(i)}_j.
  \end{equation*}
  for appropriate scalars from \( \BbbK \) and vectors from \( E \). Since this can be done for every \( a_i \) in \( A \), we conclude that
  \begin{equation*}
    V = \linspan\set{ a_1, \ldots, a_n } = \linspan\set{ e^{(1)}_1, \ldots, e^{(1)}_{m_1}, \ldots, e^{(n)}_1, \ldots, e^{(n)}_{m_n} }.
  \end{equation*}

  Hence, a finite subset of \( E \) spans \( V \), contradicting \fullref{thm:def:hamel_basis/minimal_spanning}. Therefore, \( E \) must be a finite set.

  \SubProof*{Proof in case \( E \) is finite} Let \( b_1, \ldots, b_m \) be the vectors of \( E \). By applying \fullref{thm:def:vector_space/dimension_lemma} twice, we conclude that \( n \leq m \) and \( m \leq n \), hence \( n = m \).

  \SubProof{Proof for infinite bases} Suppose that both \( A \) and \( E \) are infinite. Let \( S_x \) be the set of vectors in \( E \) with nonzero coefficients in the decomposition of \( x \in V \).
  \begin{itemize}
    \item \( S_x \) is necessarily a finite set.
    \item Every vector \( x \) in \( V \) belongs to \( S_a \) for some \( a \in A \).

    Indeed, \( x \) can be decomposed along \( A \) as
    \begin{equation*}
      x = \sum_{a \in A} \pi_a(x) \cdot a,
    \end{equation*}
    and \( x \in S_{a_k} \) whenever \( \pi(a) \neq 0_\BbbK \).

    \item For every basis vector \( e \) in \( E \), \( S_e = \set{ e } \).

    \item We have
    \begin{equation*}
      E \subseteq \bigcup_{a \in A} S_a
    \end{equation*}
  \end{itemize}

  Therefore,
  \begin{equation*}
    \card(E)
    \leq
    \card\parens[\Bigg]{ \bigcup_{a \in A} S_a }
    \leq
    \card\parens[\Bigg]{ \coprod_{a \in A} S_a }
    \leq
    \card(A \times \omega)
    \leq
    \card(A) \cdot \aleph_0
    \reloset {\ref{thm:simplified_cardinal_arithmetic/infinite}} \leq
    \card(A).
  \end{equation*}

  Since \( A \) and \( E \) were arbitrary bases, we can exchange them to obtain the converse inequality, and thus \( \card(A) = \card(B) \).
\end{proof}

\begin{definition}\label{def:vector_space_dimension}\mimprovised
  For a \( \BbbK \)-\hyperref[def:vector_space]{vector space} \( V \), we define its \term[bg=размерност (\cite[216]{Станилов1974АналитичнаГеометрия}), ru=размерность (\cite[sec. 3.7]{Тыртышников2007ЛинейнаяАлгебра})]{dimension} \( \dim V \) as the \hyperref[thm:cardinality_existence]{cardinality} of any of its bases.
\end{definition}
\begin{defproof}
  \item \Fullref{thm:vector_space_basis_existence} shows that every vector space has a basis.
  \item \Fullref{thm:commutative_module_rank} shows that all bases are equinumerous, hence the rank is well-defined.
\end{defproof}

\begin{proposition}\label{thm:commutative_module_rank}
  All \hyperref[def:hamel_basis]{bases} of a \hyperref[def:module]{module} over a nontrivial \hyperref[def:ring/commutative]{commutative ring} are \hyperref[def:equinumerosity]{equinumerous}.
\end{proposition}
\begin{proof}
  Suppose that \( A \) and \( E \) are bases of the \( R \)-module \( M \). Let \( I \) be a \hyperref[def:semiring_ideal/maximal]{maximal ideal} of \( R \).

  By \fullref{thm:quotient_by_maximal_ideal}, \( \BbbK = R / I \) is a field. Given an isomorphism \( \Phi: R^{\oplus A} \to R^{\oplus E} \) with components \( \Phi_e: R^{\oplus A} \to R \), define
  \begin{equation*}
    \begin{aligned}
      &\Psi: \BbbK^{\oplus A} \to \BbbK^{\oplus E} \\
      &\Psi\parens[\Big]{ \seq{ t_a + I }_{a \in A} } \coloneqq \seq[\Big]{ \Phi_e(\seq{ t_a }_{a \in A}) + I }_{e \in E}
    \end{aligned}
  \end{equation*}

  This is clearly an isomorphism if it is well-defined.

  To show that it is well-defined, suppose \( t_a + I = t_a' + I \) for every \( a \in A \), i.e. \( t_a - t_a' \in I \). Then
  \small
  \begin{equation*}
    \Phi_e(\seq{ t_a }_{a \in A}) - \Phi_e(\seq{ t_a' }_{a \in A})
    =
    \Phi_e(\seq{ t_a }_{a \in A} - \seq{ t_a' }_{a \in A})
    =
    \Phi_e(\seq{ t_a - t_a' }_{a \in A})
    =
    \sum_{a \in A} (\underbrace{ t_a - t_a' }_I) \Phi_e(a)
    \in
    I.
  \end{equation*}
  \normalsize

  Thus,
  \begin{equation*}
    \Phi_e(\seq{ t_a }_{a \in A}) + I = \Phi_e(\seq{ t_a' }_{a \in A}) + I.
  \end{equation*}

  Therefore, \( \Psi \) is a well-defined linear isomorphism. Applying \fullref{thm:vector_space_dimension}, we conclude that \( A \) and \( E \) are equinumerous.
\end{proof}

\begin{corollary}\label{thm:finitely_generated_module_basis}
  For a \hi{nontrivial} \hi{commutative} ring \( R \), if a \hyperref[def:semimodule/generated]{finitely generated} \( R \)-module has a \hyperref[def:hamel_basis]{basis}, the basis is finite.
\end{corollary}
\begin{proof}
  Follows from \fullref{thm:commutative_module_rank}.
\end{proof}

\begin{definition}\label{def:module_rank}\mimprovised
  For a \hyperref[def:ring/commutative]{commutative ring} \( R \), we define the \term[bg=rank (\cite[32]{КоцевСидеров2016КомутативнаАлгебра}), ru=rank (\cite[47]{Шафаревич1999ОсновныеПонятияАлгебры}), en=rank (\cite[171]{Jacobson1985BasicAlgebraI})]{rank} of a \hyperref[rem:free_module]{free \( R \)-module} as the \hyperref[thm:cardinality_existence]{cardinality} of any of its bases.
\end{definition}
\begin{comments}
  \item Unlike vector space dimensions, module ranks may not exist in more general cases --- see \fullref{ex:def:hamel_basis/module_without_basis}.
  \item We generalize the definition by \incite[171]{Jacobson1985BasicAlgebraI} to \hyperref[con:transfinite]{transfinite} ranks.
\end{comments}
\begin{defproof}
  That the choice of basis is immaterial follows from \fullref{thm:commutative_module_rank}.
\end{defproof}

\begin{example}\label{ex:field_submodules}
  For a nontrivial \hyperref[def:ring/commutative]{commutative ring} \( R \), every ideal of \( R \) is a submodule of the \hyperref[def:module_rank]{rank-one} \hyperref[def:module]{module} \( R \). For example, both \( \BbbZ \) and \( 2\BbbZ \) are \( \BbbZ \)-modules of rank one.

  For a \hyperref[def:field]{field} \( \BbbK \), every ideal of \( \BbbK \) is a submodule of the \hyperref[thm:vector_space_dimension]{unidimensional} \hyperref[def:vector_space]{vector space} \( \BbbK \). The only ideals of \( \BbbK \) are the zero ideal, whose dimension is zero, and the field itself, whose dimension is one.
\end{example}

\begin{proposition}\label{thm:modules_with_same_rank_are_isomorphic}
  Two \( R \)-modules having the same \hyperref[def:module_rank]{rank} are \hyperref[def:linear_function]{linearly isomorphic}.
\end{proposition}
\begin{proof}
  Suppose that \( A \) is a \hyperref[def:hamel_basis]{basis} of \( M \) and \( E \) is a basis of \( N \). Also suppose that both \( M \) and \( N \) have the same rank.

  Then \( A \) is equinumerous with \( E \) and there exists a bijective function \( f: A \to E \). We can define the map \( \varphi: A \to R^{\oplus E} \) by sending \( a \) to the embedding of \( f(a) \) in \( R^{\oplus E} \). We can then \hyperref[thm:free_semimodule_universal_property]{extend} \( \varphi \) to a linear isomorphism \( \Phi: R^{\oplus A} \to R^{\oplus E} \).

  Therefore, there exists an isomorphism between \( M \) and \( R^{\oplus A} \), between \( R^{\oplus A} \) and \( R^{\oplus E} \) and between \( R^{\oplus E} \) and \( N \). Hence, \( M \) and \( N \) are isomorphic.
\end{proof}

\begin{proposition}\label{thm:rank_of_direct_sum}
  Assuming that the \( R \)-modules \( M_1, \ldots, M_n \) have bases, the \hyperref[def:module_rank]{rank} of their direct sum
  \begin{equation*}
    M_1 \oplus \cdots \oplus M_n
  \end{equation*}
  is the \hyperref[def:cardinal_arithmetic/addition]{sum of cardinals}
  \begin{equation*}
    \rank M_1 + \cdots + \rank M_n.
  \end{equation*}
\end{proposition}
\begin{proof}
  Follows from \fullref{thm:basis_of_direct_sum}.
\end{proof}

\paragraph{Rank-nullity theorem}

\begin{lemma}\label{thm:vector_space_dimension_monotonicity}
  For vector spaces \( U \subseteq V \) we have \( \rank U \leq \rank V \).
\end{lemma}
\begin{proof}
  Let \( A \) be a basis of \( U \). By \fullref{thm:def:vector_space/expansion}, there exists a basis \( E \) of \( V \) such that \( A \subseteq E \). Then clearly \( \rank U \leq \rank V \).
\end{proof}

\begin{proposition}\label{thm:rank_nullity_via_subspaces}
  Let \( U \) be a subspace of the \hyperref[thm:vector_space_dimension]{finite-dimensional} \hyperref[def:vector_space]{vector space} \( V \). Then
  \begin{equation*}
    V \cong U \oplus (V / U).
  \end{equation*}
\end{proposition}
\begin{proof}
  By \fullref{thm:vector_space_dimension_monotonicity}, \( \dim U \leq \dim V \). Let \( a_1, \ldots, a_m \) be an ordered basis for \( U \). By \fullref{thm:def:vector_space/expansion}, there exist vectors \( a_{m+1}, \ldots, a_n \) such that \( a_1, \ldots, a_n \) is a basis of \( V \). We will show that \( a_{m+1} + U, \ldots, a_n + U \) is a basis of \( V / U \), thus demonstrating the isomorphism.

  First, we must show that it is a spanning set. Fix a vector \( x + U \) from \( V / U \). We know that \( x \) can be decomposed as
  \begin{equation*}
    x = \sum_{k=1}^n \pi_k(x) \cdot a_k.
  \end{equation*}

  Since \( a_1, \ldots, a_m \) belong to \( U \),
  \begin{equation*}
    x + U = \sum_{k={m+1}}^n \pi_k(x) \cdot a_k + U.
  \end{equation*}

  Hence, \( x + U \) can be represented as a linear combination of the vectors \( a_{m+1} + U, \ldots, a_n + U \).

  To show uniqueness, suppose that
  \begin{equation*}
    x + U = \sum_{k={m+1}}^n t_k (a_k + U) = \sum_{k={m+1}}^n r_k (a_k + U).
  \end{equation*}

  Then
  \begin{equation*}
    U = \sum_{k={m+1}}^n (t_k - r_k) (a_k + U).
  \end{equation*}

  Since neither of \( a_{m+1}, \ldots, a_n \) are in \( U \), it follows that \( t_k = r_k \) for \( k = m + 1, \ldots, n \).

  Therefore, \( a_{m+1} + U, \ldots, a_n + U \) is a basis of \( V / U \).
\end{proof}

\begin{definition}\label{def:rank_and_nullity}\mcite[70]{FriedbergInselSpence2018LinearAlgebra}
  For a \hyperref[def:linear_function]{linear map} \( \varphi: U \to V \), we call the dimension of the kernel of \( \varphi \) the \term[ru=дефект (\cite[250]{Тыртышников2007ЛинейнаяАлгебра})]{nullity} of \( \varphi \) and the dimension of the image - the \term[ru=ранг (\cite[250]{Тыртышников2007ЛинейнаяАлгебра})]{rank} of \( \varphi \)
\end{definition}

\begin{theorem}[Rank-nullity theorem]\label{thm:rank_nullity_theorem}
  For every \hyperref[def:linear_function]{linear map} \( \varphi: U \to V \) between \hyperref[thm:vector_space_dimension]{finite-dimensional} \hyperref[def:vector_space]{vector spaces}, we have
  \begin{equation}\label{eq:thm:rank_nullity_theorem}
    U \cong \ker \varphi \oplus \img \varphi.
  \end{equation}

  In particular,
  \begin{equation}\label{eq:thm:rank_nullity_theorem/dim}
    \dim U = \dim \ker \varphi + \dim \img \varphi.
  \end{equation}
\end{theorem}
\begin{proof}
  By \fullref{thm:module_zero_morphisms/isomorphism},
  \begin{equation*}
    \img \varphi \cong U / \ker \varphi.
  \end{equation*}

  By \fullref{thm:rank_nullity_via_subspaces},
  \begin{equation*}
    U \cong \ker \varphi \oplus (U / \ker \varphi) \cong \ker \varphi \oplus \img \varphi.
  \end{equation*}

  The equality \eqref{thm:rank_nullity_theorem} then follows from \fullref{thm:rank_of_direct_sum}.
\end{proof}
