\section{Univariate polynomials}\label{sec:univariate_polynomials}

We will discuss here the \hyperref[def:polynomial_algebra]{polynomial algebra} \( R[X] \) in one indeterminate over the \hyperref[def:ring/trivial]{nontrivial} \hyperref[def:ring/commutative]{commutative unital ring} \( R \). We call them \term{univariate polynomials} based on \cref{def:operation_arity_terminology}, although we acknowledge the polynomials are not functions. \Cref{rem:polynomials_over_infinitely_many_indeterminates} discusses why we often focus only on finitely many indeterminates, and why the theory of univariate polynomials is often sufficient.

Polynomials do not exactly correspond to polynomial functions in general, and the exact relationship between polynomials and polynomial functions is discussed in \fullref{thm:polynomial_algebra_universal_property} and \cref{thm:functions_over_finite_fields}.

\paragraph{Euclidean division of polynomials}

\begin{definition}\label{def:monic_polynomial}
  We say that the nonzero univariate polynomial is \term[bg=нормиран (\cite[409]{Обрешков1962ВисшаАлгебра}), ru=нормированный/приведенный (\cite[102]{Винберг2014КурсАлгебры})]{monic} if its leading coefficient is \( 1 \).
\end{definition}

\begin{proposition}\label{thm:polynomial_degree_arithmetic}
  The \hyperref[def:polynomial_degree]{polynomial degree} has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:polynomial_degree_arithmetic/sum} For any two nonzero polynomials \( f(X) \) and \( g(X) \), either their sum is zero or
    \begin{equation}\label{eq:thm:polynomial_degree_arithmetic/sum}
      \deg (f + g) \leq \max \set{ \deg f, \deg g }.
    \end{equation}

    \thmitem{thm:polynomial_degree_arithmetic/product} For any two nonzero polynomials \( f(X) \) and \( g(X) \), either their product is zero or
    \begin{equation}\label{eq:thm:polynomial_degree_arithmetic/product}
      \deg (fg) \leq \deg f + \deg g.
    \end{equation}

    If the leading coefficients of \( f(X) \) and \( g(X) \) do not multiply to zero, then equality in \eqref{eq:thm:polynomial_degree_arithmetic/product} holds.
  \end{thmenum}
\end{proposition}
\begin{comments}
  \item An easy sufficient condition for equality in \eqref{eq:thm:polynomial_degree_arithmetic/product} is for the semiring to be \hyperref[def:entire_semiring]{entire}, although it is also sufficient for the ring to be nontrivial (so that \( 0_R \neq 1_R \)) and either \( f(X) \) or \( g(X) \) to be \hyperref[def:monic_polynomial]{monic}.

  \item We generalize a weaker statement for multivariate polynomials in \cref{thm:degree_of_multivariate_polynomial_product}.
\end{comments}
\begin{proof}
  Fix nonzero polynomials
  \begin{align*}
    f(X) = \sum_{k=0}^n a_k X^k, &&
    g(X) = \sum_{k=0}^m b_k X^k.
  \end{align*}

  \SubProofOf{thm:polynomial_degree_arithmetic/sum} Additionally assume that \( f(X) \neq -g(X) \) since otherwise \( f(X) + g(X) = 0 \) and \( \deg(f + g) \) is undefined.

  Since the polynomials are not equal, there exists at least one index \( k = 0, 1, 2, \ldots \) such that \( a_k \neq b_k \). Denote by \( k_0 \) the largest such index (only finitely many are nonzero). Then
  \begin{equation*}
    a_k - b_k = 0 \T{whenever} k > k_0.
  \end{equation*}

  Therefore, \( \deg(f + g) = k_0 \). Note that \( k_0 \) cannot exceed both \( \deg f \) and \( \deg g \) because it corresponds to a nonzero coefficient in both. Thus, \( k_0 \leq \max\set{ \deg f, \deg g } \).

  \SubProofOf{thm:polynomial_degree_arithmetic/product} Suppose that the product \( f(X) g(X) \) is nonzero. The coefficient \( c_{n + m} \) of \( f(X) g(X) \) is \( a_n b_m \) by definition. For \( k > n + m \), if \( i + j = k \), either \( i > n \) or \( j > m \), so \( c_k \) is zero. In other words, either \( c_{n + m} \) is zero or is last nonzero coefficient of \( f(X) g(X) \).
\end{proof}

\begin{corollary}\label{thm:leading_coefficient_of_product}
  If the leading coefficients of two univariate polynomials do not multiply to zero, the product of their leading coefficients is the leading coefficient of their product.
\end{corollary}
\begin{proof}
  Consider the polynomials
  \begin{align*}
    f(X) = \sum_{k=0}^n a_k X^k, &&
    g(X) = \sum_{k=0}^m b_k X^k.
  \end{align*}

  By definition of convolution product, the \( (n + m) \)-th coefficient of \( f(X) g(X) \) is \( a_n b_m \). \Cref{thm:polynomial_degree_arithmetic/product} implies that this is their leading coefficient.
\end{proof}

\begin{algorithm}[Euclidean division of polynomials]\label{alg:euclidean_division_of_polynomials}
  In a commutative ring \( R \), fix two univariate polynomials
  \begin{align*}
    f(X) = \sum_{k=0}^n a_k X^k, &&
    g(X) = \sum_{k=0}^m b_k X^k.
  \end{align*}

  Suppose that \( g(X) \) is \hyperref[def:monic_polynomial]{monic}, i.e. \( b_m = 1_R \). We will build polynomials \( q(X) \) and \( r(X) \), where \( r(X) \) is either zero or \( \deg r < \deg g = m \), such that
  \begin{equation*}
    f(X) = g(X) \cdot q(X) + r(X).
  \end{equation*}

  \begin{thmenum}
    \thmitem{alg:euclidean_division_of_polynomials/zero} If \( f(X) \) is the zero polynomial, let
    \begin{align*}
      q(X) \coloneqq 0_R, &&
      r(X) \coloneqq 0_R.
    \end{align*}

    \thmitem{alg:euclidean_division_of_polynomials/no_division} Otherwise, if \( \deg f = n < m = \deg g \), let
    \begin{align*}
      q(X) \coloneqq 0_R, &&
      r(X) \coloneqq f(X).
    \end{align*}

    \thmitem{alg:euclidean_division_of_polynomials/division} Otherwise, \( \deg f = n \geq m = \deg g \). Let
    \begin{equation*}
      \widehat r(X) \coloneqq f(X) - a_n X^{n-m} \cdot g(X).
    \end{equation*}

    We use the algorithm recursively to divide \( \widehat r(X) \) by \( g(X) \), and obtain \( \widehat q(X) \) and \( r(X) \), where \( r(X) \) is either zero or of lower degree than \( g \), such that
    \begin{equation*}
      \widehat r(X) = g(X) \cdot \widehat q(X) + r(X).
    \end{equation*}

    Then
    \begin{align*}
      \widehat r(X)                                                  &= f(X) - a_n X^{n-m} \cdot g(X), \\
      g(X) \cdot \widehat q(X) + r(X)                                &= f(X) - a_n X^{n-m} \cdot g(X), \\
      g(X) \cdot \parens[\big]{ \widehat q(X) + a_n X^{n-m} } + r(X) &= f(X).
    \end{align*}

    It remains to define
    \begin{equation*}
      q(X) \coloneqq \widehat q(X) + a_n X^{n-m}.
    \end{equation*}
  \end{thmenum}
\end{algorithm}
\begin{comments}
  \item In general \( q(X) \) and \( r(X) \) are not unique. This is discussed in \cref{ex:polynomial_root_uniqueness}. In \hyperref[def:integral_domain]{integral domains}, uniqueness follows from \cref{thm:polynomial_euclidean_division_uniqueness}.

  \item This algorithm can be found as \identifier{math.polynomials.euclidean_divmod} in \cite{notebook:code}.
\end{comments}
\begin{defproof}
  We only need to show that the algorithm terminates. This is clear if \( f(X) \) is zero. Otherwise, we will do this by induction on the degree \( n \) of \( f(X) \).

  \begin{itemize}
    \item If \( n = 0 \), either \( m > 0 \) and the algorithm terminates at \cref{alg:euclidean_division_of_polynomials/no_division}, or \( m = 0 \) and we use the recursive step \cref{alg:euclidean_division_of_polynomials/division}.

    In the latter case, \( \widehat r(X) \) evaluates to \( 0_R \), so the recursive application uses \cref{alg:euclidean_division_of_polynomials/zero} and then the algorithm terminates.

    \item Suppose that \( n > 0 \) and that the inductive hypothesis holds for \( n - 1 \).

    Again, we use either \cref{alg:euclidean_division_of_polynomials/no_division} or the recursive step \cref{alg:euclidean_division_of_polynomials/division}.

    In the latter case, to use the inductive hypothesis, we only need to show that \( \widehat r(X) \) is either zero or has degree lower than \( n \). Let
    \begin{align*}
      \widehat f(X) &\coloneqq f(X) - a_n X^n, \\
      \widehat g(X) &\coloneqq g(X) - X^m.
    \end{align*}

    Clearly \( \deg \widehat f < n \) and \( \deg \widehat g < m \). Moreover,
    \begin{equation*}
      \widehat r(X) = \widehat f(X) - a_n X^{n-m} \cdot \widehat g(X).
    \end{equation*}

    If \( \widehat r(X) \) is not zero, then
    \begin{equation*}
      \deg \widehat r
      \reloset {\eqref{eq:thm:polynomial_degree_arithmetic/sum}} \leq
      \max\set{ \deg \widehat f, n - 1 }
      =
      n - 1
    \end{equation*}
    because
    \begin{equation*}
      \deg(a_n X^{n-m} \cdot \widehat g(X))
      \reloset {\eqref{eq:thm:polynomial_degree_arithmetic/product}} =
      (n - m) + \deg \widehat g
      \leq
      (n - m) + (m - 1)
      =
      n - 1.
    \end{equation*}
  \end{itemize}
\end{defproof}

\begin{algorithm}[Horner's rule]\label{alg:horners_rule}\mcite[\S III.V.2]{Обрешков1962ВисшаАлгебра}
  Consider the polynomials
  \begin{equation*}
    f(X) = \sum_{k=0}^n a_k X^k
  \end{equation*}
  and
  \begin{equation*}
    g(X) = X + b.
  \end{equation*}

  The coefficients of the quotient of \( f(X) \) and \( g(X) \) with respect to \fullref{alg:euclidean_division_of_polynomials} can be computed recursively as follows:
  \begin{equation}\label{eq:alg:horners_rule/quot}
    c_{n-k} \coloneqq \begin{cases}
      a_n,                              &k = 1 \\
      a_{n-(k-1)} - b \cdot c_{n-(k-1)} &k > 1.
    \end{cases}
  \end{equation}

  Furthermore, \( r(X) \) is a constant that equals
  \begin{equation}\label{eq:alg:horners_rule/rem}
    c_{-1} = a_0 - b \cdot c_0.
  \end{equation}
\end{algorithm}
\begin{comments}
  \item This algorithm can be found as \identifier{math.polynomials.division.horner_divmod} in \cite{notebook:code}.
\end{comments}
\begin{proof}
  Denote the quotient by
  \begin{equation*}
    q(X) = \sum_{k=0}^{n-1} c_k X^k.
  \end{equation*}

  We have
  \begin{equation*}
    f(X) = g(X) \cdot q(X) + r(X),
  \end{equation*}
  from where, for every \( k > 0 \),
  \begin{equation*}
    a_k = c_{k-1} + b \cdot c_k,
  \end{equation*}
  from which \eqref{eq:alg:horners_rule/quot} follows.

  Furthermore,
  \begin{equation*}
    r(X) = a_0 - b \cdot c_0,
  \end{equation*}
  which demonstrates \eqref{eq:alg:horners_rule/rem}.
\end{proof}

\begin{remark}\label{rem:alg:horners_rule}
  The phrase \enquote{Horner's rule} is ambiguous.

  \incite{Horner1819SolvingNumericalEquations} describes a method for seeking polynomial roots. Variations of method are described by \incite[144]{Курош1968КурсВысшейАлгебры}, \incite[97]{Винберг2014КурсАлгебры} and \incite[209]{Кострикин2000АлгебраЧасть1} as \enquote{схема Горнера} (\enquote{Horner's scheme}) and \incite[\S III.V.2]{Обрешков1962ВисшаАлгебра} as \enquote{правилото на Хорнер} (\enquote{Horner's rule}). We roughly follow their discussion in \fullref{alg:horners_rule}.

  On the other hand, \incite[486]{Knuth1997ArtVol2} calls \enquote{Horner's rule} the representation
  \begin{equation}\label{eq:rem:alg:horners_rule/knuth}
    f(X) = \sum_{k=0}^n a_k X^k = a_0 + X (a_1 + \cdots + X(a_{n-1} + X a_n) + \cdots),
  \end{equation}
  considered from the point of view of computational complexity --- at allows computing \( f(\alpha) \) via \( n \) multiplications and \( n \) additions, while direct evaluation requires  \( {n(n+1)} / 2 \) multiplications and \( n \) additions.

  \incite[exerc. 3.3.14]{Rosen2019DiscreteMathematics} calls this procedure \enquote{Horner's method}.
\end{remark}

\paragraph{\( n \)-th roots}

\begin{definition}\label{def:nth_root}\mimprovised
  In a \hyperref[def:ring/commutative]{commutative ring}, for \( n \geq 2 \), we say that an element is an \term{\( n \)-th root} of \( a \) if it is a \hyperref[def:polynomial_root]{polynomial root} of \( X^n - a \).

  We use the prefixes from the polynomial degree terminology described in \cref{def:polynomial_degree_terminology}, with one modification --- instead of \enquote{quadratic root}, we say \enquote{square root}.

  If \( b \) is a square root (resp. cubic root) of \( a \), we say that \( a \) is a \term{square} (resp. \term{cube}) of \( b \).
\end{definition}
\begin{comments}
  \item In the case of positive \hyperref[def:real_numbers]{real numbers}, we have a canonical choice of \( n \)-th roots given by \cref{def:principal_nonnegative_nth_root}, where we use the notation \( \sqrt[n]{ x } \). We also have such a canonical choice for square roots of negative real numbers --- see \cref{def:principal_real_square_root}.
\end{comments}

\begin{definition}\label{def:algebraic_equation}\mimprovised
  \hyperref[def:equation]{Equations} in the \hyperref[def:ring/theory]{theory of rings} are called \term{algebraic}. Such equations are equalities of polynomials in finitely many indeterminates. It is sufficient to only consider equations whose right side is zero (since we can cancel it otherwise), thus a general algebraic equation has the form
  \begin{equation*}\label{eq:def:algebraic_equation}
    f(X_1, \ldots, X_n) = 0.
  \end{equation*}

  We use the prefixes from the polynomial degree terminology described in \cref{def:polynomial_degree_terminology}, e.g. we call \eqref{eq:def:algebraic_equation} a \enquote{quadratic equation} if \( f(X_1, \ldots, X_n) \) is a quadratic polynomial.
\end{definition}

\begin{definition}\label{def:trivial_solution_of_algebraic_equation}\mimprovised
  If the polynomial corresponding to an \hyperref[def:algebraic_equation]{algebraic equation} has no \hyperref[def:univariate_polynomial]{constant term}, evaluating all indeterminates to zero provides a \hyperref[def:equation/solution]{solution}. We call it the \term{trivial solution}.
\end{definition}

\begin{remark}\label{rem:root_terminology}
  The term \enquote{root} has several distinct (but related) meanings:
  \begin{itemize}
    \item The \( n \)-th root in the sense of \cref{def:nth_root}. The discussion in \cite{HSMSE:radical_symbol_history} suggests that this is the origin of the terms \enquote{root} and \enquote{radical}, based on the Latin \enquote{radix}.

    There is inherent ambiguity in picking \enquote{the} root, since there may be many. For positive real numbers we have an established canonical choice of \( n \)-th roots, which we call \enquote{principal roots}, and for negative real numbers --- of square roots.

    \item The \hyperref[def:equation/solution]{solutions} of an \hyperref[def:algebraic_equation]{algebraic equation} are also called \enquote{roots}. An explicit definition with this usage can be found in \incite[2]{Обрешков1962ВисшаАлгебра}.

    As noted in \cref{def:algebraic_equation}, polynomials naturally arise from equations on rings, thus it makes sense for this usage to predate polynomials.

    \item From a modern perspective, both are encompassed by roots of polynomials as defined in \cref{def:polynomial_root}. Roots are zeros in the sense of \cref{def:zero_of_function} of a fixed polynomial function. For \hyperref[def:univariate_polynomial]{univariate polynomials}, \cref{def:polynomial_root_multiplicity} provides a characterization in terms of divisibility, as well as a concept of \enquote{multiplicity} of a root.

    A \enquote{root} is defined as a zero of a univariate polynomial by
    \incite[282]{Aluffi2009Algebra},
    \incite[11]{Knapp2016BasicAlgebra} and
    \incite[119]{Тыртышников2017ОсновыАлгебры}.
  \end{itemize}
\end{remark}

\begin{definition}\label{def:square_free_element}\mimprovised
   In a \hyperref[def:ring/commutative]{commutative ring}, we say that \( x \) of is \term[ru=свободное от квадратов (число) (\cite[def. 93]{Бухштаб1966ТеорияЧисел}), en=square-free (element) (\cite[79]{JędrzejewiczEtAl2017SquareFreeFactorization})]{square-free} if no \hi{non-invertible} divisor of \( x \) has a \hyperref[def:nth_root]{square root}.
\end{definition}
\begin{comments}
  \item This concept is established for the ring of integers. An explicit definition can be found in \cite[def. 93]{Бухштаб1966ТеорияЧисел}) and an inline definition can be found in \cite[176]{Birkhoff1967LatticeTheory}, both requiring all prime factors of square-free integers to be distinct.

  \incite[79]{JędrzejewiczEtAl2017SquareFreeFactorization} generalize this concept to commutative rings --- they require \( y \mid x \) to imply that \( y^2 \not\mid x \). We give an equivalent definition in terms of square roots.
\end{comments}

\paragraph{Multiple roots}

\begin{definition}\label{def:algebraic_derivative}\mcite[461]{Knapp2016BasicAlgebra}
  Generalizing \cref{def:differentiability} from analysis, we define the \term[ru=производная (\cite[163]{Тыртышников2017ОсновыАлгебры})]{algebraic derivative} of a univariate polynomial
  \begin{equation*}
    f(X) = \sum_{k=0}^n a_k X^k = a_n X^n + a_{n-1} X^{n-1} + \cdots + a_2 X^2 + a_1 X + a_0
  \end{equation*}
  as
  \begin{equation*}
    f'(X) \coloneqq \sum_{k=1}^n k a_k X^{k-1} = n a_n X^{n-1} + (n-1) a_{n-1} X^{n-2} + \cdots + a_2 X + a_1.
  \end{equation*}

  Via \fullref{thm:omega_recursion}, we can define algebraic derivatives of order \( m \) as
  \begin{equation*}
    f^{(m)}(X) \coloneqq \begin{cases}
      f(X)                             &m = 0 \\
      \parens[\Big]{ f^{(m - 1)} }'(X) &m > 0
    \end{cases}
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:def:algebraic_derivative}
  \hyperref[def:algebraic_derivative]{Algebraic derivatives} have the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:algebraic_derivative/linear} The derivative operator \( f(X) \mapsto f'(X) \) is linear.
    \thmitem{thm:def:algebraic_derivative/degree} \( f^{(n)}(X) \) is either zero or has degree \( \deg f - n \).

    \thmitem{thm:def:algebraic_derivative/product} The product rule holds:
    \begin{equation}\label{eq:thm:def:algebraic_derivative/product}
      (fg)' = f'g + fg'.
    \end{equation}

    \thmitem{thm:def:algebraic_derivative/leibniz} A variant of \fullref{thm:leibniz_rule} holds:
    \begin{equation}\label{eq:thm:def:algebraic_derivative/leibniz}
      (fg)^{(n)} = \sum_{k=0}^n \binom n k f^{(k)} g^{(n-k)}
    \end{equation}

    \thmitem{thm:def:algebraic_derivative/affine_power} If \( m \leq n \), the \( m \)-th derivative of \( (X - \alpha)^n \) is
    \begin{equation*}
      \frac {n!} {(n-m)!} (X - \alpha)^{n-m}.
    \end{equation*}
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:algebraic_derivative/linear} Trivial.

  \SubProofOf{thm:def:algebraic_derivative/degree} Trivial.

  \SubProofOf{thm:def:algebraic_derivative/product} By \cref{thm:def:algebraic_derivative/linear}, it is enough to consider the case where both \( f(X) \) and \( g(X) \) are monomials.

  \begin{align*}
    f'(X) g(X) + f(X) g'(X)
    &=
    n a_n X^{n-1} \cdot b_m X^m + a_n X^n \cdot m b_m X^{m-1}
    = \\ &=
    (n + m) a_n b_m X^{n+m-1}
    = \\ &=
    (a_n b_m X^{n+m})'
    = \\ &=
    (fg)'(X).
  \end{align*}

  \SubProofOf{thm:def:algebraic_derivative/leibniz} The proof in \fullref{thm:leibniz_rule} relies only on the product rule, hence it holds here as well.

  \SubProofOf{thm:def:algebraic_derivative/affine_power} We use outer induction on \( m \) and inner induction on \( n \).

  The case \( m = n = 1 \) is obvious. Assume that the statement holds for \( m = 1 \) and \( n - 1 \). Then
  \begin{equation*}
    \parens[\Big]{ (X - \alpha)^n }'
    =
    \parens[\Big]{ (X - \alpha)^{n-1} \cdot (X - \alpha) }'
    \reloset {\eqref{eq:thm:def:algebraic_derivative/product}} =
    \parens[\Big]{ (X - \alpha)^{n-1} }' (X - \alpha) + (X - \alpha)^{n-1}
    \reloset {\T{ind.}} =
    n (X - \alpha)^{n-1}.
  \end{equation*}

  Now suppose that the statement holds for derivatives of order less than \( m \) and for every \( n \geq m \). Then,
  \begin{equation*}
    \parens[\Big]{ (X - \alpha)^n }^{(m)}
    =
    \parens*{\parens[\Big]{ (X - \alpha)^n }^{(m-1)}}'
    \reloset {\T{ind.}} =
    \parens*{ \frac {n!} {(n - m + 1)!} (X - \alpha)^{n - m + 1} }'
    \reloset {\T{ind.}} =
    \frac {n!} {(n - m)!} (X - \alpha)^{n - m}.
  \end{equation*}
\end{proof}

\begin{definition}\label{def:polynomial_root_multiplicity}\mimprovised
  Let \( R \) be a nontrivial commutative ring.

  We say that the \hyperref[def:polynomial_root]{root} \( \alpha \) of the univariate polynomial \( f(X) \) of degree \( n \) has \term[bg=кратност (\cite[171]{Обрешков1962ВисшаАлгебра}), ru=кратность (\cite[163]{Тыртышников2017ОсновыАлгебры}), en=multiplicity (\cite[229]{Jacobson1985BasicAlgebraI})]{multiplicity} \( m \) if any of the following equivalent conditions hold:
  \begin{thmenum}
    \thmitem{def:polynomial_root_multiplicity/division}\mcite[163]{Тыртышников2017ОсновыАлгебры} The polynomial \( (X - \alpha)^m \) divides \( f(X) \).

    \thmitem{def:polynomial_root_multiplicity/derivative_roots} The value \( \alpha \) is a \hyperref[def:polynomial_root]{root} of the \hyperref[def:algebraic_derivative]{algebraic derivatives} \( f^{(0)}(X), f^{(1)}(X), \ldots, f^{(m-1)}(X) \).
  \end{thmenum}

  Every polynomial \( f(X) \) has a \hyperref[def:multiset]{multiset} of roots. If at least one of them has multiplicity greater than one, we say that it is a \term[bg=многократен (корен) (\cite[171]{Обрешков1962ВисшаАлгебра}), ru=кратный (корень) (\cite[163]{Тыртышников2017ОсновыАлгебры}), en=multiple root (\cite[229]{Jacobson1985BasicAlgebraI})]{multiple root}, otherwise we say that it is a \term[bg=прост корен (\cite[171]{Обрешков1962ВисшаАлгебра}), ru=простой корень (\cite[163]{Тыртышников2017ОсновыАлгебры}), en=simple root (\cite[229]{Jacobson1985BasicAlgebraI})]{simple root}.
\end{definition}
\begin{comments}
  \item This is an extension of the general concept of polynomial roots discussed in \cref{def:polynomial_root}.
\end{comments}
\begin{defproof}
  \ImplicationSubProof{def:polynomial_root_multiplicity/division}{def:polynomial_root_multiplicity/derivative_roots} Suppose that \( (X - \alpha)^m \) divides \( f(X) \). Then there exists a polynomial \( g(X) \) such that
  \begin{equation*}
    f(X) = (X - \alpha)^m g(X).
  \end{equation*}

  For the \( n < m \)-th derivative of \( f(X) \), by \cref{thm:def:algebraic_derivative/leibniz}, we have
  \begin{equation*}
    f^{(n)}(X) = \sum_{k=0}^n \binom n k \underbrace{\parens[\Big]{ (X - \alpha)^m }^{(k)}}_{\mathclap{\frac {m!} {(m-k)!} (X - \alpha)^{m-k} \T*{by} \ref{thm:def:algebraic_derivative/affine_power}}} q^{(n-k)}(X).
  \end{equation*}

  Let \( \Phi_\alpha: R[X] \to R \) be the \hyperref[con:evaluation_homomorphism]{evaluation homomorphism} at \( \alpha \). Then
  \begin{equation*}
    \Phi_\alpha(f^{(n)}) = \sum_{k=0}^n \binom n k \frac {m!} {(m-k)!} 0_R^{m-k} \Phi_\alpha(g^{(n-k)})
  \end{equation*}

  For \( n < m \), clearly \( \Phi_\alpha(f^{(n)}) = 0_R \).

  \ImplicationSubProof{def:polynomial_root_multiplicity/derivative_roots}{def:polynomial_root_multiplicity/division} Suppose that \( \alpha \) is a root of \( f^{(0)}(X), \ldots, f^{(m-1)}(X) \). We will use induction on \( m \) to show that \( (X - \alpha)^m \mid f(X) \).

  The case \( m = 0 \) is trivial. Suppose that \( \alpha \) is root of \( f^{(0)}(X), \ldots, f^{(m-1)}(X) \) and that \( (X - \alpha)^{m-1} \) divides \( f(X) \). Additionally suppose that \( \alpha \) is a root of \( f^{(m)}(X) \).

  By the inductive hypothesis, there exists a polynomial \( g(X) \) such that
  \begin{equation*}
    f(X) = (X - \alpha)^{m-1} g(X).
  \end{equation*}

  By \cref{thm:def:algebraic_derivative/leibniz},
  \begin{equation*}
    f^{(m-1)}(X) = \sum_{k=0}^{m-1} \binom {m-1} k \underbrace{\parens[\Big]{ (X - \alpha)^{m - 1} }^{(k)}}_{\mathclap{\frac {(m - 1)!} {(m - 1 - k)!} (X - \alpha)^{m - 1 - k} \T*{by} \ref{thm:def:algebraic_derivative/affine_power}}} q^{(m - 1 - k)}(X).
  \end{equation*}

  Then
  \begin{equation*}
    \Phi_\alpha(f^{(m-1)}) = \sum_{k=0}^{m-1} \binom {m-1} k \frac {(m - 1)!} {(m - 1 - k)!} 0_R^{m - 1 - k} \Phi_\alpha(q^{(m - 1 - k)}).
  \end{equation*}

  All terms on the right are zero except for the case where \( k = m - 1 \), where \( g^{(0)} = g \) and the entire expression reduces to \( \Phi_\alpha(g) \). The scalar \( \alpha \) is a root of \( f^{(m-1)} \), implying that it is also a root of \( g \).

  We use \fullref{alg:euclidean_division_of_polynomials} to obtain a polynomial \( s(X) \) and a constant polynomial \( r(X) = r_0 \) so that
  \begin{equation*}
    g(X) = (X - \alpha) s(X) + r_0.
  \end{equation*}

  Since \( \Phi_\alpha(g) = 0_R \), then necessarily \( r_0 = 0_R \). Therefore,
  \begin{equation*}
    f(X) = (X - \alpha)^{m-1} g(X) = (X - \alpha)^m s(X).
  \end{equation*}
\end{defproof}

\begin{theorem}[Polynomial factor theorem]\label{thm:polynomial_factor_theorem}\mcite[corr. 2.2]{Jacobson1985BasicAlgebraI}
  Over a nontrivial commutative ring, the value \( \alpha \) is a \hyperref[def:polynomial_root]{root} of the univariate polynomial \( f(X) \) if and only if \( (X - \alpha) \) divides \( f(X) \).
\end{theorem}
\begin{comments}
  \item A much stronger theorem holds in \hyperref[def:gcd_domain]{GCD domains} --- see \fullref{thm:polynomial_factorization_via_roots}.
\end{comments}
\begin{proof}
  Special case of the equivalence of definitions in \cref{def:polynomial_root_multiplicity}.
\end{proof}
