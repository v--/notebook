\subsection{Euclidean plane}\label{subsec:euclidean_plane}

\begin{definition}\label{def:euclidean_plane}
  We call the two-dimensional \hyperref[def:euclidean_space]{Euclidean space} \( \BbbR^2 \) the \term{Euclidean plane}.
\end{definition}

\begin{remark}\label{rem:euclidean_plane_embedding}
  Every \hyperref[def:affine_plane]{affine plane} in \( \BbbR^n \) is isomorphic to \( \BbbR^2 \), and we can use the concepts from this subsection as long as we fix a plane.
\end{remark}

\begin{remark}\label{rem:xyz}
  By convention, depending on the context, in \hyperref[def:euclidean_plane]{Euclidean planes} the letters \( x \) and \( y \) have several meanings:
  \begin{itemize}
    \item The vectors of the \hyperref[def:sequence_space]{standard basis}.
    \item The corresponding \hyperref[def:euclidean_plane]{coordinate axes}.
    \item The \hyperref[def:affine_coordinate_system]{(affine) coordinates} of some arbitrary point.
  \end{itemize}

  We call the axis \( x \) the \term{abscissa} and \( y \) --- the \term{ordinate}.

  In three-dimensional \hyperref[def:euclidean_space]{Euclidean spaces}, we use the letter \( z \) to denote the third coordinate axis and call it the \term{applicata}.

  To avoid confusion, we avoid using \( x \), \( y \) and \( z \) in Euclidean planes to denote points and vectors.
\end{remark}

\begin{definition}\label{def:plane_line_equations}
  \hyperref[def:affine_line]{Lines} in \( \BbbR^2 \) are so ubiquitous that they are often represented via a variety of \hyperref[ex:equations]{equations}.

  We will start with \fullref{def:affine_line/parametric} --- the \hyperref[def:affine_operator]{affine} \hyperref[def:parametric_curve]{parametric curve}
  \begin{equation}\label{eq:def:plane_line_equations/parametric}
    l(t) = O + td
  \end{equation}

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/thm__plane_line_equations__cartessian}
    \caption{A \hyperref[def:affine_line]{line} in \( \BbbR^2 \) defined using its \hyperref[def:plane_line_equations/cartesian]{Cartesian equation}.}\label{fig:def:plane_line_equations/cartesian}
  \end{figure}

  \begin{thmenum}
    \thmitem{def:plane_line_equations/vector_parametric} We call \eqref{eq:def:plane_line_equations/parametric} a \term{vector parametric equation} of \( L \).

    \medspace

    \thmitem{def:plane_line_equations/scalar_parametric} The parametric equation \eqref{eq:def:plane_line_equations/parametric} can be rewritten as
    \begin{equation}\label{eq:def:plane_line_equations/scalar_parametric}
      \begin{cases}
         &l_x(t) = x_o + t x_d, \\
         &l_y(t) = y_o + t y_d.
      \end{cases}
    \end{equation}

    We say that these are \term{scalar parametric equations} of the line. They are non-unique by the same reason as the vector parametric equation.

    \thmitem{def:plane_line_equations/general}\mcite[sec. 9.9]{Тыртышников2007} The image of the scalar equations \eqref{eq:def:plane_line_equations/scalar_parametric} consists of all pairs \( (x, y) \) such that
    \begin{equation}\label{eq:def:plane_line_equations/general}
      \underbrace{ Ax + By + C }_{ p(x, y) } = 0
    \end{equation}
    for some scalars \( A \), \( B \) and \( C \), where \( A \) or \( B \) (or both) are nonzero.
    We call \eqref{eq:def:plane_line_equations/general} a \term{general equation} of the line.

    More concretely,
    \begin{equation*}
      A(o_x + td_x) + B(o_y + td_y) + C = 0
    \end{equation*}
    for all \( t \) if \( A = d_y \), \( B = -d_x \) and \( C = o_y d_x - o_x d_y \).

    Conversely, given the general equation \eqref{eq:def:plane_line_equations/general}, assuming \( A \neq 0 \), we can define the parametric equations
    \begin{equation*}
      \begin{cases}
        &l_x(t) \coloneqq -\tfrac C A - t \tfrac B A  \\
        &l_y(t) \coloneqq t.
      \end{cases}
    \end{equation*}

    The case when \( A = 0 \) and \( B \neq 0 \) is handled analogously.

    Note that multiple general equations can have the same locus --- actually all scalar multiples of \( p(x, y) \). If \( A^2 + B^2 = 1 \) in \eqref{eq:def:plane_line_equations/general}, we call it a \term{normal equation}. There are only two normal equations.

    \thmitem{def:plane_line_equations/cartesian} It is common, especially in analysis, to use the \term{Cartesian equation}
    \begin{equation}\label{eq:def:plane_line_equations/cartesian}
      y = kx + m
    \end{equation}
    for some scalars \( k \) and \( m \). We call \( k \) the \term{slope} of the line.

    It is a special case of the general equation \eqref{eq:def:plane_line_equations/general} with \( A = -k \), \( B = -1 \) and \( C = m \).

    Unlike the general equation, the Cartesian equation of a line is unique, but it cannot express vertical lines. If \( B \neq 0 \) in \eqref{eq:def:plane_line_equations/general}, we can define \( k = -\ifrac A B \) and \( m = -\ifrac C B \) to form a Cartesian equation.

    \thmitem{def:plane_line_equations/intercept} Another equation that is occasionally used is the \term{intercept equation}
    \begin{equation}\label{eq:def:plane_line_equations/intercept}
      \frac x a + \frac y b = 1
    \end{equation}
    for some nonzero real numbers \( a \) and \( b \).

    It is again a special case of the general equation \eqref{eq:def:plane_line_equations/general} with \( A = \ifrac 1 a \), \( B = \ifrac 1 b \) and \( C = -1 \). It is also unique, but it cannot express neither vertical nor horizontal lines, nor lines passing through the origin.

    Conversely, if \( A \), \( B \) and \( C \) are all nonzero in the general equation \eqref{eq:def:plane_line_equations/general}, we can define an intercept equation as \( a = -\ifrac C A \) and \( b = -\ifrac C B \).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:coordinates_of_directional_vector}
  If \( A x + B y + C = 0 \) is a \hyperref[def:plane_line_equations/general]{general equation} of some line, then \( (x_0, y_0) \) is a directional vector of the line if and only if
  \begin{equation*}
    A x_0 + B y_0 = 0.
  \end{equation*}
\end{proposition}
\begin{proof}
  \SufficiencySubProof Suppose that \( (x_0, y_0) \) is a directional vector, and let \( (x_1, y_1) \) be the coordinates of some point on the line. Then \( (x_0 + x_1, y_0 + y_1) \) is also a point, and
  \begin{equation*}
    A x_0 + B y_0 + C = 0 = A (x_0 + x_1) + B (y_0 + y_1) + C.
  \end{equation*}

  Then \( A x_0 + B y_0 = 0 \).

  \NecessitySubProof Suppose that \( A x_0 + B y_0 = 0 \). Let \( (x_1, y_1) \) and be a point on the line. Then
  \begin{equation*}
    A x_1 + B y_1 + C = 0 = A x_0 + B y_0.
  \end{equation*}
  and
  \begin{equation*}
    A (x_1 + t x_0) + B (y_1 + t y_0) + C = A x_1 + B y_1 + C + t (A x_0 + B y_0) = 0.
  \end{equation*}

  That is, \( (x_0, y_0) \) is a directional vector of the line.
\end{proof}

\begin{proposition}\label{thm:parallel_lines_in_plane}
  Let \( A_g x + B_g y + C_g = 0 \) and \( A_h x + B_h y + C_h = 0 \) be the \hyperref[def:plane_line_equations/general]{general equations} of the lines \( g \) and \( h \). The lines are \hyperref[def:affine_parallelism]{parallel} if and only if the vectors \( (A_g, B_g) \) and \( (A_h, B_h) \) are linearly dependent, and they coincide if and only if \( (A_g, B_g, C_g) \) and \( (A_h, B_h, C_h) \) are linearly dependent.
\end{proposition}
\begin{proof}
  \SufficiencySubProof Suppose that \( g \) and \( h \) are parallel, and let \( (x, y) \) be a directional vector for them. Then \Fullref{thm:coordinates_of_directional_vector} implies that
  \begin{equation*}
    0 = A_g x + B_g y = A_h x + B_h y.
  \end{equation*}

  Hence,
  \begin{equation*}
    \begin{pmatrix}
      A_h & B_h \\
      A_g & B_g
    \end{pmatrix}
    \begin{pmatrix}
      x \\ y
    \end{pmatrix}
    =
    \begin{pmatrix}
      0 \\ 0
    \end{pmatrix},
  \end{equation*}
  implying via \fullref{thm:matrix_invertibility} that \( (A_h, B_h) \) and \( (A_g, B_g) \) are linearly dependent.

  Finally, suppose that \( g \) and \( h \) coincide, and let \( (x_0, y_0) \) be a point. We have already shown that there exists some nonzero \( \lambda \) such that \( (A_h, B_h) = \lambda (A_g, B_g) \), thus
  \begin{equation*}
    0 = A_h x_0 + B_h y_0 + C_h = \lambda (A_g x_0 + B_g y_0 + C_g) - \lambda C_g + C_h,
  \end{equation*}
  implying \( C_h = \lambda C_g \).

  \NecessitySubProof Let \( (x_g, y_g) \) and \( (x_h, y_h) \) be directional vectors for \( g \) and \( h \). Then \Fullref{thm:coordinates_of_directional_vector} implies that
  \begin{equation*}
    A_g x_g + B_g y_g = 0 = A_h x_h + B_h y_h.
  \end{equation*}

  Suppose that the vectors \( (A_g, B_g) \) and \( (A_h, B_h) \) are linearly dependent, i.e. there exists some \( \lambda \) such that \( (A_h, B_h) \) and \( \lambda (A_g, B_g) \). Then
  \begin{equation*}
    0 = A_h x_h + B_h y_h = \lambda (A_g x_h) + \lambda (B_g y_h).
  \end{equation*}

  Hence,
  \begin{equation*}
    \begin{pmatrix}
      x_g & y_g \\
      x_h & y_h
    \end{pmatrix}
    \begin{pmatrix}
      A_g \\ B_g
    \end{pmatrix}
    =
    \begin{pmatrix}
      0 \\ 0
    \end{pmatrix}
  \end{equation*}
  implying via \fullref{thm:matrix_invertibility} that \( (x_g, y_g) \) and \( (x_h, y_h) \) are linearly dependent.

  Therefore, \( g \) and \( h \) are parallel lines.

  If, in addition, \( C_h = \lambda C_g \), then for every point \( (x_0, y_0) \) in \( g \),
  \begin{equation*}
    A_h x_0 + B_h y_0 + C_h = \lambda (A_g x_0 + B_g y_0 + C_g) = 0,
  \end{equation*}
  hence \( g \) and \( h \) coincide.
\end{proof}

\begin{proposition}\label{thm:lines_intersect_in_plane}
  Two distinct \hyperref[def:affine_line]{lines} in the Euclidean plane intersect if and only if they are not \hyperref[def:affine_parallelism]{parallel}. Furthermore, non-parallel lines intersect in exactly one point.
\end{proposition}
\begin{proof}
  Let \( A_g x + B_g y + C_g = 0 \) and \( A_h x + B_h y + C_h = 0 \) be the \hyperref[def:plane_line_equations/general]{general equations} of the lines \( g \) and \( h \). Consider the \hyperref[rem:system_of_equations]{system of linear equations}
  \begin{equation}\label{eq:thm:lines_intersect_in_plane/system}
    \begin{pmatrix}
      A_g & B_g \\
      A_h & B_h
    \end{pmatrix}
    \begin{pmatrix}
      x \\ y
    \end{pmatrix}
    =
    -
    \begin{pmatrix}
      C_g \\ C_h
    \end{pmatrix}.
  \end{equation}

  The system has a solution if and only if the lines intersect.

  \SufficiencySubProof If \( g \) and \( h \) intersect, the system \eqref{eq:thm:lines_intersect_in_plane/system} has a solution, and \fullref{thm:kroneker_capelli} implies that the vector \( (C_g, C_h) \) belongs to the column space of the matrix. Then either:
  \begin{itemize}
    \item The lines are parallel and, by \fullref{thm:parallel_lines_in_plane}, the lines coincide --- this contradicts our assumption that the lines are distinct.
    \item The lines are not parallel.
  \end{itemize}

  \NecessitySubProof Suppose that \( g \) and \( h \) are not parallel. \Fullref{thm:parallel_lines_in_plane} implies that the vectors \( (A_g, A_h) \) and \( (B_g, B_h) \) are linearly independent, and \fullref{thm:matrix_invertibility} implies that
  \begin{equation*}
    \begin{pmatrix}
      x \\ y
    \end{pmatrix}
    =
    -
    \begin{pmatrix}
      A_g & B_g \\
      A_h & B_h
    \end{pmatrix}^{-1}
    \begin{pmatrix}
      C_g \\ C_h
    \end{pmatrix}.
  \end{equation*}

  \UniquenessSubProof Suppose that \( g \) and \( h \) are not parallel. \Fullref{thm:parallel_lines_in_plane} implies that the matrix in \eqref{eq:thm:lines_intersect_in_plane/system} is invertible. Then \fullref{thm:system_of_equations_unique_solution} implies that the system has a unique solution.
\end{proof}

\begin{proposition}\label{thm:normal_vector_of_line}
  The vector with coordinates \( (A, B) \) is \hyperref[def:normal_vector]{normal} for the line with \hyperref[def:plane_line_equations/general]{general equation} \( A x + B y + C = 0 \).
\end{proposition}
\begin{proof}
  The vector \( (-B, A) \) is directional for the line as a consequence of \fullref{thm:coordinates_of_directional_vector}. Obviously
  \begin{equation*}
    A(-B) + BA = 0.
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:plane_rotation_matrix}
  \hyperref[def:rigid_motion/rotation]{Rotations} about the origin in the Euclidean plain are \hyperref[def:unitary_matrix]{orthogonal} \( 2 \times 2 \) matrices with \hyperref[def:matrix_determinant]{determinant} \( 1 \), i.e. the \hyperref[def:unitary_groups]{special orthogonal group} \( \grp{SO}(2) \). We call them \term{(plane) rotation matrices}.

  These are the matrices with entries
  \begin{equation}\label{eq:thm:plane_rotation_matrix}
    \begin{pmatrix}
      a & -b \\
      b & a
    \end{pmatrix},
  \end{equation}
  where \( a^2 + b^2 = 1 \).
\end{proposition}
\begin{defproof}
  Let
  \begin{equation*}
    A = \begin{pmatrix}
      a & c \\
      b & d
    \end{pmatrix}
  \end{equation*}
  be an orthogonal matrix with determinant \( 1 \).

  Since \( A \) is orthogonal, its rows are orthogonal. That is, \( ab + cd = 0 \).

  Also, \( \det A = ad - bc = 1 \). Either \( a \) or \( b \) or both must be nonzero, because otherwise \( A \) would be singular.
  \begin{itemize}
    \item If \( a = 0 \), then \( cd = 0 \) and hence either \( c = 0 \) or \( d = 0 \). If \( c = 0 \), then \( \det A = 0 \), which contradicts the assumption that \( \det A = 1 \). Thus, \( c \neq 0 \) and \( d = 0 \).

    Then \( b^2 = c^2 = 1 \) since the columns are normed, and also \( \det A = -bc = -1 < 0 \). Thus, \( \abs{b} = \abs{c} = 1 \) and they have different signs.

    \item If \( a \neq 0 \), then \( b = -\ifrac {cd} a \) and \( ad + \ifrac {c^2 d} a = 1 \). Multiplying both sides by \( a \), we obtain
    \begin{equation*}
      (a^2 + c^2) d = a.
    \end{equation*}

    But \( a^2 + c^2 = 1 \) because the columns of \( A \) are normed. Thus, \( d = a \). It then follows that \( c = -b \).
  \end{itemize}

  In both cases,
  \begin{equation*}
    A
    =
    \begin{pmatrix}
      a & -b \\
      b & a
    \end{pmatrix}
  \end{equation*}
  and also
  \begin{equation*}
    \det A = a^2 + b^2 = 1.
  \end{equation*}
\end{defproof}

\begin{proposition}\label{thm:plane_ray_abscissa_rotation}
  Every \hyperref[def:geometric_ray]{ray} at the origin in the Euclidean plane is a \hyperref[def:rigid_motion/rotation]{rotation} about the origin of the \hyperref[rem:xyz]{abscissa}. Furthermore, this rotation is unique.
\end{proposition}
\begin{proof}
  Let \( r(t) = td \) be some ray and let \( (x, y) \) be the coordinates of the vector \( d \).

  \UniquenessSubProof Suppose that there exist \hyperref[thm:plane_rotation_matrix]{rotation matrices} \( A \) and \( B \) such that
  \begin{equation*}
    \begin{pmatrix} x \\ y \end{pmatrix} = A \begin{pmatrix} 1 \\ 0 \end{pmatrix} = B \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
  \end{equation*}

  Rotation matrices have the form \eqref{eq:thm:plane_rotation_matrix}, and in this case
  \begin{equation*}
    A = B = \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}.
  \end{equation*}

  \ExistenceSubProof The matrix
  \begin{equation*}
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}.
  \end{equation*}
  is obviously a rotation matrix.

  Since \( (1, 0) \) are the coordinates of the abscissa basis vector,
  \begin{equation*}
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}
    \begin{pmatrix}
      1 \\ 0
    \end{pmatrix}
    =
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x \\ y
    \end{pmatrix}.
  \end{equation*}

  This vector is \hyperref[def:geometric_ray/unidirectional]{unidirectional} with \( d \), hence its ray at the origin coincides with \( r \).
\end{proof}

\begin{proposition}\label{thm:plane_ray_rotation}
  For every point \( O \) and every pair of rays \( r(t) = O + td \) to \( s(t) = O + te \) with \( \norm{d} = \norm{e} \), there exists a unique \hyperref[def:rigid_motion/rotation]{rotation} \( f(v) \) through \( O \) sending the image of \( r \) to \( s \). Furthermore, \( s(t) = f(r(t)) \).
\end{proposition}
\begin{proof}
  \SubProof{Proof that \( s = f \bincirc r \)} Suppose that \( \norm{d} = \norm{e} = 1 \). Let \( f(v) = O + T(v - O) \) be a rotation sending the image of \( r(t) \) to the image of \( s(t) \). That is, \( f(\img r) = \img s \), but we do not know how the functions \( f \), \( r \) and \( s \) relate.

  We have
  \begin{equation*}
    f(r(0)) = f(O) = O = s(0).
  \end{equation*}

  Then
  \begin{equation*}
    f(r(t)) = f(O + td) = O + T(O + td - O) = O + t Td.
  \end{equation*}

  Since \( f(\img r) = \img s \), there exists some positive number \( \lambda \) such that \( f(r(1)) = s(\lambda) \). That is,
  \begin{equation*}
    O + Td = f(r(1)) = s(\lambda) = O + \lambda e.
  \end{equation*}

  Note that \( T \) preserves norms as an orthogonal transformation, hence
  \begin{equation*}
    \underbrace{\norm{Td}}_{1} = \lambda \underbrace{\norm{e}}_{1}.
  \end{equation*}

  It follows that \( \lambda = 1 \) and \( e = Td \). Therefore,
  \begin{equation*}
    f(r(t)) = O + t Td = O + te = s(t).
  \end{equation*}

  \UniquenessSubProof Suppose that \( f(v) = O + F(v - O) \) and \( g(v) = O + G(v - O) \) are rotations about \( O \) sending the ray \( r(t) \) to \( s(t) \). Then
  \begin{equation*}
    \vect 0 = s(t) - s(t) = f(r(t)) - g(r(t)) = O + F(v - O) - O - G(v - O).
  \end{equation*}

  Therefore,
  \begin{equation*}
    F(v - O) = G(v - O)
  \end{equation*}
  and
  \begin{equation*}
    (G - F) v = (G - F) O.
  \end{equation*}

  Since this holds for arbitrary \( v \), it is only possible that \( (G - F) v = (G - F) O = \vect 0 \). Thus, \( F = G \) and \( f(v) = g(v) \).

  \ExistenceSubProof \Fullref{thm:plane_ray_abscissa_rotation} implies that there exists a unique rotation \( R \) sending the abscissa to \( \widehat{r}(t) = td \) and \( S \) sending it to \( \widehat{s}(t) = te \).

  Then
  \begin{equation*}
    S^{-1} e
    =
    S^{-1} S \begin{pmatrix} 1 \\ 0 \end{pmatrix}
    =
    R^{-1} R \begin{pmatrix} 1 \\ 0 \end{pmatrix}
    =
    R^{-1} d.
  \end{equation*}

  Hence,
  \begin{equation*}
    e = S R^{-1} d.
  \end{equation*}

  That is, \( T \coloneqq R^{-1} S \) sends \( \widehat{r} \) to \( \widehat{s} \). Then \( v \mapsto O + T(v - O) \) sends \( r \) to \( s \).
\end{proof}

\begin{proposition}\label{thm:plane_rotation_matrix_angle}
  The map
  \begin{equation}\label{eq:thm:plane_rotation_matrix_angle}
    \varphi
    \mapsto
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
  \end{equation}
  is an \hyperref[def:morphism_invertibility/right_cancellative]{epimorphism} from the real numbers under addition to the group of \hyperref[thm:plane_rotation_matrix]{plane rotation matrices} under composition. The kernel of this map is the set of multiples of \( 2\pi \).

  We call \( \varphi \) the \term{angle} of the rotation; the semantics of the word \enquote{angle} are discussed in \fullref{def:angle}.

  There are other groups isomorphic to the rotation group --- see \fullref{def:circle_group}.
\end{proposition}
\begin{proof}
  \SubProof{Proof of well-definedness} The matrix \eqref{eq:thm:plane_rotation_matrix_angle} is orthogonal, and its determinant is \( 1 \) as a consequence of \fullref{thm:trigonometric_identities/pythagorean_identity}. Hence, it induces a rotation.

  \SubProofOf[def:function_invertibility/surjective/equality]{surjectivity} Let
  \begin{equation*}
    A
    =
    \begin{pmatrix}
      a & -b \\
      b & c
    \end{pmatrix}
  \end{equation*}
  be a rotation matrix; i.e. \( \det A = a^2 + b^2 = 1 \). Every rotation matrix has this form as discussed in \fullref{thm:plane_rotation_matrix}.

  Define \( \varphi \) as
  \begin{equation*}
    \varphi \coloneqq \begin{cases}
      \arccos a,         &b \geq 0, \\
      2 \pi - \arccos a, &b < 0.
    \end{cases}
  \end{equation*}

  Then
  \begin{equation*}
    (\sin \varphi)^2 = 1 - (\cos \varphi)^2 = 1 - a^2 = b^2.
  \end{equation*}

  \begin{itemize}
    \item If \( b \geq 0 \), then \( \varphi \in [0, \pi] \) and hence \( \sin \varphi \geq 0 \). Since the square root has nonnegative values,
    \begin{equation*}
      \sin \varphi = \sqrt{ 1 - a^2 } = b.
    \end{equation*}

    \item If \( b < 0 \), then \( \varphi \in [\pi, 2\pi) \) and hence \( \sin \varphi < 0 \). Thus,
    \begin{equation*}
      \sin \varphi = -\sqrt{ 1 - a^2 } = b.
    \end{equation*}
  \end{itemize}

  Therefore,
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    =
    \begin{pmatrix}
      a & -b \\
      b & a
    \end{pmatrix}
    =
    A.
  \end{equation*}

  \SubProof{Proof of homomorphism condition} We have
  \begin{equation*}
    \cos(\varphi + \psi)
    \reloset {\eqref{eq:thm:trigonometric_identities/sum_of_angles/cos}} =
    \cos \varphi \cos \psi - \sin \varphi \sin \psi
    =
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \cos \psi \\ \sin \psi
    \end{pmatrix}.
  \end{equation*}
  and
  \begin{equation*}
    \sin(\varphi + \psi)
    \reloset {\eqref{eq:thm:trigonometric_identities/sum_of_angles/cos}} =
    \cos \varphi \sin \psi + \sin \varphi \cos \psi
    =
    \begin{pmatrix}
      \cos \varphi & \sin \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \sin \psi \\ \cos \psi
    \end{pmatrix}.
  \end{equation*}

  Then
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \cos \psi & -\sin \psi \\
      \sin \psi & \cos \psi
    \end{pmatrix}
    =
    \begin{pmatrix}
      \cos (\varphi + \psi) & -\sin (\varphi + \psi) \\
      \sin (\varphi + \psi) & \cos (\varphi + \psi)
    \end{pmatrix}.
  \end{equation*}

  \SubProof{Proof that kernel are multiples of \( 2\pi \)} Suppose that
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    =
    \begin{pmatrix}
      \cos \psi & -\sin \psi \\
      \sin \psi & \cos \psi
    \end{pmatrix}.
  \end{equation*}

  Both \( \sin \) and \( \cos \) are bijective on the interval \( [0, 2\pi) \). From \fullref{thm:trigonometric_function_period} it follows that, if \( \cos \varphi = \cos \psi \), then \( 2\pi \) divides \( \varphi - \psi \).
\end{proof}

\begin{definition}\label{def:angle}\mimprovised
  A \term{directed angle} is an ordered pair of \hyperref[def:geometric_ray]{rays} with a common vertex. We say that the rays are the \term{sides} of the angle and denote the angle with sides \( r \) and \( s \) via \( \angle(r, s) \).

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__angle}
    \caption{The two \hyperref[def:angle]{directed angles} \( \angle(r, s) \) and \( \angle(r, s) \) given by the rays \( r \) and \( s \).}\label{def:angle/measure/figure}
  \end{figure}

  \begin{thmenum}
    \thmitem{def:angle/measure} Denote by \( O \) the common vertex of \( r \) and \( s \). \Fullref{thm:plane_ray_rotation} implies that there exists a unique \hyperref[def:rigid_motion/rotation]{rotation} \( f(v) = O + T(v - O) \) sending \( r \) to \( s \). \Fullref{thm:plane_rotation_matrix_angle} then implies the existence of a unique number \( \varphi \in [0, 2\pi) \) entirely determining \( T \). We will call \( \varphi \) the \term{measure} of \( \angle(r, s) \) and denote it by \( \measuredangle(r, s) \)

    We can classify angles based on their measure as
    \begin{thmenum}
      \thmitem{def:angle/measure/zero} \term{zero} if \( \varphi = 0 \),

      \medspace

      \thmitem{def:angle/measure/acute}\mcite[\textnumero 16]{Saul2008Hadamard} \term[bg=остър (\cite[9]{Гюзелев1873}), ru=острый (\cite[\textnumero 22]{Киселёв2009})]{acute} if \( 0 < \varphi < \ifrac \pi 2 \),

      \medspace

      \thmitem{def:angle/measure/right} \term[bg=прав (\cite[9]{Гюзелев1873}), ru=прямой (\cite[\textnumero 22]{Киселёв2009})]{right} if \( \varphi = \tfrac \pi 2 \),

      \medspace

      \thmitem{def:angle/measure/obtuse}\mcite[\textnumero 16]{Saul2008Hadamard} \term[bg=тъп (\cite[9]{Гюзелев1873}), ru=тупой (\cite[\textnumero 22]{Киселёв2009})]{obtuse} if \( \ifrac \pi 2 < \varphi < \pi \),

      \medspace

      \thmitem{def:angle/measure/straight}\mcite[\textnumero 15]{Saul2008Hadamard} \term{straight} if \( \varphi = \pi \), in which case the angle is actually a line,

      \medspace

      \thmitem{def:angle/measure/reflex} \term{reflex} if \( \varphi > \pi \).
    \end{thmenum}

    \begin{figure}[!ht]
      \centering
      \includegraphics[align=c]{output/def__angle__measure__right}
      \caption{A \hyperref[def:angle/measure/right]{right angle} is conventionally denoted via dots.}\label{fig:def:angle/measure/right}
    \end{figure}

    \thmitem{def:angle/vectors} It is conventional to conflate an angle and its measure. For this reason, it is sometimes convenient to define angles via directional vectors rather than rays, disregarding the vertex.

    We call vectors determining the rays \term{directional vectors} of the angle.

    \thmitem{def:angle/undirected} Given the transformation \( f(v) \) sending \( r \) to \( s \), its inverse \( f^{-1}(v) \) sends \( s \) to \( r \). Their composition is the identity, whose angle measure is a multiple \( 2\pi \). \Fullref{thm:plane_rotation_matrix_angle} implies that the angle measures \( \angle(r, s) \) and \( \angle(s, r) \) sum to \( 2\pi \). We call the angle with the smaller measure the \term{undirected angle} between \( r \) and \( s \).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:cosine_of_angle_measure}
  The \hyperref[def:angle/measure]{measure} of an angle \( \angle(u, v) \) between the normed vectors \( u \) and \( v \) satisfies
  \begin{equation}\label{eq:thm:cosine_of_angle_measure/cos}
    \cos \measuredangle(r, s) = \inprod u v.
  \end{equation}

  Furthermore, denoting by \( y_u \) and \( y_v \) the ordinates of \( u \) and \( v \),
  \begin{equation}\label{eq:thm:cosine_of_angle_measure/arccos}
    \measuredangle(r, s) = \begin{cases}
      \arccos \inprod u v,        &y_v \geq y_u, \\
      2\pi - \arccos \inprod u v, &y_v < y_u.
    \end{cases}
  \end{equation}
\end{proposition}
\begin{proof}
  \Fullref{thm:cauchy_bunyakovsky_schwarz_inequality} implies that \( \inprod u v \) ranges between \( -1 \) and \( 1 \); hence, it is the cosine of a real number.

  \Fullref{thm:plane_ray_abscissa_rotation} gives us an angle measure \( \beta \) whose rotation sends the abscissa into \( u \), and a similar angle measure \( \gamma \) for \( v \). Then \( \angle(u, v) = \gamma - \beta \) The coordinates of \( u \) are
  \begin{equation*}
    \begin{pmatrix}
      \cos \beta & -\sin \beta \\
      \sin \beta & \cos \beta
    \end{pmatrix}
    \begin{pmatrix}
      1 \\ 0
    \end{pmatrix}
    =
    \begin{pmatrix}
      \cos \beta \\ \sin \beta
    \end{pmatrix},
  \end{equation*}
  and similarly for \( v \).

  Then
  \begin{align*}
    \inprod u v
    &=
    \cos \beta \cos \gamma + \sin \beta \sin \gamma
    \reloset {\ref{thm:trigonometric_identities/products}} = \\ &=
    \tfrac 1 2 [\cos(\beta - \gamma) + \cos(\beta + \gamma) + \cos(\beta - \gamma) - \cos(\beta + \gamma)]
    = \\ &=
    \cos(\beta - \gamma)
    = \\ &=
    \cos(\gamma - \beta)
    = \\ &=
    \cos \measuredangle(u, v).
  \end{align*}

  If \( y_v \geq y_u \), then \( \measuredangle(u, v) = \arccos \inprod u v \). We have
  \begin{equation*}
    \abs{\sin \measuredangle(u, v)}
    =
    \abs{\sin \arccos \inprod u v}
    =
    \sqrt{1 - \inprod u v^2}.
  \end{equation*}

  Since \( 0 \leq \measuredangle(u, v) \leq \pi \), we have \( \sin \measuredangle(u, v) \geq 0 \) and
  \begin{equation*}
    \sin \measuredangle(u, v) = \sqrt{1 - \inprod u v^2}.
  \end{equation*}

  Otherwise, \( \measuredangle(u, v) = 2\pi - \arccos \inprod u v \). We have
  \begin{equation*}
    \abs{\sin \measuredangle(u, v)}
    \reloset{\ref{thm:trigonometric_function_period}} =
    \abs{\sin(-\arccos \inprod u v)}
    \reloset{\ref{thm:def:trigonometric_function/parity}} =
    \abs{-\sin(\arccos \inprod u v)}
    =
    \sqrt{1 - \inprod u v^2}.
  \end{equation*}

  Since \( \pi \leq \measuredangle(u, v) \leq 2\pi \), we have \( \sin \measuredangle(u, v) \leq 0 \) and
  \begin{equation*}
    \sin \measuredangle(u, v) = -\sqrt{1 - \inprod u v^2}.
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:arctantwo}
  The measure of a directed angle between the abscissa and the ray with directional vector \( v = (x, y) \) is
  \begin{equation}
    \angle(Ox, v) = \arctantwo(y, x),
  \end{equation}
  where
  \begin{equation*}
    \begin{aligned}
       &\arctantwo: \BbbR^2 \setminus \set{ \vect 0 } \to [-\pi, \pi), \\
       &\arctantwo(y, x) \coloneqq \begin{cases}
        \arctan(\ifrac y x),                     &x > 0, \\
        \arctan(\ifrac y x) + \sgn(y) \cdot \pi, &x < 0 \T{and} y \neq 0, \\
        \pi,                                     &x < 0 \T{and} y = 0, \\
        \sgn(y) \cdot \ifrac \pi 2,              &x = 0. \\
      \end{cases}
    \end{aligned}
  \end{equation*}

  We take the branch of \( \arctan \) with values \( [-\ifrac \pi 2, \ifrac \pi 2) \).

  The name of the function comes from the \( \logic{FORTRAN} \) programming language and the suffix \enquote{2} highlights that the function has two arguments rather than one.
\end{proposition}
\begin{proof}
  \hfill
  \begin{itemize}
    \item If \( x > 0 \), then
    \begin{equation*}
      \cos(\arctantwo(y, x))
      =
      \cos(\arctan(\ifrac y x))
      \reloset {\eqref{eq:thm:def:inverse_trigonometric_function/cos_of_arctan}} =
      \frac 1 {\sqrt{1 + \ifrac {y^2} {x^2}}}
      =
      \frac x {\sqrt{x^2 + y^2}}
    \end{equation*}
    and
    \begin{equation*}
      \sin(\arctantwo(y, x))
      =
      \sin(\arctan(\ifrac y x))
      \reloset {\eqref{eq:thm:def:inverse_trigonometric_function/sin_of_arctan}} =
      \frac {\ifrac y x} {\sqrt{1 + \ifrac {y^2} {x^2}}}
      =
      \frac y {\sqrt{x^2 + y^2}}.
    \end{equation*}

    Then \( \arctantwo(y, x) \) is the angle of the unique rotation sending the abscissa to \( v \).

    \item If \( x < 0 \) and \( y \neq 0 \), then
    \begin{align*}
      \cos(\arctantwo(y, x))
      &=
      \cos(\arctan(\ifrac y x) + \sgn(y) \cdot \pi)
      \reloset {\eqref{eq:thm:trigonometric_function_period_identities/full/cos}} = \\ &=
      -\cos(\arctan(\ifrac y x))
      = \\ &=
      -\frac 1 {\sqrt{1 + \ifrac {y^2} {x^2}}}
      = \\ &=
      -\frac 1 {\ifrac 1 {(-x)} \cdot \sqrt{x^2 + y^2}}
      = \\ &=
      \frac x {\sqrt{x^2 + y^2}}.
    \end{align*}
    and similarly
    \begin{equation*}
      \sin(\arctantwo(y, x))
      =
      \sin(\arctan(\ifrac y x)  + \sgn(y) \cdot \pi)
      \reloset {\eqref{eq:thm:trigonometric_function_period_identities/full/sin}} =
      -\sin(\arctan(\ifrac y x))
      =
      \cdots
      =
      \frac y {x^2 + y^2}.
    \end{equation*}

    \item If \( x < 0 \) and \( y = 0 \), then
    \begin{equation*}
      \cos(\arctantwo(y, x)) = \cos \pi = -1
    \end{equation*}
    and
    \begin{equation*}
      \sin(\arctantwo(y, x)) = \sin \pi = 0.
    \end{equation*}

    \item If \( x = 0 \), then
    \begin{equation*}
      \cos(\arctantwo(y, x)) = \cos(\sgn(y) \cdot \ifrac \pi 2) = 0.
    \end{equation*}
    and
    \begin{equation*}
      \sin(\arctantwo(y, x)) = \sin(\sgn(y) \cdot \ifrac \pi 2) = \sgn(y) \cdot 1.
    \end{equation*}
  \end{itemize}
\end{proof}

\begin{definition}\label{def:perpendicularity}\mimprovised
  We say that two vectors are \term{perpendicular} if the \hyperref[def:angle/undirected]{undirected angle} between them is \hyperref[def:angle/measure/right]{right}.

  \begin{thmenum}
    \thmitem{def:perpendicularity/directional} The definition also applies to rays and lines if we take their directional vectors.
    \thmitem{def:perpendicularity/subspace} The term \enquote{perpendicular from a point to an affine subspace} refers to the segment from the point to its \hyperref[def:orthogonal_projection]{orthogonal projection} onto the subspace.
  \end{thmenum}
\end{definition}
\begin{comments}
  \item This is the geometric analog of \hyperref[def:orthogonality]{orthogonality}.
\end{comments}

\begin{proposition}\label{thm:perpendicular_iff_orthogonal}
  Two vectors are \hyperref[def:orthogonality]{orthogonal} if and only if they are \hyperref[def:perpendicularity/directional]{perpendicular}.
\end{proposition}
\begin{proof}
  For the angle \( \angle(u, v) \), we have
  \begin{equation*}
    \cos \measuredangle(u, v)
    \reloset {\eqref{eq:thm:cosine_of_angle_measure/cos}} =
    \inprod u v.
  \end{equation*}

  Then \( \measuredangle(u, v) = \ifrac \pi 2 \) if and only if \( \cos(\measuredangle(u, v)) = 0 \) if and only if \( \inprod u v = 0 \).
\end{proof}

\begin{proposition}\label{thm:straight_iff_opposite_rays}
  An angle is \hyperref[def:angle/measure/straight]{straight} if and only if its sides are \hyperref[def:geometric_ray/opposite]{opposite rays}.
\end{proposition}
\begin{proof}
  \SufficiencySubProof Suppose that the angle \( \angle(r, s) \) is straight. Let \( O \) be the vertex and let \( r(t) = O + td \) and \( s(t) = O + te \) be parametrizations of the rays.

  We have assumed that the measure of the angle is \( \pi \). \Fullref{thm:cosine_of_angle_measure} implies that
  \begin{equation*}
    \frac {\inprod d e} {\norm{d} \cdot \norm{e}} = \cos(\pi) = -1.
  \end{equation*}

  \Fullref{thm:cauchy_bunyakovsky_schwarz_inequality} implies that \( d \) and \( e \) are linearly dependent. We have two possibilities:
  \begin{itemize}
    \item If \( e = \ifrac {\norm e} {\norm d} \cdot d \), then \( r(t) \) and \( s(t) \) describe the same set of points, and thus the rotation between them is the identity matrix. But the identity matrix induces an angle with measure zero, and we have assumed that the measure is \( \pi \).

    \item It remains for \( e \) to be \( - \ifrac {\norm e} {\norm d} \cdot d \).
  \end{itemize}

  Therefore, the rays \( r(t) \) and \( s(t) \) are opposite.

  \NecessitySubProof Suppose that \( r(t) = O + td \) and \( s(t) = O + te \) are opposite rays. Denote the measure of \( \angle(r, s) \) via \( \alpha \). Then
  \begin{equation*}
    \cos(\alpha)
    =
    \frac {\inprod d e} {\norm{d} \cdot \norm{e}}
    =
    -\frac {\inprod d {\norm{e} d}} {\norm{d} \cdot \norm{d} \cdot \norm{e}}
    =
    -\frac {\inprod d d} {\norm{d}^2}
    =
    -1.
  \end{equation*}

  The only number in \( [0, 2\pi) \) with this property is \( \pi \). Hence, the angle \( \angle(r, s) \) is straight.
\end{proof}

\begin{definition}\label{def:adjacent_angles}\mcite[\textnumero 10]{Saul2008Hadamard}
  We say that two \hyperref[def:angle]{undirected angles} with a common vertex are \term[bg=съседен (\cite[\textparagraph 5]{Гюзелев1873}), ru=смежный (\cite[\textnumero 22]{Киселёв2009})]{adjacent} if they have a common side and if their other sides lie on different \hyperref[def:half_space]{half-planes} with respect to (the line containing) their common side.

  We avoid introducing similar terminology for directed angles.

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__adjacent_angles}
    \caption{The undirected angles \( \angle(r, p) \) and \( \angle(p, s) \) are adjacent.}\label{fig:def:adjacent_angles}
  \end{figure}
\end{definition}

\begin{definition}\label{def:sum_of_angles}
  Fix three rays \( p \), \( r \) and \( s \) with a common vertex \( O \). We call the (directed) angle \( \angle(r, s) \) the \term[bg=сума (\cite[8]{Гюзелев1873}), ru=сумма (\cite[\textnumero 15]{Киселёв2009})]{sum} of \( \angle(r, p) \) and \( \angle(p, s) \).

  If the angles are undirected, we only consider sums if the addends are \hyperref[def:adjacent_angles]{adjacent}.

  \begin{figure}[!ht]
    \hfill
    \includegraphics[align=c]{output/def__sum_of_angles__acute}
    \hfill
    \includegraphics[align=c]{output/def__sum_of_angles__obtuse}
    \hfill
    \hfill
    \caption{Sum of two directed angles. The first is also a sum of the corresponding undirected angles.}\label{fig:def:sum_of_angles}
  \end{figure}
\end{definition}

\begin{proposition}\label{thm:sum_of_angles_measure}
  The \hyperref[def:sum_of_angles]{angle sum} of \( \angle(r, p) \) and \( \angle(p, s) \) satisfies the following \hyperref[rem:congruence_modulo_real_number]{congruence} of \hyperref[def:angle/measure]{angle measures}:
  \begin{equation*}
    \measuredangle(r, s) \equiv \measuredangle(r, p) + \measuredangle(p, s) \pmod {2\pi}.
  \end{equation*}
\end{proposition}
\begin{proof}
  Let \( f(v) = o + F(v - o) \) be the operator sending \( r \) to \( p \) given by \fullref{thm:plane_ray_rotation} and \( g(v) = o + G(v - o) \) be the map from \( p \) to \( s \). Then, when regarding the rays as parametric curves,
  \begin{equation*}
    [g \bincirc f](r(t)) = g(f(r(t))) = g(p(t)) = s(t),
  \end{equation*}
  thus \( g \bincirc f \) is an affine map sending \( r \) to \( s \).

  Furthermore,
  \begin{equation*}
    [g \bincirc f](v)
    =
    o + G(f(v) - o)
    =
    o + G(o + F(v - o) - o)
    =
    o + GF(v - o),
  \end{equation*}
  hence \fullref{thm:plane_ray_rotation} implies that \( g \bincirc f \) is the \hi{unique} affine map with a rotation sending \( r \) to \( s \).

  We know from \fullref{thm:plane_rotation_matrix_angle} that the angle of the rotation \( GF \) is the sum of angles of \( G \) and \( F \). This concludes the proof.
\end{proof}

\begin{definition}\label{def:vertical_angles}\mcite[\textnumero 12]{Saul2008Hadamard}
  Let \( g \) and \( h \) be \hyperref[def:crossing_lines]{crossing lines} with intersection point \( O \).

  Let \( P \) and \( Q \) be arbitrary points from \( g \) and \( h \) distinct from \( O \); let \( P' \) and \( Q' \) be their \hyperref[def:rigid_motion/point_reflection]{point reflections} through \( O \).

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__angles_of_crossing}
    \caption{The angles \( \angle(\vect{OP}, \vect{OQ}) \) and \( \angle(\vect{OP'}, \vect{OQ'}) \) are \hyperref[def:vertical_angles]{vertical}.}\label{fig:def:vertical_angles}
  \end{figure}

  We say that \( \angle(\vect{OP}, \vect{OQ}) \) and \( \angle(\vect{OP'}, \vect{OQ'}) \) are a pair of \term[bg=вертикални/срещуположни ъгли (\cite[\textparagraph 7]{Гюзелев1873}), ru=вертикальные углы (\cite[\textnumero 26]{Киселёв2009})]{vertical angles}, and similarly for \( \angle(\vect{OP}, \vect{OQ'}) \) and \( \angle(\vect{OP'}, \vect{OQ}) \).
\end{definition}

\begin{proposition}\label{thm:vertical_angles_are_equal}
  Every two \hyperref[def:vertical_angles]{vertical angles} have equal \hyperref[def:angle/measure]{measures}.
\end{proposition}
\begin{proof}
  \Fullref{thm:perpendicular_iff_orthogonal} implies that \( \measuredangle(\vect{OP}, \vect{OP'}) = \pi \).

  \Fullref{thm:sum_of_angles_measure} implies that
  \begin{equation*}
    \measuredangle(\vect{OP}, \vect{OQ}) + \measuredangle(\vect{OP'}, \vect{OQ}) = \measuredangle(\vect{OP}, \vect{OP'}) = \pi
  \end{equation*}
  and similarly
  \begin{equation*}
    \measuredangle(\vect{OP'}, \vect{OQ}) + \measuredangle(\vect{OP'}, \vect{OQ'}) = \pi.
  \end{equation*}

  Then
  \begin{equation*}
    0 = \pi - \pi = \measuredangle(\vect{OP}, \vect{OQ}) - \measuredangle(\vect{OP'}, \vect{OQ'}),
  \end{equation*}
  hence
  \begin{equation*}
    \measuredangle(\vect{OP}, \vect{OQ}) = \measuredangle(\vect{OP'}, \vect{OQ'}).
  \end{equation*}

  We can prove the other equality analogously.
\end{proof}

\begin{proposition}\label{thm:angle_with_inverse_vectors}
  For any three \hyperref[def:affine_dependence]{affinely independent} points \( P \), \( Q \) and \( R \), the angles \( \angle(\vect{PQ}, \vect{PR}) \) and \( \angle(\vect{RP}, \vect{RQ}) \) are \hyperref[def:vertical_angles]{vertical}.
\end{proposition}
\begin{comments}
  \item In particular, by \fullref{thm:vertical_angles_are_equal}, they have equal measures.
\end{comments}
\begin{proof}
  We have
  \begin{equation*}
    \vect{PQ} = Q - P = 2Q - P - Q = \vect{Q(2Q - P)},
  \end{equation*}
  where \( 2Q - P \) is the \hyperref[def:rigid_motion/point_reflection]{point reflection} of \( P \) through \( Q \).

  Similarly, we have \( \vect{PR} = \vect{R(2R - P)} \).

  Furthermore, the two vectors are linearly independent since the points are affinely independent.

  Then the angles \( \angle(\vect{PQ}, \vect{PR}) \) and
  \begin{equation*}
    \angle(\vect{QP}, \vect{RP}) = \angle(\vect{Q(2Q - P)}, \vect{R(2R - P)})
  \end{equation*}
  are vertical.
\end{proof}

\begin{remark}\label{rem:angle}
  To recap, the word \enquote{angle} may refer to:
  \begin{itemize}
    \item The unique real number from \( [0, 2\pi) \) inducing a rotation as shown in \fullref{thm:plane_rotation_matrix_angle}.
    \item Either a \hyperref[def:angle]{directed angle} or its \hyperref[def:angle/measure]{measure}.
    \item Either an \hyperref[def:angle]{undirected angle} or its measure.
    \item The angle of a line crossing discussed in \fullref{thm:vertical_angles_are_equal}.
  \end{itemize}
\end{remark}

\begin{definition}\label{def:angles_of_transversal}\mcite[\textnumero 37]{Saul2008Hadamard}
  Let \( l \) be a \hyperref[def:transversal_line]{transversal} of the distinct lines \( g \) and \( h \). Suppose that, if \( g \) and \( h \) intersect, \( l \) does not pass through their intersection.

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__angles_of_transversal}
    \caption{A transversal crossing two lines (with some of the distances shortened).}\label{fig:def:angles_of_transversal}
  \end{figure}

  Let \( P \) be the crossing point of \( g \) and \( l \) and let \( P' \) be the \hyperref[def:orthogonal_projection]{orthogonal projection} of \( P \) onto \( h \).

  Similarly, let \( Q \) be the crossing point of \( h \) and \( l \) and let \( Q' \) be the projection of \( Q \) onto \( g \).

  We introduce the following terminology for the eight (undirected) angles of the intersection:
  \begin{thmenum}
    \thmitem{def:angles_of_transversal/interior} We say that an angle is \term{interior} if it lies in the intersection of the half-plane of \( g \) containing \( Q \) and the half-plane of \( h \) containing \( P \).

    For example, the angles \( \angle(\vect{PQ}, \vect{PQ'}) \) and \( \angle(\vect{QP}, \vect{QP'}) \) are interior.

    \thmitem{def:angles_of_transversal/exterior} We say that an angle is \term{exterior} if it is not interior.

    For example, the angles \( \angle(\vect{P(2P - Q)}, \vect{PQ'}) \) and \( \angle(\vect{Q(2Q - P)}, \vect{QP'}) \) are exterior.

    \thmitem{def:angles_of_transversal/alternate} We say that two \hi{non-\hyperref[def:adjacent_angles]{adjacent}} angles are \term[bg={кръстни, кръстосани (\cite[\textparagraph 28]{Гюзелев1873})}, ru=накрестлежащие (\cite[\textnumero 72]{Киселёв2009})]{alternate} if they lie in different half-planes with respect to \( l \) and are both either interior or exterior.

    For example, \( \angle(\vect{PQ}, \vect{PQ'}) \) and \( \angle(\vect{QP}, \vect{QP')}) \) is a pair of interior alternate angles, while their corresponding pair of \hyperref[def:vertical_angles]{vertical angles} \( \angle(\vect{P(2P - Q)}, \vect{P(2P - Q')}) \) and \( \angle(\vect{Q(2Q - P)}, \allowbreak \vect{Q(2Q - P')}) \) is exterior alternate.

    \thmitem{def:angles_of_transversal/corresponding} We say that two \hi{non-\hyperref[def:adjacent_angles]{adjacent}} angles are \term[bg=съответни (\cite[\textparagraph 28]{Гюзелев1873}), ru=соответственные (\cite[\textnumero 72]{Киселёв2009})]{corresponding} if they lie in different in the same half-plane with respect to \( l \) and one of them is internal, while the other is external.

    For example, the \( \angle(\vect{PQ}, \vect{PQ'}) \) and \( \angle(\vect{Q(2Q - P)}, \vect{Q(2Q - P')}) \) is a pair of corresponding angles.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:angles_of_transversal_parallel_lines}
  Let \( l \) be a \hyperref[def:transversal_line]{transversal} of the distinct lines \( g \) and \( h \). Suppose that, if \( g \) and \( h \) intersect, \( l \) does not pass through their intersection.

  Then the following are equivalent:
  \begin{thmenum}
    \thmitem{thm:angles_of_transversal_parallel_lines/parallel} The lines \( g \) and \( h \) are \hyperref[def:affine_parallelism]{parallel}.
    \thmitem{thm:angles_of_transversal_parallel_lines/alternate} Any two \hyperref[def:angles_of_transversal/alternate]{alternate angles} have equal measures.
    \thmitem{thm:angles_of_transversal_parallel_lines/corresponding} Any two \hyperref[def:angles_of_transversal/corresponding]{corresponding angles} have equal measures.
  \end{thmenum}
\end{proposition}
\begin{proof}
  \ImplicationSubProof{thm:angles_of_transversal_parallel_lines/parallel}{thm:angles_of_transversal_parallel_lines/alternate} Suppose that \( g \) and \( h \) are parallel. The vectors \( \vect{PQ'} \) and \( \vect{P'Q} \) are collinear and there exists some scalar \( a \) such that \( \vect{P'Q} = a \cdot \vect{PQ'} \).

  It follows from \fullref{thm:def:orthogonal_projection/normal} it follows that \( \vect{PP'} \) is normal for \( h \). Then \( \vect{PP'} \) is orthogonal to \( \vect{P'Q} \), and hence also to \( \vect{PQ'} \). \Fullref{thm:perpendicular_iff_orthogonal} implies that the angle \( \angle(\vect{PQ'}, \vect{PP'}) \) is right.

  \Fullref{thm:sum_of_angles_measure} implies that
  \begin{equation*}
    \underbrace{\measuredangle(\vect{PQ'}, \vect{PP'})}_{\ifrac \pi 2} = \measuredangle(\vect{PQ'}, \vect{PQ}) + \measuredangle(\vect{PQ}, \vect{PP'}) \pmod {2\pi}.
  \end{equation*}

  All angles are undirected and thus have a measure at most \( \pi \). It follows that both \( \angle(\vect{PQ'}, \vect{PQ}) \) and \( \angle(\vect{PQ}, \vect{PP'}) \) must be acute.

  Similarly, we can conclude that \( \angle(\vect{QP'}, \vect{QP}) \) is acute, and hence so is its vertical \( \angle(P'Q, PQ) \).

  The value of \( \cos(t) \) for \( 0 < t < \ifrac \pi 2 \) is positive. Hence, \( \cos(\measuredangle(\vect{PQ}, \vect{P'Q})) \) and \( \cos(\measuredangle(\vect{PQ}, \vect{PQ'})) \) are both positive because both angles are acute.

  Since \( \vect{P'Q} = a \cdot \vect{PQ'} \), \fullref{thm:cosine_of_angle_measure} implies that
  \begin{equation*}
    \cos(\measuredangle(\vect{PQ}, \vect{P'Q}))
    =
    \frac {\inprod {\vect{PQ}} {\vect{P'Q}}} {\norm{\vect{PQ}} \cdot \norm{\vect{P'Q}}}
    =
    \frac a {\abs{a}} \cdot \frac {\inprod {\vect{PQ}} {\vect{PQ'}}} {\norm{\vect{PQ}} \cdot \norm{\vect{PQ'}}}
    =
    \sgn(a) \cdot \cos(\measuredangle(\vect{PQ}, \vect{PQ'}))
  \end{equation*}

  Both cosines are positive, hence \( a \) must itself be positive. We conclude that \( \vect{P'Q} = \vect{PQ'} \).

  Therefore,
  \begin{equation*}
    \measuredangle(\vect{PQ}, \vect{PQ'})
    =
    \measuredangle(\vect{PQ}, \vect{P'Q})
    \reloset {\ref{thm:angle_with_inverse_vectors}} =
    \measuredangle(\vect{QP}, \vect{QP'}).
  \end{equation*}

  This shows that two of the internal alternate angles are equal. \Fullref{thm:vertical_angles_are_equal} implies that their vertical angles, which are external alternate, are also equal. \Fullref{thm:sum_of_angles_measure} and \fullref{thm:perpendicular_iff_orthogonal} imply that the other pairs of alternate angles are equal.

  \ImplicationSubProof{thm:angles_of_transversal_parallel_lines/alternate}{thm:angles_of_transversal_parallel_lines/corresponding} If two alternate angles have equal measures, from \fullref{thm:vertical_angles_are_equal} it follows that the first angle and the vertical angle of the second also have equal measures. The aforementioned two angles are corresponding.

  \ImplicationSubProof{thm:angles_of_transversal_parallel_lines/corresponding}{thm:angles_of_transversal_parallel_lines/parallel} Suppose that some pair of corresponding angles have equal measures. Then \fullref{thm:vertical_angles_are_equal} implies that their vertical angles also have equal measures, and \fullref{thm:sum_of_angles_measure} and \fullref{thm:perpendicular_iff_orthogonal} imply that the other pairs of corresponding angles also do. Hence, every two corresponding angles have equal measures.

  In particular, \( \angle(\vect{PQ}, \vect{PQ'}) \) and \( \angle(\vect{Q(2Q - P)}, \vect{Q(2Q - P')}) \) have equal measures, the latter angle being the same as to \( \angle(\vect{PQ}, \vect{P'Q'}) \). Hence,
  \begin{equation*}
    \measuredangle(\vect{PQ}, \vect{PQ'}) = \measuredangle(\vect{PQ}, \vect{P'Q}).
  \end{equation*}

  The angle \( \angle(\vect{QP}, \vect{P'Q}) = \angle(\vect{QP}, \vect{Q(2Q - P')}) \) is adjacent to \( \angle(\vect{QP}, \vect{QP'}) \) and the two sum to a straight angle. Hence,
  \begin{equation*}
    \underbrace{\measuredangle(\vect{QP}, \vect{QP'})}_{\measuredangle(\vect{PQ}, \vect{P'Q})} = \pi - \measuredangle(\vect{QP}, \vect{P'Q}),
  \end{equation*}
  thus, combining with the above gives us
  \begin{equation*}
    \measuredangle(\vect{PQ}, \vect{PQ'}) = \measuredangle(\vect{PQ}, \vect{P'Q}) = \pi - \measuredangle(\vect{QP}, \vect{P'Q}).
  \end{equation*}

  Aiming at a contradiction, suppose that \( g \) and \( h \) intersect at some point \( R \). Consider the \( \angle(\vect{PQ}, \vect{PQ'}) = \angle(\vect{PQ}, \vect{PR}) \).

  We will now do a partial proof of \fullref{thm:sum_of_triangle_angles}. Consult \cref{fig:thm:sum_of_triangle_angles}.

  Let \( k \) be a line through \( R \) parallel to \( l \) and let \( P^\dprime \) and \( Q^\dprime \) be the orthogonal projections of \( P \) and \( Q \) on \( k \). Note that \( R \) lies on the line segment between \( P^\dprime \) and \( Q^\dprime \) because the orthogonal projection reduces to a translation.

  Then \fullref{thm:angles_of_transversal_parallel_lines/parallel} holds for \( g \) intersecting the parallel lines \( k \) and \( l \), and hence \fullref{thm:angles_of_transversal_parallel_lines/alternate} implies that the angles \( \angle(\vect{PQ}, \vect{PR}) \) and \( \angle(\vect{RP}, \vect{RP^\dprime}) \) have equal measures as interior alternate angles.

  Similarly, we conclude that \( \angle(\vect{QP}, \vect{QR}) \) and \( \angle(\vect{RQ}, \vect{RQ^\dprime}) \) have equal measures.

  Since \( \angle(\vect{RP^\dprime}, \vect{RQ^\dprime}) \) is a straight angle, it follows from \fullref{thm:sum_of_angles_measure} that
  \begin{equation*}
    \angle(\vect{RP}, \vect{RQ}) = \pi - \angle(\vect{PQ}, \vect{PR}) - \angle(\vect{QP}, \vect{QR})
  \end{equation*}

  We have the following possibilities:
  \begin{itemize}
    \item If \( \vect{PR} \) is unidirectional with \( \vect{PQ'} \), then \( \measuredangle(\vect{PQ}, \vect{PR}) = \measuredangle(\vect{PQ}, \vect{PQ'}) \) and \( \measuredangle(\vect{QP}, \vect{QR}) = \measuredangle(\vect{QP}, \vect{P'Q}) = \pi - \measuredangle(\vect{PQ}, \vect{PQ'}) \), and thus \( \measuredangle(\vect{RP}, \vect{RQ}) = 0 \).

    \item Otherwise, we instead have \( \measuredangle(\vect{PQ}, \vect{PR}) = \measuredangle(\vect{PQ}, \vect{Q'P}) \) and \( \measuredangle(\vect{QP}, \vect{QR}) = \measuredangle(\vect{QP}, \vect{QP'}) = \pi - \measuredangle(\vect{PQ}, \vect{Q'P}) \) and thus \( \measuredangle(\vect{RP}, \vect{RQ}) = 0 \).
  \end{itemize}

  In both cases, we obtain that \( \angle(\vect{RP}, \vect{RQ}) \) is a zero angle, and thus the lines \( g \) and \( h \) coincide. But this is not possible since we have assumed that they are distinct.

  The obtained contradiction shows that \( g \) and \( h \) do not intersect.
\end{proof}
