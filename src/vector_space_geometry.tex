\subsection{Vector space geometry}\label{subsec:vector_space_geometry}

We will denote by \( \BbbK \) either the field of \hyperref[def:real_numbers]{real numbers} or the \hyperref[def:real_numbers]{complex numbers}. We will mostly work over the real numbers, but some important definitions and theorems hold more generally.

\begin{remark}\label{rem:real_field_extensions}
  When speaking about vector spaces, we usually restrict ourselves to vector spaces over \( \BbbR \) or, at most, \( \BbbC \). This restriction may seem arbitrary, however important concepts like \hyperref[def:geometric_ray]{rays} or \hyperref[def:convex_set]{convexity} requires the field to be an extension of \( \BbbR \), and it just so happens that, by \fullref{thm:fundamental_theorem_of_algebra} and \fullref{thm:no_finite_extensions_of_closed_fields}, the only nontrivial finite \hyperref[def:field/submodel]{field extension} of \( \BbbR \) is \( \BbbC \). It is technically possible to work with infinite field extensions, however in practice vector spaces over \( \BbbC \) are esoteric enough.

  Considering only \( \BbbR \) and \( \BbbC \) leads to certain concepts being defined for complex vector spaces and then real vector spaces become a special case. This is formalized via \hyperref[def:complexification]{complexification}. For example, inner products are defined in \fullref{def:inner_product_space} differently for real and complex vector spaces, however we can transition between them due to \fullref{thm:complexification_universal_property} and \fullref{thm:complexification_of_symmetric_bilinear_form}.
\end{remark}

\begin{definition}\label{def:geometric_shape}
  A \term{geometric shape} is an informal notion that refers to certain special subsets of a vector space, usually defined in a coordinate-independent manner. Shapes in two-dimensional spaces are called \term{figures} and shapes in three dimensions are called \term{surfaces}.

  When two geometric shapes intersect, we say that they are \term{incident}. This relates to \hyperref[def:hypergraph/incidence]{(hyper)graph incidence} via \hyperref[def:quiver_geometric_realization]{geometric realizations}.
\end{definition}

\begin{definition}\label{def:point}
  A \term{point} is a simple \hyperref[def:geometric_shape]{geometric shape} comprising a singleton subset of a topological space. We use the convention \fullref{rem:singleton_sets} and, unless the distinction is important, we do not distinguish between singleton sets and their only element --- see \fullref{def:simplex/point} for an example.

  Within vector spaces points are also called vectors, which is justified by \fullref{def:euclidean_plane_coordinate_system}.
\end{definition}

\begin{definition}\label{def:affine_hull}\mimprovised
  Let \( X \) be a vector space over \( \BbbK \). We say that the \hyperref[rem:linear_combinations]{linear combination}
  \begin{equation*}
    t_1 x_1 + \ldots + t_n x_n
  \end{equation*}
  with real coefficients is an \term{affine combination} if
  \begin{equation*}
    t_1 + \cdots + t_n = 1.
  \end{equation*}

  This can be expressed more succinctly by saying that for any real number \( \lambda \) and any vectors \( x \) and \( y \), we have
  \begin{equation}\label{eq:def:affine_hull/combination}
    \lambda x + (1 - \lambda) y.
  \end{equation}

  The \term{affine hull} of the set \( S \) is the set of all affine combinations of members of \( S \). This is a \hyperref[def:closure_operator]{closure operator}.

  \begin{figure}[!ht]
    \centering
    \includegraphics[page=1]{output/def__convex_hull.pdf}
    \caption{The \hyperref[def:affine_hull]{affine}, \hyperref[def:conic_hull]{conic} and \hyperref[def:convex_hull]{convex} hulls of \( \set{ A, B, C } \).}\label{fig:def:convex_hull}
  \end{figure}

  Geometrically, the affine hull of \( S \) is the smallest translated vector subspace of \( X \). Unlike the linear span, the affine hull does not necessarily contain the zero vector because it is not itself a vector subspace, but a translation of one.
\end{definition}
\begin{defproof}
  We will show that the affine hull operator \( A: \pow(X) \to \pow(X) \) is a closure operator.

  \SubProofOf[def:inflationary_function]{inflation} Obviously \( S \subseteq A(S) \).

  \SubProofOf[def:magma/idempotent]{idempotence} Consider the affine combination \( \lambda x + (1 - \lambda) y \) of vectors from \( A(S) \). Suppose that \( x = t_x u_x + (1 - t_x) v_x \) and \( y = t_y u_y + (1 - t_y) v_y \), where \( u_x \), \( u_y \), \( v_x \) and \( v_y \) are vectors from \( S \).

  Then
  \begin{equation*}
    \lambda x + (1 - \lambda) y
    =
    \lambda t_x u_x + \lambda (1 - t_x) v_x + (1 - \lambda) t_y u_y + (1 - \lambda) (1 - t_y) v_y.
  \end{equation*}

  This is an affine combination of members of \( S \). Therefore, \( A(A(S)) = A(S) \).

  \SubProofOf[eq:def:partially_ordered_set/homomorphism/nonstrict]{monotonicity} If \( S_1 \subseteq S_2 \), then \( A(S_2) \) contains the affine combinations of the members of \( S_1 \) in addition to others. Hence, \( A(S_1) \subseteq A(S_2) \).
\end{defproof}

\begin{definition}\label{def:affine_operator}
  We say that the function \( f: X \to Y \) between vector spaces over \( \BbbK \) is an \term{affine operator} if any of the following equivalent conditions hold:
  \begin{thmenum}
    \thmitem{def:affine_operator/translation} The map \( T(x) \coloneqq f(x) - f(0) \) is a linear operator.
    \thmitem{def:affine_operator/combination} \( f \) preserves \hyperref[def:affine_hull]{affine combinations}. That is, for any real number \( \lambda \),
    \begin{equation}\label{eq:def:affine_operator/combination}
      f\parens[\Big]{ \lambda x + (1 - \lambda) y } = \lambda f(x) + (1 - \lambda) f(y).
    \end{equation}
  \end{thmenum}
\end{definition}
\begin{defproof}
  \ImplicationSubProof{def:affine_operator/translation}{def:affine_operator/combination} Suppose that \( T \) is linear. Then for an arbitrary real number \( \lambda \),
  \begin{balign*}
    f(\lambda x + (1 - \lambda) y)
    &=
    T(\lambda x + (1 - \lambda) y) + f(0)
    = \\ &=
    \lambda T(x) + (1 - \lambda) T(y) + f(0)
    = \\ &=
    \lambda \parens[\Big]{ f(x) - f(0) } + (1 - \lambda) \parens[\Big]{ f(y) - f(0) } + f(0)
    = \\ &=
    \lambda f(x) + (1 - \lambda) f(y).
  \end{balign*}

  We can cancel \( f(0) \) to obtain \eqref{eq:def:affine_operator/combination}.

  \ImplicationSubProof{def:affine_operator/combination}{def:affine_operator/translation} Suppose that \eqref{eq:def:affine_operator/combination} holds. Then
  \begin{balign*}
    T(x + y)
    &=
    f(x + y) - f(0)
    = \\ &=
    f(1 \cdot x - 1 \cdot 0 + 1 \cdot y - 1 \cdot 0 + 1 \cdot 0) - f(0)
    = \\ &=
    \parens[\Big]{ f(x) - f(0) } + \parens[\Big]{ f(y) - f(0) } + f(0) - f(0)
    = \\ &=
    T(x) + T(y).
  \end{balign*}

  Also,
  \begin{equation*}
    T(\lambda x)
    =
    f(\lambda x + (1 - \lambda) 0) - f(0)
    =
    \lambda f(x) - \lambda f(0)
    =
    \lambda T(x).
  \end{equation*}

  This shows that \( T \) is a linear operator.
\end{defproof}

\begin{proposition}\label{thm:isometry_iff_affine_orthogonal_operator}\mcite[thm. 7.1]{Treil2017}
  The endofunction \( f: X \to X \) over the real inner product space \( X \) is an \hyperref[def:isometry]{isometry} if and only if it is an \hyperref[def:affine_operator]{affine operator} whose linear part \( T(x) \coloneqq f(x) - f(0) \) is \hyperref[def:unitary_operator]{orthogonal}.
\end{proposition}
\begin{proof}
  \SufficiencySubProof Suppose that \( f \) is an isometry.

  First note that
  \begin{equation*}
    \inprod { f(x) } { f(y) } = \inprod x y.
  \end{equation*}

  Indeed, we have
  \begin{equation*}
    \norm{ f(x) - f(y) } = \norm{ f(x) } + \norm{ f(y) } - 2 \inprod { f(x) } { f(y) }
  \end{equation*}
  and
  \begin{equation*}
    \norm{ x - y } = \norm x + \norm y - 2 \inprod x y.
  \end{equation*}

  Therefore,
  \begin{equation*}
    \inprod { f(x) } { f(y) }
    =
    \frac{ \norm{ f(x) - f(y) } - \norm{ f(x) } - \norm{ f(y) } } 2
    =
    \frac{ \norm{ x - y } - \norm{ x } - \norm{ y } } 2
    =
    \inprod x y.
  \end{equation*}

  Now we can show additivity of \( T \):
  \begin{balign*}
    &\phantom{{}={}}
    \norm{ T(x + y) - T(x) - T(y) }^2
    = \\ &=
    \norm{ f(x + y) - f(0) - f(x) + f(0) - f(y) + f(0) }^2
    = \\ &=
    \norm{ \parens{ f(x + y) - f(x) } - \parens{ f(y) - f(0) } }^2
    = \\ &=
    \norm{ f(x + y) - f(x) }^2 + \norm{ f(y) - f(0) }^2 - 2 \inprod{ f(x + y) - f(x) } { f(y) - f(0) }
    = \\ &=
    \norm{ x + y - x }^2 + \norm{y}^2 - 2 \inprod{x + y} y + 2 \inprod x y - 2 \inprod {x + y} 0 + 2 \inprod x 0
    = \\ &=
    2 \norm{y}^2 - 2 \inprod x y - 2 \norm{y}^2 + 2 \inprod x y.
  \end{balign*}

  The norm is zero, hence \( T(x + y) = T(x) + T(y) \).

  Similarly,
  \begin{balign*}
    &\phantom{{}={}}
    \norm{ T(\lambda x) - \lambda T(x) }^2
    = \\ &=
    \norm{ f(\lambda x) - f(0) - \lambda f(x) + \lambda f(0) }^2
    = \\ &=
    \norm{ f(\lambda x) - f(0) }^2 + \norm{ \lambda f(x) - \lambda f(0) }^2 - 2 \inprod{ f(\lambda x) - f(0) } { \lambda f(x) - \lambda f(0) }
    = \\ &=
    \norm{\lambda x}^2 + \lambda^2 \norm{x}^2 - 2 \lambda \inprod{ f(\lambda x) - f(0) } { f(x) - f(0) }
    = \\ &=
    2 \lambda^2 \norm{x}^2 - 2 \lambda^2 \inprod x x.
  \end{balign*}

  This norm is also zero, hence \( T(\lambda x) = \lambda T(x) \).

  Finally, we must show that \( T \) is a unitary operator:
  \begin{balign*}
    \inprod{ T(x) }{ T(y) }
    &=
    \inprod{ f(x) - f(0) }{ f(y) - f(0) }
    = \\ &=
    \inprod{ f(x) }{ f(y) } - \inprod{ f(x) }{ f(0) } - \inprod{ f(0) }{ f(y) } + \inprod{ f(0) }{ f(0) }
    = \\ &=
    \inprod x y.
  \end{balign*}

  \NecessitySubProof Suppose that \( f(x) = Tx + f_0 \) for some unitary operator \( T \) and some vector \( f_0 \). Then
  \begin{balign*}
    \norm{ f(x) - f(y) }^2
    &=
    \norm{ Tx - f_0 - Ty + f_0 }^2
    = \\ &=
    \norm{ T(x - y) }^2
    = \\ &=
    \inprod{ T(x - y) }{ T(x - y) }
    = \\ &=
    \inprod{ x - y }{ T^{-1} T(x - y) }
    = \\ &=
    \norm{ x - y }^2.
  \end{balign*}
\end{proof}

\begin{definition}\label{def:euclidean_space}\mimprovised
  An \term{Euclidean space} is a finite-dimensional real \hyperref[def:inner_product_space]{inner product space}, most commonly the \hyperref[def:sequence_space]{tuple space} \( \BbbR^n \) with the dot product \( (x, y) \mapsto x^T y \).
\end{definition}

\begin{remark}\label{rem:euclidean_space_etymology}
  The term \enquote{Euclidean space} may have different meanings depending on the context. For example, \cite[sec. 24.1]{Тыртышников2004Лекции} defines Euclidean spaces as possibly infinite-dimensional real inner product spaces, while \cite[2.19]{Rudin1987RealAndComplex} restricts them to tuple spaces with the dot product. \enquote{The} Euclidean space may refer to the three-dimensional generalization of the Euclidean plane discussed in \fullref{def:euclidean_plane}.
\end{remark}

\begin{lemma}\label{thm:dot_product_and_outer_product}
  For vectors \( x \), \( y \) and \( z \) in \( \BbbK^n \), we have
  \begin{equation*}
    x^T y z = y z^T x.
  \end{equation*}
\end{lemma}
\begin{proof}
  The \( k \)-th coordinate of \( x^T y z \) is \( (x^T y) z_k \).

  The \( k \)-th coordinate of \( y z^T x \) is
  \begin{equation*}
    \sum_{i=1}^n (y_i z_k) x_i
    =
    z_k \sum_{i=1}^n y_i x_i
    =
    (x^T y) z_k.
  \end{equation*}
\end{proof}

\begin{definition}\label{def:rigid_motion}\mimprovised
  A \term{rigid motion} is an \hyperref[def:isometry]{isometry} in an \hyperref[def:euclidean_space]{Euclidean space}. \Fullref{thm:isometry_iff_affine_orthogonal_operator} provides an equivalent characterization: a rigid motion is an affine operator whose linear part is \hyperref[def:unitary_operator]{orthogonal}. Thus, given a rigid motion \( f: X \to X \), there exists an orthogonal operator \( T: X \to X \) and a vector \( d \) such that
  \begin{equation*}
    f(x) = Tx + d.
  \end{equation*}

  The following are common rigid motions:
  \begin{thmenum}
    \thmitem{def:rigid_motion/translation} The \term{translation} along the \term{direction} \( d \) is
    \begin{equation*}
      f(x) = x + d.
    \end{equation*}

    \begin{figure}[!ht]
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__translation__2d.pdf}
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__translation__3d.pdf}
      \hfill
      \hfill
      \caption{Translation of the unit square in \( \BbbR^2 \) and unit cube in \( \BbbR^3 \).}\label{fig:def/rigid_motion/translation}
    \end{figure}

    The term \enquote{translation} generalizes to an arbitrary \hyperref[def:magma]{magma} via
    \begin{equation*}
      f(x) \coloneqq v \cdot x.
    \end{equation*}

    \thmitem{def:rigid_motion/rotation} A \term{rotation} is an \hyperref[def:orthogonal_operator]{orthogonal} operator with \hyperref[def:matrix_determinant]{determinant} \( 1 \).

    \begin{figure}[!ht]
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__rotation__2d.pdf}
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__rotation__3d.pdf}
      \hfill
      \hfill
      \caption{Rotation of the unit square in \( \BbbR^2 \) and unit cube in \( \BbbR^3 \).}\label{fig:def/rigid_motion/rotation}
    \end{figure}

    \thmitem{def:rigid_motion/reflection} The \term{Householder reflection} with \term{normal vector} \( v \) is, assuming \( \norm v = 1 \),
    \begin{equation*}
      f(x) \coloneqq x - (2 \inprod x v) v.
    \end{equation*}

    In \( \BbbR^n \) this can be expressed in matrix form as
    \begin{equation*}
      f(x)
      =
      x - (2 x^T v) v
      \reloset {\ref{thm:dot_product_and_outer_product}} =
      x - 2 v v^T x
      =
      (I_n - 2 v v^T) x.
    \end{equation*}

    \begin{figure}[!ht]
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__reflection__2d.pdf}
      \hfill
      \includegraphics[align=c]{output/def__rigid_motion__reflection__3d.pdf}
      \hfill
      \hfill
      \caption{Reflection of the unit square in \( \BbbR^2 \) and unit cube in \( \BbbR^3 \).}\label{fig:def/rigid_motion/reflection}
    \end{figure}
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:zero_locus}
  Let \( S \) be an arbitrary set and let \( M \) be a \hyperref[def:monoid]{monoid} with identity \( e \).

  The \term{zero locus} or \term{set of zeros} of a function \( f: S \to M \) is the preimage
  \begin{equation*}
    f^{-1}(e) = \{ x \in X \colon f(x) = e \}.
  \end{equation*}

  In practice, \( M \) is usually a \hyperref[def:ring]{ring} or a \hyperref[def:module]{module}, in which case the zero locus is defined for the additive group, i.e.
  \begin{equation*}
    f^{-1}(0_M) = \{ x \in X \colon f(x) = 0_M \}.
  \end{equation*}

  See also \fullref{def:group/kernel}, \fullref{def:ring/kernel} and \fullref{def:module/kernel}.
\end{definition}

\begin{definition}\label{def:hypersurface}
  A \term{hypersurfaces} can have different meanings depending on the context. We are interested in

  \begin{thmenum}
    \thmitem{def:hypersurface/parametric} A parametric hypersurface (\fullref{def:parametric_hypersurface}) is a purely topological definition.
    \thmitem{def:hypersurface/algebraic} An affine variety (\fullref{def:affine_algebraic_set}) is a purely algebraic definition.
    \thmitem{def:hypersurface/geometric} A manifold (\fullref{def:topological_manifold}) can be regarded as a geometric definition.
  \end{thmenum}

  Note that all of the enumerated hypersurfaces have a concept of dimension. Hypersurfaces of dimension \( 2 \) are simply called \term{surfaces} (see \fullref{def:affine_algebraic_set/surface}) and hypersurfaces of dimension \( 1 \) are called \term{curves} (see also \fullref{def:affine_algebraic_set/curve} and \fullref{def:affine_algebraic_set/curve}).
\end{definition}

\begin{definition}\label{def:geometric_line}
  A particularly important \hyperref[def:hypersurface]{curve} is a \term{line} in a vector space \( X \) over any field \( \BbbK \), which can be defined equivalently as

  \begin{thmenum}
    \thmitem{def:geometric_line/subspace} A subspace of \( X \) of \hyperref[thm:vector_space_dimension]{dimension} one. Note that this is not consistent with the other definitions because this defines only lines through the origin \( 0_X \). Hence, if \( L \subseteq X \) is a line (a subspace of dimension one) and if \( a \in X \) is any point, we define a line with origin \( a \) to be the translation \( a + L \).

    \thmitem{def:geometric_line/algebraic} An \hyperref[def:affine_algebraic_set/curve]{algebraic curve} in \( X \) given by a polynomial of degree one.

    \thmitem{def:geometric_line/parametric} If the field \( \BbbK \) is ordered (usually when \( \BbbK = \BbbR \)), we can define a line with \term{directional vector} \( x \) and \term{origin} \( a \) as the parametric curve
    \begin{balign*}
       & l: \BbbK \to X   \\
       & l(t) = tx + a.
    \end{balign*}
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:geometric_ray}
  If \( X \) is a vector space over \( \BbbK \in \{ \BbbR, \BbbC \} \), we define \term{closed rays} with a vertex \( a \) as the parametric curves
  \begin{balign*}
     & l^+: [0, \infty) \to X \\
     & l^+(t) = tx + a
  \end{balign*}
  and
  \begin{balign*}
     & l^-: (-\infty, 0] \to X \\
     & l^-(t) = tx + a
  \end{balign*}

  If the inequalities are strict, we instead obtain \term{open rays}.

  Unless explicitly noted otherwise, we assume that the vertex of the ray is \( 0 \) because every ray is a translation of a ray centered at \( 0 \).
\end{definition}

\begin{definition}\label{def:geometric_cone}
  An open (resp. closed) \term{cone} in a vector space over \( \BbbK \in \{ \BbbR, \BbbC \} \) is a union of open (resp. closed) \hyperref[def:geometric_ray]{rays} with a common vertex, called the \term{vertex} of the cone.
\end{definition}

\begin{definition}\label{def:hyperplane}
  Dually to \hyperref[def:geometric_line]{lines}, another particularly important \hyperref[def:hypersurface]{hypersurface} is a \term{hyperplane} in a vector space \( X \) over any field.

  \begin{thmenum}
    \thmitem{def:hyperplane/subspace} A \term{linear hyperplane} is simply a subspace of \( X \) of \hyperref[thm:vector_space_dimension]{codimension} one. As in \fullref{def:geometric_line/subspace}, we define a \term{affine hyperplane} to be a \hyperref[def:rigid_motion/translation]{translation} of a linear hyperplane.

    \thmitem{def:hyperplane/kernel} Linear hyperplanes (as defined in \fullref{def:hyperplane/subspace}) are simply zero \hyperref[def:zero_locus]{loci} (\hyperref[def:ring/kernel]{kernels}) of linear \hyperref[def:semimodule/homomorphism]{functionals}. and affine hyperplanes are zero loci of \hyperref[def:affine_operator]{affine functionals}.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:hyperplanes}
  Affine \hyperref[def:hyperplane]{hyperplanes} in \( \BbbR^2 \) are \hyperref[def:geometric_line]{lines} and affine hyperplanes in \( \BbbR^3 \) are planes.

  Linear \hyperref[def:hyperplane]{hyperplanes} in \( \BbbR^2 \) are the lines passing through the origin \( (0, 0) \) and linear hyperplanes in \( \BbbR^3 \) are the planes incident to \( (0, 0, 0) \).
\end{example}

\begin{definition}\label{def:half_space}
  Vector spaces over \( \BbbR \) have the concept of \term{half-spaces}. Given a \hyperref[def:hyperplane]{hyperplane} \( H \) of the real vector space \( X \), defined by the affine functional \( l(x) = \inprod {x^*} x + a \), its closed half-spaces are defined as
  \begin{equation*}
    H^+ \coloneqq \{ l(x) \geq 0 \} = \{ \inprod {x^*} x \geq -a \}
  \end{equation*}
  and
  \begin{equation*}
    H^- \coloneqq \{ l(x) \leq 0 \} = \{ \inprod {x^*} x \leq -a \}.
  \end{equation*}

  If the inequalities are strict, we instead obtain \term{open half-spaces}.
\end{definition}

\begin{definition}\label{def:polyhedron}
  A \term{polyhedron} in a real vector space is an intersection of \hyperref[def:half_space]{half-spaces}.
\end{definition}

\begin{definition}\label{def:hyperplane_separation}
  Although \hyperref[def:hyperplane]{hyperplanes} are defined for vector spaces over an arbitrary field \( \BbbK \), we define \term{hyperplane separation} only for \( \BbbK \in \{ \BbbR, \BbbC \} \) (see \fullref{rem:real_field_extensions}).

  We say that the sets \( A, B \subseteq X \) are \term{separated} by the linear functional \( l \in X^* \) if there exists a real number \( c \in \BbbR \) such that
  \begin{equation}\label{def:hyperplane_separation/normal}
    \real l(x) < c \leq \real l(y) \quad\forall x \in A, y \in B.
  \end{equation}

  See \fullref{rem:linear_functionals_over_c} for a justification of only considering the real part of \( l \).

  The asymmetry in the inequalities \fullref{def:hyperplane_separation/normal} can be inverted by considering \( -l(x) \) and \( -c \).

  We say that \( A \) and \( B \) are \term{strongly separated} by \( l \) if both inequalities in \fullref{def:hyperplane_separation/normal} are strict:
  \begin{equation}\label{def:hyperplane_separation/strong}
    \real l(x) < c < \real l(y) \quad\forall x \in A, y \in B.
  \end{equation}

  We can regard \( l \) as a hyperplane as in \fullref{def:hyperplane/kernel}, which justifies the terminology \enquote{hyperplane separation}. It is more correct, however, especially if \( \BbbK = \BbbR \), to say that they are separated by the affine hyperplane \( l(x) + c \).

  If \( \BbbK = \BbbR \) \fullref{def:hyperplane_separation/normal} is equivalent to requiring that \( A \) is contained in an open \hyperref[def:half_space]{half-space} relative to \( l(x) + c \) and that \( B \) is contained in the complementing closed half-space (or vice-versa). \Fullref{def:hyperplane_separation/strong} then states that both \( A \) and \( B \) are contained in opposite open half-spaces.
\end{definition}

\begin{definition}\label{def:convex_set}
  \hfill
  \begin{thmenum}
    \thmitem{def:convex_set/line_segment} Given two points \( x, y \in X \) in a Banach space \( X \), we define the \term{line segment} between \( x \) and \( y \) as the parametric curve \( t \mapsto tx + (1-t)y, t \in [0, 1] \). The image
    \begin{equation*}
      [x, y] \coloneqq \{ tx + (1-t)y \colon t \in [0, 1] \}
    \end{equation*}
    of this parametric curve is called the \term{convex hull} of \( x \) and \( y \). We usually use the term \enquote{line segment} to refer to the convex hull itself.

    The length \( \len([x, y]) \) of a line segment is defined as \( \norm{x - y} \).

    \thmitem{def:convex_set/hull} We define the convex hull \( \conv A \) of a set \( A \subseteq X \) as the union of all line segments with endpoints in \( A \).

    \thmitem{def:convex_set/set} We call a set \term{convex} if it coincides with its convex hull, that is, if it contains the line segment between any two of its points.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:convex_combination}\mimprovised
  Consider the \hyperref[rem:linear_combinations]{linear combination} \( t_1 x_1 + \ldots + t_n x_n \) over \( \BbbK \) with real coefficients.

  \begin{thmenum}
    \thmitem{def:convex_combination/affine} If all coefficients satisfy \( t_k \leq 1 \), we say that the combination is \term{affine}.
    \thmitem{def:convex_combination/conic} If all coefficients are nonnegative, we say that the combination is \term{conic}.
    \thmitem{def:convex_combination/convex} If the combination is both affine and conic, we say that it is \term{convex}.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:def:convex_set}
  \hyperref[def:convex_set]{Convex sets} have the following basic properties:

  \begin{thmenum}
    \thmitem{thm:def:convex_set/closed_under_combinations} A convex set is closed under convex \hyperref[def:convex_combination]{combinations}.
    \thmitem{thm:def:convex_set/cone_closed_under_combinations} A closed \hyperref[def:convex_set]{convex} \hyperref[def:geometric_cone]{cone} is closed under conic \hyperref[def:convex_combination/conic]{combinations}.
    \thmitem{thm:def:convex_set/closed_under_intersections} Any intersection of convex sets is convex.
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:convex_set/closed_under_combinations} Fix a convex set \( C \). Let \( \sum_{k=1}^n t_k x_k \) be a convex combination of elements of \( C \).

  We will use induction on \( n \). If \( n = 1 \), this is obvious. If \( n = 2 \), this is given by definition. Assume that it is true for \( n - 1 \). Denote \( s \coloneqq \sum_{k=1}^{n-1} t_k \). If \( s = 0 \), take another convex combination in order to handle all the possible cases of the induction. Suppose \( s \neq 0 \). Then
  \begin{equation*}
    \sum_{k=1}^n t_k x_k
    =
    s \sum_{k=1}^n \frac{t_k} s x_k
    =
    s \underbrace{\sum_{k=1}^{n-1} \frac{t_k} s x_k}_{\eqqcolon y} + t_n x_n.
  \end{equation*}

  By the inductive hypothesis, \( y \in C \). Note that \( s \in [0, 1] \) and that \( s + t_n = 1 \) by definitions of \( s \). Then \( s y + t_n x_n \) is a binary convex combination that we know is contained in \( C \) by definition.

  \SubProofOf{thm:def:convex_set/cone_closed_under_combinations} Fix a cone \( C \). Let \( \sum_{k=1}^n t_k x_k \) be a conic combination of elements of \( C \). Each vector \( x_k \) lies on a closed ray, say \( r_k \), thus \( t_k x_k \) also lies on \( r_k \).

  Therefore, we only need to show that the sum of two elements \( x_1, x_2 \in C \) is again in \( C \). This is true because \( x_1 + x_2 \) is a convex combination of \( 2x_1 \in r_1 \) and \( 2x_2 \in r_2 \).

  \SubProofOf{thm:def:convex_set/closed_under_intersections} Let \( X = \cap_{\alpha \in \mscrK} X_\alpha \) be an intersection of convex sets. Take \( x, y \in X \) and \( t \in [0, 1] \). Then \( tx + (1-t)y \in X_\alpha \) for all \( \alpha \in \mscrK \), hence \( tx + (1-t)y \in X \). Therefore, \( X \) is convex.
\end{proof}

\begin{definition}\label{def:affine_dependence}\mimprovised
  Let \( X \) be a vector space over \( \BbbR \) and let \( B \) be a subset of \( X \). We say that the elements of \( B \) are \term{affinely independent} if there exists a nontrivial linear combination
  \begin{equation*}
    t_1 b_1 + \cdots + t_n b_n
  \end{equation*}
  that sums to zero and where
  \begin{equation*}
    t_1 + \cdots + t_n = 0.
  \end{equation*}

  Relaxing the last condition, we obtain the definition of linear dependence.
\end{definition}

\begin{definition}\label{def:simplex}
  A \( k \)-\term{simplex} is the convex \hyperref[def:convex_set/hull]{hull} of \( k + 1 \) \hyperref[def:affine_dependence]{affinely independent} vectors called the \term{vertices} of the simplex. The convex hull of any subset of the vertices is called a \term{face} of the simplex.

  \begin{thmenum}
    \thmitem{def:simplex/point} A \( 0 \)-simplex is a \hyperref[def:point]{point}.
    \thmitem{def:simplex/line_segment} A \( 1 \)-simplex is a line segment as defined in \fullref{def:convex_set/line_segment}.
    \thmitem{def:simplex/triangle} A \( 2 \)-simplex is a triangle as defined in \fullref{def:triangle}.
    \thmitem{def:simplex/tetrahedron} A \( 3 \)-simplex is called a \term{tetrahedron}.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:k_cell}
  A \( k \)-cell is a \hyperref[def:cartesian_product]{Cartesian product} of \( k \) nonempty \hyperref[def:partially_ordered_set_interval/closed]{closed intervals} of real numbers.

  \begin{thmenum}
    \thmitem{def:k_cell/point} A \( 0 \)-cell is a \hyperref[def:point]{point}.
    \thmitem{def:k_cell/interval} A \( 1 \)-cell is a closed interval.
    \thmitem{def:k_cell/rectangle} A \( 2 \)-cell is called a \term{rectangle}. If a rectangle \( R \) is a product of two copies of the same interval, i.e. if \( R = [a, b]^2 \), we say that \( R \) is a \term{square} with side \( b - a \).
    \thmitem{def:k_cell/parallelepiped} A \( 3 \)-cell is called a \term{parallelepiped}. If \( R = [a, b]^3 \), we say that \( R \) is a \term{cube} with side \( b - a \).
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:neighborhood_set_types}
  The following topology-independent definitions are often used for neighborhoods in a topological vector space \( X \):

  \begin{thmenum}
    \thmitem{def:neighborhood_set_types/absorbing} \( A \) is \term{absorbing} if \( \bigcup_{k=0}^\infty kA = X \).
    \thmitem{def:neighborhood_set_types/symmetric} \( A \) is \term{symmetric} if \( -A = A \).
    \thmitem{def:neighborhood_set_types/balanced} \( A \) is \term{balanced} if \( tA \subseteq A \) for any \( t \in [0, 1] \).
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:collinear_complanar}
  The geometric version of \hyperref[def:linear_dependence]{linear independence} has two special names: we say that the set \( A \subseteq X \) of any vector space \( X \) is \term{collinear} (on the same line) if \( \dim(\linspan(A)) \leq 1 \) and \term{complanar} (on the same plane) if \( \dim(\linspan(A)) \leq 2 \).
\end{definition}
