\subsection{Formal languages}\label{subsec:formal_languages}

Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:set_definition_recursion}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.

\begin{definition}\label{def:formal_language}
  Fix a nonempty set \( \mscrA \).

  \begin{thmenum}
    \thmitem{def:formal_language/alphabet} We call \( \mscrA \) an \term{alphabet}.

    \thmitem{def:formal_language/symbol} We call each element of \( \mscrA \) a \term{symbol}.

    \thmitem{def:formal_language/word} A \term{string} over \( \mscrA \) is a \hyperref[def:sequence]{finite sequence} of symbols. If \( (a, b, c) \) is a word, for convenience we write it as the string \( abc \). This is the reason words are also referred to as \term{strings}. This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    The term \enquote{string} is common in programming practice. In the context of formal languages, strings are often called \term{words}. We will avoid the later term since it does not correspond to the everyday use of the term \enquote{word}.

    \thmitem{def:formal_language/empty_word} We denote the empty string by \( \varepsilon \).

    \thmitem{def:formal_language/word_length} The \term{length} \( \len(w) \) of a word \( w \) is the number of elements of the tuple \( w \).

    \thmitem{def:formal_language/concatenation} The \term{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) is the word
    \begin{equation*}
      vw \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \overbrace{w w \ldots w}^{k \T{times}} \) as \( w^k \). This is only a notation. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).

    \thmitem{def:formal_language/reverse} The \term{reverse word} of \( w = (w_1, \ldots, w_n) \) is
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:formal_language/prefix} The word \( p = (p_1, \ldots, p_m) \) is a \term{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:formal_language/suffix} The word \( s \) is a \term{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:formal_language/subword} The word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = pvs.
    \end{equation*}

    \thmitem{def:formal_language/kleene_star} The \term{Kleene star} \( \mscrA^* \) of \( \mscrA \) is the set of all words over \( \mscrA \). If we wish to exclude the empty word, like we often do, we instead write \( \mscrA^+ \) for the set of all non-empty words over \( \mscrA \).

    \thmitem{def:formal_language/language} A \term{language} over \( \mscrA \) is any subset of \( \mscrA^* \). Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic} the term \enquote{language} may refer to the alphabet itself (see \fullref{rem:propositional_language_is_alphabet}).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:kleene_star_is_monoid}
  For any alphabet \( \mscrA \), the Kleene star \( \mscrA^* \) is a \hyperref[def:unital_magma/monoid]{monoid} under concatenation.
\end{proposition}
\begin{proof}
  Concatenation is clearly associative and the empty word \( \varepsilon \) is a \hyperref[def:magma_identity]{two-sided identity} under concatenation.
\end{proof}

\begin{definition}\label{def:formal_grammar}\mcite[def. 2.2]{Sipser2013}
  Let \( V \) and \( \Sigma \) be disjoint nonempty subsets of some \hyperref[def:formal_language/alphabet]{alphabet}.

  \begin{thmenum}
    \thmitem{def:formal_grammar/terminals} We call elements of \( \Sigma \) \term{terminals}. We denote terminals in abstract grammars using lowercase Greek letters, and we denote words using lowercase Latin letters.

    \thmitem{def:formal_grammar/non_terminals} We call elements of \( V \) \term{non-terminals}. By convention, variables are denoted using capital letters.

    \thmitem{def:formal_grammar/start} We assume that a special \term{start symbol} \( S \in V \) is fixed.

    \thmitem{def:formal_grammar/production_rules} We define a binary \hyperref[def:relation]{relation} \( \to \) of \term{production rules} over \( (V \cup \Sigma)^* \).

    We impose the restriction that no rules of the form \( \varepsilon \to v \) exist for any word \( v \). We do allow, however, production rules of the form \( v \to \varepsilon \). Such rules are called \term{\( \varepsilon \)-rules}.

    Rules describe transformations that define how a language is \enquote{generated} starting from \( S \). See \fullref{def:grammar_derivation} and \fullref{ex:natural_number_arithmetic_grammar/derivation}.

    \thmitem{def:formal_grammar/grammar} The quadruple \( G \coloneqq (V, S, \Sigma, \to) \) is called a \term{formal grammar} or simply a \term{grammar}.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:chomsky_hierarchy}
  We will define the \term{Chomsky hierarchy} of \hyperref[def:formal_grammar]{formal grammars}. We can classify a grammar \( G = (V, S, \Sigma, \to) \) as follows, based on their rules:
  \begin{thmenum}
    \thmitem{def:chomsky_hierarchy/unrestricted} In general, every production rule has the form \( v \to w \), where both \( v \) and \( w \) are words consisting of terminal and non-terminals, and \( v \) is nonempty.

    When no additional restrictions are imposed on the rules of the grammar, we call it \term{unrestricted grammar}. The other levels of the hierarchy are subsets of the unrestricted grammars.

    \thmitem{def:chomsky_hierarchy/non_contracting} The grammar is \term{non-contracting} if \( \len(v) \leq \len(w) \) for every production rule \( v \to w \).

    \thmitem{def:chomsky_hierarchy/context_sensitive} The grammar is \term{context-sensitive} if every rule has the form \( aAb \to w \) for some non-terminal \( A \), arbitrary words \( a \) and \( b \), and a nonempty word \( w \).

    The requirement for \( w \) to be nonempty is set up so that context-sensitive grammars are non-contracting.

    \thmitem{def:chomsky_hierarchy/context_free} The grammar is \term{context-free} every rule has the form \( A \to w \) for some non-terminal \( A \) and a nonempty word \( w \).

    Unlike for context-sensitive languages, \( w \) is allowed to be empty. Thus, a context-free grammar is non-contracting, however it may not be context-sensitive if it has \( \varepsilon \)-rules.

    \thmitem{def:chomsky_hierarchy/regular} Finally, the grammar is \term{regular} if every rule has one of the forms
    \begin{align*}
      &A \to \varepsilon, \\
      &A \to B \tau, \\
      &A \to \tau B, \\
      &A \to \tau,
    \end{align*}
    where \( A \) and \( B \) are non-terminals and \( \tau \) is a terminal.

    Regular grammars are obviously context-free.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/backus_naur_form}
  We define a grammar for primary school notation of multiplication and division of \hyperref[def:set_of_natural_numbers]{natural numbers}. Note that we consider the numbers in \( \BbbN \) only as symbols, without any regard to semantics.

  Let \( V \coloneqq \set{ N, O, M, E } \) and \( \Sigma \coloneqq \BbbN \cup \set{ \times, \div, (, ) } \). Define the grammar
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}
    \begin{aligned}
      N &\to 0 \\
      N &\to 1 \\
      \phantom{N} &\vdots \\
      N &\to n \\
      \phantom{N} &\vdots \\
      O &\to \times \\
      O &\to \div \\
      E &\to N \\
      E &\to (E O E)
    \end{aligned}
  \end{equation}

  It is convenient to use the following shorthands:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}
    \begin{aligned}
      N &\to 0 \mid 1 \mid 2 \mid \ldots \\
      O &\to \times \mid \div \\
      E &\to N \mid (E O E)
    \end{aligned}
  \end{equation}

  We can choose different non-terminals as the starting symbol. The symbol \( N \) corresponds to numbers, \( O \) corresponds to operations, and \( E \) can be either a number or an expression. We say that \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand} specifies a \term{grammar schema}. With any starting symbol, the grammar is clearly \hyperref[def:chomsky_hierarchy]{context-free}.
\end{example}

\begin{remark}\label{rem:backus_naur_form}
  The infinitude of possible rules in \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form} may not bother us formally, but when dealing with software implementations, we must have a finite number of rules. An example of a nontrivial grammar in the wild is the Python grammar that can be found in \cite{Python39Grammar}. There are also other advantages of introducing a more convenient metasyntax (a syntax for describing language syntax).

  For \hyperref[def:chomsky_hierarchy/context_free]{context-free grammars}, is often convenient to use the \term{Backus-Naur form (BNF)}. For \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}, the BNF is
  \begin{bnf*}
    \bnfprod{nonzero digit} {\bnfts{1} \bnfor \bnfts{2} \bnfor \bnfts{3} \bnfor \bnfts{4} \bnfor \bnfts{5} \bnfor \bnfts{6} \bnfor \bnfts{7} \bnfor \bnfts{8} \bnfor \bnfts{9}} \\
    \bnfprod{digit}         {\bnfts{0} \bnfor \bnfpn{nonzero digit}} \\
    \bnfprod{number}        {\bnfpn{nonzero digit} \bnfor \bnfpn{number} \bnfsp \bnfpn{digit}} \\
    \bnfprod{operation}     {\bnfts{\( \times \)} \bnfor \bnfts{\( \div \)}} \\
    \bnfprod{expression}    {\bnfpn{number} \bnfor \bnfts{(} \bnfsp \bnfpn{number} \bnfsp \bnfpn{operation} \bnfsp \bnfpn{number} \bnfsp \bnfts{)}}.
  \end{bnf*}

  The obvious difference is that we explicitly define numbers via their decimal representation, which means that we get a finite amount of rules. Compared to \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple} some other differences are:
  \begin{itemize}
    \item Variables are denoted by \( \langle \)words enclosed in angle brackets\( \rangle \), so that we can name variables more descriptively using more than one symbol.
    \item Terminals are, by convention, put in \enquote{quotes}. In human-readable rich text documents like this one, it is sometimes possible to use different fonts, and so instead of using \enquote{quotes} we specify terminals using an \texttt{upright typewriter font}.
    \item Free-text rules can be specified using a normal font. This is also only used in human-readable rich text documents, however this usage is justified because such rules are only beneficial for human understanding and not for machine parsing.
    \item By convention, the symbol \( \Coloneqq \) is used instead of \( \to \) for specifying transition rules.
    \item Different rules with the same, source are concatenated as in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}.
    \item In order to fully describe a context-free grammar, we must only specify its Backus-Naur form and its starting variable.
  \end{itemize}
\end{remark}

\begin{definition}\label{def:grammar_derivation}
  Fix a \hyperref[def:formal_grammar]{formal grammar} \( G = (V, S, \Sigma, \to) \).

  \begin{thmenum}
    \thmitem{def:grammar_derivation/derivation} We define the binary relation \( \Rightarrow \) on the Kleene star \( (V \cup \Sigma)^* \) by declaring that, for every two \hyperref[def:formal_language/word]{words} \( p \) and \( s \) over \( V \cup \Sigma \) and every production rule \( v \to w \), we have \( pvw \Rightarrow pws \). We also define the relation \( \Rightarrow_L \) as a restriction of \( \Rightarrow \) to the cases where \( p \) contains only terminal symbols and \( \Rightarrow_R \) --- if \( s \) contains only terminal symbols.

    A \term{derivation} of the word \( w_n \) from \( w_1 \) is a \hyperref[def:quiver_path/directed]{directed path} in the quiver induced by the relation \( \Rightarrow \), i.e.
    \begin{equation}\label{eq:def:grammar_derivation/derivation}
      w_1
      \reloset {u_1 \to v_1} \implies
      w_2
      \reloset {u_2 \to v_2} \implies
      \cdots
      \reloset {u_{n-2} \to v_{n-2}} \implies
      w_{n-1}
      \reloset {u_{n-1} \to v_{n-1}} \implies
      w_n.
    \end{equation}

    A \term{leftmost derivation} is a derivation performed using \( \Rightarrow_L \) rather than \( \Rightarrow \). \term{Rightmost derivations} are defined analogously.

    We say that \( w_n \) is \term{derivable} from \( w_1 \) if there exists a derivation from \( w_1 \) to \( w_n \).

    We denote the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \Rightarrow \) by \( \reloset + \Rightarrow \) and the \hyperref[def:relation_closures/reflexive]{reflexive} closure of \( \reloset + \Rightarrow \) by \( \reloset {*} \Rightarrow \). Clearly \( w_1 \) is derivable from \( w_n \) if and only if \( w_1 \reloset {*} \Rightarrow w_n \).

    The leftmost and rightmost derivations generate the same derivability relation --- the only potential difference is in the order of rule applications in the derivation itself.

    \thmitem{def:grammar_derivation/unambiguous}\mcite[def. 2.7]{Sipser2013} We say that the word \( w \) can be derived \term{unambiguously} if it has a unique leftmost derivation.

    Define the set
    \begin{equation*}
      D \coloneqq \set{ w \in (V \cup \Sigma)^* \colon S \reloset + \Rightarrow w }
    \end{equation*}
    of all words derivable from the starting symbol \( S \).

    If every word in \( D \) can be derived unambiguously, we say that the grammar itself is \term{unambiguous}.

    In an unambiguous grammar, \fullref{thm:structural_induction_on_unambiguous_grammars} can be used on the \hyperref[def:quiver/simple]{simple directed graph} \( (D, \Rightarrow_L) \). Indeed, every word in \( D \) is derivable from \( S \) and every leftmost derivation is unique.

    \thmitem{def:grammar_derivation/grammar_language} The \term{language} of the grammar is the set
    \begin{equation*}
      \mscrL(G) \coloneqq \set{ w \in \Sigma^* \colon S \reloset + \Rightarrow w }
    \end{equation*}
    of all terminal-only words derivable from the starting symbol \( S \).

    We also say that strings in \( \mscrL(G) \) are \term{generated} by the grammar \( G \).

    If a language can be generated by a \hyperref[def:chomsky_hierarchy/regular]{regular} grammar, we say that the language itself is regular, and similarly for \hyperref[def:chomsky_hierarchy/context_free]{context-free} and \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammars.

    For other grammars, for example \hyperref[def:chomsky_hierarchy/unrestricted]{unrestricted} or \hyperref[def:chomsky_hierarchy/non_contracting]{non-contracting}, such a terminology is not established.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/derivation}
  We continue \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}. Depending on our choice of starting symbol, we can derive different sets of words.

  For the sake of simplifying our exposition and proof, however, we will assume the simpler grammar described in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}.

  Choose the starting symbol to be \( E \). We will show that this grammar is unambiguous.

  \Cref{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous} demonstrates that removing the parentheses makes even this simple grammar ambiguous.

  \begin{figure}
    \hfill
    \includegraphics[page=1]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{The unique way to produce the parenthesized arithmetic expression \( ((6 \div 2) \times 3) \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/unambiguous}
  \end{figure}

  \begin{figure}
    \hfill
    \includegraphics[page=2]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{Different leftmost derivations of the parenthesis-less arithmetic expression \( 6 \div 3 \times 2 \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous}
  \end{figure}

  We will show that \( G \) is unambiguous. Let \( w \) be a word in \( \mscrL(G) \). We explicitly build the leftmost derivation of \( w \) using recursion on \( \len(w) \):
  \begin{itemize}
    \item If \( \len(w) = 1 \), then \( w = n \in \BbbN \), and the word has been derived as \( E \to N \to n \).

    \item Assume that \( w \) is unambiguously derived for \( \len(w) < m + 2 \) and let \( \len(w) = m + 2 \), then \( w \) is necessarily enclosed in parentheses. Let \( w = ( \sigma_1 \ldots \sigma_m ) \) be the symbols of \( w \). Because of the parentheses, the only possibility for \( \sigma_1 \ldots \sigma_m \) is that it consists of two words in \( \mscrL(G) \) with either a multiplication symbol \( \times \) or a division symbol \( \div \) between them. Let \( k \) be the index of the operator symbol, that is, the index such that \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) both belong to \( \mscrL(G) \).

    By the inductive hypothesis, both \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) are unambiguously derived from \( E \). Then \( w \) is generated by the rule \( E \to (E O E) \), where the operator symbol \( \sigma_k \) determines the terminal of \( O \). Therefore, the derivation of \( w \) is also unambiguous.
  \end{itemize}
\end{example}

\begin{definition}\label{def:ordered_arborescence}
  An \term{ordered arborescence} is an \hyperref[def:arborescence]{arborescence} \( T = (G, A) \) with a \hyperref[def:partially_ordered_set]{partial order} \( \leq \) such that every set of \hyperref[def:arborescence/ancestry]{siblings} is a \hyperref[def:partially_ordered_set_chain_and_antichain]{chain}.
\end{definition}

\begin{definition}\label{def:grammar_syntax_tree}\mimprovised
  Fix a \hyperref[def:chomsky_hierarchy/context_free]{context-free} \hyperref[def:formal_grammar]{formal grammar} \( G = (V, S, \Sigma, \to) \).

  For every word \( w \) in \( \mscrL(G) \), we will build an \hyperref[def:ordered_arborescence]{ordered} \hyperref[def:arborescence/undirected]{rooted tree} whose \hyperref[def:arborescence/ancestry]{leaves} are the symbols of \( w \) and whose root is \( S \). We will call this a \term{syntax tree} for \( w \).

  \begin{figure}
    \hfill
    \includegraphics[page=1]{output/alg__grammar_syntax_tree.pdf}
    \hfill\hfill
    \caption{A grammar tree corresponding to the expression \( (6 \div (3 \times 2)) \) from \cref{fig:ex:natural_number_arithmetic_grammar/derivation/unambiguous}}
    \label{fig:def:grammar_syntax_tree}
  \end{figure}

  Fix a derivation
  \begin{equation}\label{eq:def:grammar_syntax_tree/derivation}
    S \Rightarrow w_1 \Rightarrow \cdots \Rightarrow w_{n-1} \Rightarrow w_n.
  \end{equation}

  We use \hyperref[rem:natural_number_recursion]{natural number recursion} on \( n \) to build the tree. Note that, for the purposes of recursion, we allow \( w_n \) to contain non-terminals.

  \begin{itemize}
    \item In the trivial case where \( n = 0 \), and there is no actual derivation, we build a single-vertex tree with root \( S \).

    \item Suppose that we can build a tree for all derivations of length \( m - 1 \) and fix a derivation \eqref{eq:def:grammar_syntax_tree/derivation} of length \( n \).

    First, build a tree \( T \) from the derivation
    \begin{equation*}
      S \Rightarrow w_1 \Rightarrow \cdots \Rightarrow w_{n-2} \Rightarrow w_{n-1}.
    \end{equation*}

    There must exist words \( p \), \( s \) and \( v \) and a non-terminal \( A \) such that
    \begin{equation*}
      w_{n-1} = pAs \Rightarrow pvs = w_n.
    \end{equation*}

    There already exists a leaf for \( A \) in \( T \). For every symbol in \( v \), add a new node as a child of this node.
  \end{itemize}
\end{definition}

\begin{proposition}\label{thm:unambiguous_grammar_syntax_trees}
  A \hyperref[def:chomsky_hierarchy/context_free]{context-free} grammar is \hyperref[def:chomsky_hierarchy/context_free]{unambiguous} if and only if every word has a unique \hyperref[def:grammar_syntax_tree]{syntax tree}.
\end{proposition}

\begin{theorem}[Structural induction on unambiguous grammars]\label{thm:structural_induction_on_unambiguous_grammars}\mimprovised
  Unlike for the other induction principles in \fullref{rem:induction}, we will not formulate this one via logical formulas. This will complicate us unnecessarily. We will instead describe how the principle is used in practice.

  Let \( G = (V, S, \Sigma, \to) \) be an \hyperref[def:chomsky_hierarchy/context_free]{unambiguous} \hyperref[def:chomsky_hierarchy/context_free]{context-free} \hyperref[def:formal_grammar]{formal grammar}.

  Suppose that we want to prove a statement for every word in \( \mscrL(G) \). It is sufficient to perform the following for every rule \( A \to w \):
  \begin{displayquote}
    Let \( A_1, \ldots, A_n \) be all non-terminals of \( w \) and let \( u_0, \ldots, u_n \) be subwords of \( w \) such that
    \begin{equation*}
      w = u_0 A_1 u_1 A_2 \ldots A_n u_n.
    \end{equation*}

    Let \( v_1, \ldots, v_n \) be arbitrary words in \( \mscrL(G) \) derivable from \( A_1, \ldots, A_n \), respectively, so that we have the syntax tree
    \begin{equation*}
      \begin{aligned}
        \includegraphics[page=1]{output/thm__structural_induction_on_unambiguous_grammars.pdf}
      \end{aligned}
    \end{equation*}

    Then we must prove the statement for the word
    \begin{equation*}
      u_0 v_1 u_1 \ldots v_n u_n.
    \end{equation*}
  \end{displayquote}

  Compare this principle to the more general \fullref{thm:well_founded_induction}.
\end{theorem}
\begin{proof}
  Clearly every word in \( \mscrL(G) \) can be obtained in this way.
  The role of non-ambiguity is discussed in the proof of \fullref{thm:well_founded_induction}.
\end{proof}
