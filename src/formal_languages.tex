\subsection{Formal languages}\label{subsec:formal_languages}

Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:set_definition_recursion}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.

\begin{definition}\label{def:formal_language}
  Fix a nonempty set \( \mscrA \).

  \begin{thmenum}
    \thmitem{def:formal_language/alphabet} We call \( \mscrA \) an \term{alphabet}.

    \thmitem{def:formal_language/symbol} We call each element of \( \mscrA \) a \term{symbol}.

    \thmitem{def:formal_language/word} A \term{word} over \( \mscrA \) is a \hyperref[def:sequence]{finite sequence} of symbols. If \( (a, b, c) \) is a word, for convenience we write it as the string \( abc \). This is the reason words are also referred to as \term{strings}. This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    \thmitem{def:formal_language/empty_word} We denote the empty word by \( \varepsilon \).

    \thmitem{def:formal_language/word_length} The \term{length} \( \len(w) \) of a word \( w \) is the number of elements of the tuple \( w \).

    \thmitem{def:formal_language/concatenation} The \term{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) is the word
    \begin{equation*}
      vw \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \overbrace{w w \ldots w}^{k \T{times}} \) as \( w^k \). This is only a notation. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).

    \thmitem{def:formal_language/reverse} The \term{reverse word} of \( w = (w_1, \ldots, w_n) \) is
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:formal_language/prefix} The word \( p = (p_1, \ldots, p_m) \) is a \term{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:formal_language/suffix} The word \( s \) is a \term{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:formal_language/subword} The word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = pvs.
    \end{equation*}

    \thmitem{def:formal_language/kleene_star} The \term{Kleene star} \( \mscrA^* \) of \( \mscrA \) is the set of all words over \( \mscrA \). If we wish to exclude the empty word, like we often do, we instead write \( \mscrA^+ \) for the set of all non-empty words over \( \mscrA \).

    \thmitem{def:formal_language/language} A \term{language} over \( \mscrA \) is any subset of \( \mscrA^* \). Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic} the term \enquote{language} may refer to the alphabet itself (see \fullref{rem:propositional_language_is_alphabet}).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:kleene_star_is_monoid}
  For any alphabet \( \mscrA \), the Kleene star \( \mscrA^* \) is a \hyperref[def:unital_magma/associative]{monoid} under concatenation.
\end{proposition}
\begin{proof}
  Concatenation is clearly associative and the empty word \( \varepsilon \) is a \hyperref[def:magma_identity]{two-sided identity} under concatenation.
\end{proof}

\begin{definition}\label{def:formal_grammar}\mcite[def. 2.2]{Sipser2013}
  Let \( V \) and \( \Sigma \) be disjoint nonempty subsets of some \hyperref[def:formal_language/alphabet]{alphabet}.

  \begin{thmenum}
    \thmitem{def:formal_grammar/terminals} We call elements of \( \Sigma \) \term{terminals}. We denote terminals in abstract grammars using lowercase Greek letters, and we denote words using lowercase Latin letters.

    \thmitem{def:formal_grammar/non_terminals} We call elements of \( V \) \term{non-terminals}. By convention, variables are denoted using capital letters.

    \thmitem{def:formal_grammar/start} We assume that a special \term{start symbol} \( S \in V \) is fixed.

    \thmitem{def:formal_grammar/production_rules} We define a binary \hyperref[def:relation]{relation} \( \to \) of \term{production rules} over \( (V \cup \Sigma)^* \).

    We impose the restriction that no rules of the form \( \varepsilon \to v \) exist for any word \( v \). We do allow, however, production rules of the form \( v \to \varepsilon \). Such rules are called \term{\( \varepsilon \)-rules}.

    Rules describe transformations that define how a language is \enquote{generated} starting from \( S \). See \fullref{def:grammar_derivation} and \fullref{ex:natural_number_arithmetic_grammar/derivation}.

    \thmitem{def:formal_grammar/grammar} The quadruple \( G \coloneqq (V, S, \Sigma, \to) \) is called a \term{formal grammar} or simply a \term{grammar}.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:chomsky_hierarchy}
  We will define the \term{Chomsky hierarchy} of \hyperref[def:formal_grammar]{formal grammars}. We can classify a grammar \( G = (V, S, \Sigma, \to) \) as follows, based on their rules:
  \begin{thmenum}
    \thmitem{def:chomsky_hierarchy/unrestricted} In general, every production rule has the form \( v \to w \), where both \( v \) and \( w \) are words consisting of terminal and non-terminals, and \( v \) is nonempty.

    When no additional restrictions are imposed on the rules of the grammar, we call it \term{unrestricted grammar}. The other levels of the hierarchy are subsets of the unrestricted grammars.

    \thmitem{def:chomsky_hierarchy/non_contracting} The grammar is \term{non-contracting} if \( \len(v) \leq \len(w) \) for every production rule \( v \to w \).

    \thmitem{def:chomsky_hierarchy/context_sensitive} The grammar is \term{context-sensitive} if every rule has the form \( aAb \to w \) for some non-terminal \( A \), arbitrary words \( a \) and \( b \), and a nonempty word \( w \).

    The requirement for \( w \) to be nonempty is set up so that context-sensitive grammars are non-contracting.

    \thmitem{def:chomsky_hierarchy/context_free} The grammar is \term{context-free} every rule has the form \( A \to w \) for some non-terminal \( A \) and a nonempty word \( w \).

    Unlike for context-sensitive languages, \( w \) is allowed to be empty. Thus, a context-free grammar is non-contracting, however it may not be context-sensitive if it has \( \varepsilon \)-rules.

    \thmitem{def:chomsky_hierarchy/regular} Finally, the grammar is \term{regular} if every rule has one of the forms
    \begin{align*}
      &A \to \varepsilon, \\
      &A \to B \tau, \\
      &A \to \tau B, \\
      &A \to \tau,
    \end{align*}
    where \( A \) and \( B \) are non-terminals and \( \tau \) is a terminal.

    Regular grammars are obviously context-free.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/backus_naur_form}
  We define a grammar for primary school notation of multiplication and division of \hyperref[def:set_of_natural_numbers]{natural numbers}. Note that we consider the numbers in \( \BbbN \) only as symbols, without any regard to semantics.

  Let \( V \coloneqq \set{ E } \) and \( \Sigma \coloneqq \BbbN \cup \set{ \times, \div, (, ) } \). Define the grammar
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}
    \begin{aligned}
      &E \to 0 \\
      &E \to 1 \\
      &\phantom{E \to} \vdots \\
      &E \to n \\
      &\phantom{E \to} \vdots \\
      &E \to (E \times E) \\
      &E \to (E \div E)
    \end{aligned}
  \end{equation}

  We can use the following shorthand:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}
    E \to 0 \mid 1 \mid \ldots \mid (E \times E) \mid (E \div E).
  \end{equation}

  This grammar is clearly \hyperref[def:chomsky_hierarchy]{context-free}.

  The infinitude of possible rules may not bother us formally, but when dealing with software implementations, we must have a finite number of rules. An example of a nontrivial grammar in the wild is the Python grammar that can be found in \cite{Python39Grammar}.

  There are other advantages of introducing a more convenient metasyntax (a syntax for describing language syntax).

  For \hyperref[def:chomsky_hierarchy/context_free]{context-free grammars}, is often convenient to use the \term{Backus-Naur form (BNF)}. In our example, this becomes
  \begin{bnf*}
    \bnfprod{nonzero digit} {\bnfts{1} \bnfor \bnfts{2} \bnfor \bnfts{3} \bnfor \bnfts{4} \bnfor \bnfts{5} \bnfor \bnfts{6} \bnfor \bnfts{7} \bnfor \bnfts{8} \bnfor \bnfts{9}} \\
    \bnfprod{digit}         {\bnfts{0} \bnfor \bnfpn{nonzero digit}} \\
    \bnfprod{number}        {\bnfpn{nonzero digit} \bnfor \bnfpn{number} \bnfsp \bnfpn{digit}} \\
    \bnfprod{operation}     {\bnfts{\( \times \)} \bnfor \bnfts{\( \div \)}} \\
    \bnfprod{expression}    {\bnfpn{number} \bnfor \bnfts{(} \bnfsp \bnfpn{number} \bnfsp \bnfpn{operation} \bnfsp \bnfpn{number} \bnfsp \bnfts{)}}.
  \end{bnf*}
  with \( \bnfpn{expression} \) as the starting variable.

  The obvious difference is that we explicitly define numbers via their decimal representation, which means that we get a finite amount of rules. Compared to \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple} some other differences are:
  \begin{itemize}
    \item Variables are denoted by \( \langle \)words enclosed in angle brackets\( \rangle \), so that we can name variables more descriptively using more than one symbol.
    \item Terminals are, by convention, put in \enquote{quotes}. In human-readable rich text documents like this one, it is sometimes possible to use different fonts, and so instead of using \enquote{quotes} we specify terminals using an \texttt{upright typewriter font}.
    \item Free-text rules can be specified using a normal font. This is also only used in human-readable rich text documents, however this usage is justified because such rules are only beneficial for human understanding and not for machine parsing.
    \item By convention, the symbol \( \Coloneqq \) is used instead of \( \to \) for specifying transition rules.
    \item Different rules with the same, source are concatenated as in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}.
    \item In order to fully describe a context-free grammar, we must only specify its Backus-Naur form and its starting variable.
  \end{itemize}
\end{example}

\begin{definition}\label{def:backus_naur_form}
  We have defined the \term{Backus-Naur form} of a \hyperref[def:chomsky_hierarchy/context_free]{context-free grammar} in \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}.

  Although formally necessary for \fullref{def:formal_grammar}, it is of slight inconvenience to explicitly specify the starting variable for a nontrivial grammar in Backus-Naur form because the same Backus-Naur form can be used with different starting variables.

  For this reason, we will say that the Backus-Naur form specifies \term{grammar schemas} and not grammars. Given a grammar schema, we can select any of its variables to obtain a grammar.
\end{definition}

\begin{definition}\label{def:grammar_derivation}
  Fix a \hyperref[def:formal_grammar]{formal grammar} \( G = (V, S, \Sigma, \to) \).

  \begin{thmenum}
    \thmitem{def:grammar_derivation/derivation} We define the binary relation \( \Rightarrow \) on the Kleene star \( (V \cup \Sigma)^* \) by declaring that, for every two \hyperref[def:formal_language/word]{words} \( p \) and \( s \) over \( V \cup \Sigma \) and every production rule \( v \to w \), we have \( pvw \Rightarrow pws \). We also define the relation \( \Rightarrow_L \) as a restriction of \( \Rightarrow \) to the cases where \( p \) contains only terminal symbols and \( \Rightarrow_R \) --- if \( s \) contains only terminal symbols.

    A \term{derivation} of the word \( w_n \) from \( w_1 \) is a \hyperref[def:quiver_path/directed]{directed path} in the quiver induced by the relation \( \Rightarrow \), i.e.
    \begin{equation}\label{eq:def:grammar_derivation/derivation}
      w_1 \Rightarrow w_2 \Rightarrow \cdots \Rightarrow  w_{n-1} \Rightarrow  w_n
    \end{equation}

    A \term{leftmost derivation} is a derivation performed using \( \Rightarrow_L \) rather than \( \Rightarrow \). \term{Rightmost derivations} are defined analogously.

    We say that \( w_n \) is \term{derivable} from \( w_1 \) if there exists a derivation from \( w_1 \) to \( w_n \).

    We denote the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \Rightarrow \) by \( \reloset + \Rightarrow \) and the \hyperref[def:relation_closures/reflexive]{reflexive} closure of \( \reloset + \Rightarrow \) by \( \reloset {*} \Rightarrow \). Clearly \( w_1 \) is derivable from \( w_n \) if and only if \( w_1 \reloset {*} \Rightarrow w_n \).

    The leftmost and rightmost derivations generate the same derivability relation --- the only potential difference is in the order of rule applications in the derivation itself.

    \thmitem{def:grammar_derivation/unambiguous}\mcite[def. 2.7]{Sipser2013} We say that the word \( w \) can be derived \term{unambiguously} if it has a unique leftmost derivation.

    Define the set
    \begin{equation*}
      D \coloneqq \set{ w \in (V \cup \Sigma)^* \colon S \reloset + \Rightarrow w }
    \end{equation*}
    of all words derivable from the starting symbol \( S \).

    If every word in \( D \) can be derived unambiguously, we say that the grammar itself is unambiguous.

    In an unambiguous grammar, \fullref{thm:structural_induction} can be used on the \hyperref[def:quiver/simple]{simple directed graph} \( (D, \Rightarrow_L) \). Indeed, every word in \( D \) is derivable from \( S \) and every leftmost derivation is unique.

    \thmitem{def:grammar_derivation/grammar_language} The \term{language} of the grammar is the set
    \begin{equation*}
      \mscrL(G) \coloneqq \set{ w \in \Sigma^* \colon S \reloset + \Rightarrow w }
    \end{equation*}
    of all terminal-only words derivable from the starting symbol \( S \).

    We also say that strings in \( \mscrL(G) \) are \term{generated} by the grammar \( G \).

    If a language can be generated by a \hyperref[def:chomsky_hierarchy/regular]{regular} grammar, we say that the language itself is regular, and similarly for \hyperref[def:chomsky_hierarchy/context_free]{context-free} and \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammars.

    For other grammars, for example \hyperref[def:chomsky_hierarchy/unrestricted]{unrestricted} or \hyperref[def:chomsky_hierarchy/non_contracting]{non-contracting}, such a terminology is not established.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/derivation}
  We continue \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}. Depending on our choice of starting symbol, we can derive different sets of words.

  For the sake of simplifying our exposition and proof, however, we will assume the simpler grammar described in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}.

  Choose the starting symbol to be \( E \). We will show that this grammar is unambiguous.

  \Cref{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous} demonstrates that removing the parentheses makes even this simple grammar ambiguous.

  \begin{figure}
    \hfill
    \includegraphics[page=1]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{The unique way to produce the parenthesized arithmetic expression \( ((6 \div 2) \times 3) \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/unambiguous}
  \end{figure}

  \begin{figure}
    \hfill
    \includegraphics[page=2]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{Different leftmost derivations of the parenthesis-less arithmetic expression \( 6 \div 2 \times 3 \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous}
  \end{figure}
\end{example}
\begin{proof}
  We will show that \( G \) is unambiguous. Let \( w \) be a word in \( \mscrL(G) \). We explicitly build the leftmost derivation of \( w \) using recursion on \( \len(w) \):
  \begin{itemize}
    \item If \( \len(w) = 1 \), then \( w = n \in \BbbN \), and the word has been generated by the rule \( E \to n \).

    \item Assume that \( w \) is unambiguously derived for \( \len(w) < m + 2 \) and let \( \len(w) = m + 2 \), then \( w \) is necessarily enclosed in parentheses. Let \( w = ( \sigma_1 \ldots \sigma_m ) \) be the symbols of \( w \). Because of the parentheses, the only possibility for \( \sigma_1 \ldots \sigma_m \) is that it consists of two words in \( \mscrL(G) \) with either a multiplication symbol \( \times \) or a division symbol \( \div \) between them. Let \( k \) be the index of the operator symbol, that is, the index such that \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) both belong to \( \mscrL(G) \).

    By the inductive hypothesis, both \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) are unambiguously derived. Depending on the operator symbol \( \sigma_k \), there are two possible rules for how \( w \) has been generated from the subwords \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \). Therefore, the derivation of \( w \) is also unambiguous.
  \end{itemize}
\end{proof}
