\subsection{Formal languages}\label{subsec:formal_languages}

\begin{remark}\label{rem:language_definitions_using_sets}
  Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:sets}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.
\end{remark}

\begin{definition}\label{def:language}
  Fix a nonempty set \( \mscrA \).

  \begin{thmenum}
    \thmitem{def:language/alphabet} We call \( \mscrA \) an \term{alphabet}.

    \thmitem{def:language/symbol} We call each element of \( \mscrA \) a \term{symbol}.

    \thmitem{def:language/word} A \term{word} over \( \mscrA \) is a \hyperref[def:tuple_and_cartesian_product]{tuple} of symbols. If \( (a, b, c) \) is a word, for convenience we write it as the string \( abc \). This is the reason words are also referred to as \term{strings}. This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    \thmitem{def:language/empty_word} We denote the empty word by \( \varepsilon \).

    \thmitem{def:language/word_length} The \term{length} \( \len(w) \) of a word \( w \) is the number of elements of the tuple \( w \).

    \thmitem{def:language/concatenation} The \term{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) is the word
    \begin{equation*}
      vw \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \overbrace{w w \ldots w}^{k \T{times}} \) as \( w^k \). This is only a notation. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).

    \thmitem{def:language/reverse} The \term{reverse word} of \( w = (w_1, \ldots, w_n) \) is
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:language/prefix} The word \( p = (p_1, \ldots, p_m) \) is a \term{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:language/suffix} The word \( s \) is a \term{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:language/subword} The word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = pvs.
    \end{equation*}

    \thmitem{def:language/kleene_star} The \term{Kleene star} \( \mscrA^{\ast} \) of \( \mscrA \) is the set of all (finite) words over \( \mscrA \).

    \thmitem{def:language/language} A \term{language} over \( \mscrA \) is any subset of \( \mscrA^{\ast} \). Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic} the term \enquote{language} may refer to the alphabet itself (see \fullref{rem:propositional_language_is_alphabet}).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:kleene_star_is_monoid}
  For any alphabet \( \mscrA \), the Kleene star \( \mscrA^{\ast} \) is a \hyperref[def:unital_magma/associative]{monoid} under concatenation.
\end{proposition}
\begin{proof}
  Concatenation is clearly associative and the empty word \( \varepsilon \) is a \hyperref[def:magma_identity]{two-sided identity} under concatenation.
\end{proof}

\begin{definition}\label{def:grammar}\mcite[def. 2.2]{Sipser2013}
  Let \( \mscrA \) be some \hyperref[def:language/alphabet]{alphabet} and let \( V, \Sigma \) be disjoint nonempty subsets of \( \mscrA \).

  \begin{thmenum}
    \thmitem{def:grammar/variables} We call elements of \( V \) \term{variables} or \term{non-terminals}. By convention, variables are denoted using capital letters, but this is only done when abstractly studying grammars. When dealing with concrete grammars, we use Backus-Naur forms (see \fullref{def:backus_naur_form}).

    \thmitem{def:grammar/terminals} We call elements of \( \Sigma \) \term{terminals}. We denote terminals in abstract grammars using lowercase Greek letters because we denote words using lowercase Latin letters.

    \thmitem{def:grammar/start} We assume that a special \term{start symbol} \( S \in V \) is fixed.

    \thmitem{def:grammar/production_rules} We define a binary \hyperref[def:relation]{relation} \( \to \) of \term{production rules} over \( (V \cup \Sigma)^* \). Rules describe transformations that define how a language is \enquote{generated} starting from \( S \in V \) (see \fullref{def:grammar_derivation} and \fullref{ex:natural_number_arithmetic_grammar/derivation}).

    \thmitem{def:grammar/terminal_rules} Rules of the form \( u \to \sigma \), where \( \sigma \in \Sigma \), are called \term{terminal rules}.

    \thmitem{def:grammar/grammar} The tuple \( G \coloneqq (V, \Sigma, \to, S) \) is called a \term{formal grammar} or simply a \term{grammar}.

    \thmitem{def:grammar/context_free} If every production rule has only a single variable for a, source, i.e. if for every rule \( u \to v \) we have \( u = A \) for some \( A \in V \), we say that the grammar is \term{context-free}.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/backus_naur_form}
  We define a grammar for addition and multiplication of \hyperref[def:set_of_natural_numbers]{natural numbers}. Note that we consider the numbers in \( \BbbN \) only as symbols, without any regard to the numbers themselves.

  Let \( V \coloneqq \{ E \} \) and \( \Sigma \coloneqq \BbbN \cup \{ +, (, ) \} \). Define the grammar
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}
    \begin{aligned}
      &E \to 0 \\
      &E \to 1 \\
      &\phantom{E \to} \vdots \\
      &E \to n \\
      &\phantom{E \to} \vdots \\
      &E \to (E + E) \\
      &E \to (E \cdot E)
    \end{aligned}
  \end{equation}

  We can use the following shorthand:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}
    E \to 0 \mid 1 \mid \ldots \mid (E + E) \mid (E \cdot E).
  \end{equation}

  The infinitude of possible rules may not bother us formally, but when dealing with, software implementations (e.g. the Python grammar that can be found in \cite{Python39Grammar}), we must have a finite number of rules.

  There are other advantages of introducing a more convenient metasyntax (a syntax for describing language syntax).

  For \hyperref[def:grammar/context_free]{context-free grammars}, is often convenient to use the \term{Backus-Naur form (BNF)}. In our example, this becomes
  \begin{bnf*}
    \bnfprod{nonzero digit} {\bnfts{1} \bnfor \bnfts{2} \bnfor \bnfts{3} \bnfor \bnfts{4} \bnfor \bnfts{5} \bnfor \bnfts{6} \bnfor \bnfts{7} \bnfor \bnfts{8} \bnfor \bnfts{9}} \\
    \bnfprod{digit}         {\bnfts{0} \bnfor \bnfpn{nonzero digit}} \\
    \bnfprod{number}        {\bnfpn{nonzero digit} \bnfor \bnfpn{number} \bnfsp \bnfpn{digit}} \\
    \bnfprod{operation}     {\bnfts{+} \bnfor \bnfts{\( \cdot \)}} \\
    \bnfprod{expression}    {\bnfpn{number} \bnfor \bnfts{(} \bnfsp \bnfpn{number} \bnfsp \bnfpn{operation} \bnfsp \bnfpn{number} \bnfsp \bnfts{)}}.
  \end{bnf*}
  with \( \bnfpn{expression} \) as the starting variable.

  The obvious difference is that we explicitly define numbers via their decimal representation, which means that we get a finite amount of rules. Compared to \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple} some other differences are:
  \begin{enumerate}
    \item Variables are denoted by \( \langle \)words enclosed in angle brackets\( \rangle \), so that we can name variables more descriptively using more than one symbol.
    \item Terminals are, by convention, put in \enquote{quotes}. In human-readable rich text documents like this one, it is sometimes possible to use different fonts, and so instead of using \enquote{quotes} we specify terminals using an \texttt{upright typewriter font}.
    \item Free-text rules can be specified using a normal font. This is also only used in human-readable rich text documents, however this usage is justified because such rules are only beneficial for human understanding and not for machine parsing.
    \item By convention, the symbol \( \Coloneqq \) is used instead of \( \to \) for specifying transition rules.
    \item Different rules with the same, source are concatenated as in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}.
    \item In order to fully describe a context-free grammar, we must only specify its Backus-Naur form and its starting variable.
  \end{enumerate}
\end{example}

\begin{definition}\label{def:backus_naur_form}
  We have defined the \term{Backus-Naur form} of a \hyperref[def:grammar/context_free]{context-free grammar} in \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}.

  Although formally necessary for \fullref{def:grammar}, it is of slight inconvenience to explicitly specify the starting variable for a nontrivial grammar in Backus-Naur form because the same Backus-Naur form can be used with different starting variables.

  For this reason, we will say that the Backus-Naur form specifies \term{grammar schemas} and not grammars. Given a grammar schema, we can select any of its variables to obtain a grammar.
\end{definition}

\begin{definition}\label{def:grammar_derivation}\mcite[page 104 \\ page 108]{Sipser2013}
  Fix a \hyperref[def:grammar]{formal grammar} \( G = (V, \Sigma, \to, S) \).

  \begin{thmenum}
    \thmitem{def:grammar_derivation/yields} Fix two \hyperref[def:language/word]{words} \( w = pvs \) and \( w' = pv's \). If \( v \to v' \) is a production rule, we say that \( w \) \term{yields} \( w' \) and write \( w \Rightarrow w' \).

    \thmitem{def:grammar_derivation/derivation} We say that the word \( u \) \term{derives} \( w \) and write \( u \Rrightarrow w \) if there exists a finite sequence of words \( v_1, \ldots, v_n \) such that
    \begin{equation*}
      u \Rightarrow v_1 \Rightarrow \ldots \Rightarrow v_n \Rightarrow w.
    \end{equation*}

    The sequence \( u, v_1, \ldots, v_n, w \) is called a \term{derivation} of \( w \) from \( v \).

    \thmitem{def:grammar_derivation/leftmost_rightmost_derivation} If on every step of the derivation the leftmost (resp. rightmost) variable is replaced, we say that it is a \term{leftmost} (resp. \term{rightmost}) derivation.

    \thmitem{def:grammar_derivation/grammar_language} The \term{language} of the grammar is the set
    \begin{equation*}
      \mscrL(G) \coloneqq \{ w \in \Sigma^* \colon S \T{derives} w \}
    \end{equation*}
    of all words that can be derived from \( S \) and contains only terminals.

    We also say that strings in \( \mscrL(G) \) are \term{generated} by the grammar \( G \).

    If a language can be generated by a \hyperref[def:grammar/context_free]{context-free grammar}, we say that it is a \term{context-free language}.

    \thmitem{def:grammar_derivation/ambiguity}\mcite[def. 2.7]{Sipser2013}We say that the word \( w \) can be derived \term{unambiguously} if there exists a unique leftmost derivation from \( S \). Otherwise, we say that \( w \) is generated \term{ambiguously} and that the grammar itself is \term{ambiguous}.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/derivation}
  We continue \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}. Depending on our choice of starting symbol, we can derive different sets of words.

  For the sake of simplifying our exposition and proof, however, we will assume the simpler grammar described in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}.

  Choose the starting symbol to be \( E \). We will show that this grammar is unambiguous.

  \Cref{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous} demonstrates that removing the parentheses makes even this simple grammar ambiguous.

  \begin{figure}
    \hfill
    \includegraphics[page=1]{figures/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{The unique way to produce the parenthesized arithmetic expression \( ((1 + 2) + 3) \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/unambiguous}
  \end{figure}

  \begin{figure}
    \hfill
    \includegraphics[page=2]{figures/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill
    \includegraphics[page=3]{figures/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{Derivation of the parenthesis-less arithmetic expression \( 1 + 2 + 3 \) using left and right recursion}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous}
  \end{figure}
\end{example}
\begin{proof}
  We will show that \( G \) is unambiguous. Let \( w \) be a word in \( \mscrL(G) \). We explicitly build the derivation of \( w \) by induction on \( \len(w) \):
  \begin{itemize}
    \item If \( \len(w) = 1 \), then \( w = n \in \BbbN \) and the word has been generated by the single rule \( A \to n \).

    \item Assume that \( w \) is unambiguously derived for \( \len(w) < m + 2 \) and let \( \len(w) = m + 2 \), then \( w \) is necessarily enclosed in parentheses. Let \( w = ( \sigma_1 \ldots \sigma_m ) \) be the symbols of \( w \). Because of the parentheses, the only possibility for \( \sigma_1 \ldots \sigma_m \) is that it consists of two words in \( \mscrL(G) \) with either an addition symbol \( + \) or a multiplication symbol \( \cdot \) between them. Let \( k \) be the index of the operator symbol, that is, the index such that \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) both belong to \( \mscrL(G) \).

    By inductive hypothesis, both \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) are unambiguously derived. Depending on the operator symbol \( \sigma_k \), there are two possible rules for how \( w \) has been generated from the subwords \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \). Therefore, the derivation of \( w \) is also unambiguous.
  \end{itemize}
\end{proof}
