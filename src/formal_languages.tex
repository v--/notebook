\subsection{Formal languages}\label{subsec:formal_languages}

Languages are used to define formulas for expressing the \hyperref[def:zfc]{axioms of set theory}. Here, sets are used to formally define languages. A simple way out of this vicious cycle is via the theory-metatheory relationship discussed in \fullref{rem:metalogic} and \fullref{rem:set_definition_recursion}. In short, we define languages within the metatheory using the already available concept of set, and we later define formulas, again in the metatheory, which allows us to subsequently formally define sets via axioms within the object logic.

\begin{definition}\label{def:formal_language}
  Fix a nonempty set \( \mscrA \).

  \begin{thmenum}
    \thmitem{def:formal_language/alphabet} We call \( \mscrA \) an \term{alphabet}.

    \thmitem{def:formal_language/symbol} We call each element of \( \mscrA \) a \term{symbol}.

    \thmitem{def:formal_language/word} A \term{word} over \( \mscrA \) is a \hyperref[def:sequence]{finite sequence} of symbols. If \( (a, b, c) \) is a word, for convenience we write it as the string \( abc \). This is the reason words are also referred to as \term{strings}. This notation only makes sense if each symbol of the language is actually represented by one typographic symbol.

    \thmitem{def:formal_language/empty_word} We denote the empty word by \( \varepsilon \).

    \thmitem{def:formal_language/word_length} The \term{length} \( \len(w) \) of a word \( w \) is the number of elements of the tuple \( w \).

    \thmitem{def:formal_language/concatenation} The \term{concatenation} of the words \( v = (v_1, \ldots, v_n) \) and \( w = (w_1, \ldots, w_m) \) is the word
    \begin{equation*}
      vw \coloneqq (v_1, \ldots, v_n, w_1, \ldots, w_m).
    \end{equation*}

    We abbreviate \( \overbrace{w w \ldots w}^{k \T{times}} \) as \( w^k \). This is only a notation. We do not distinguish, formally, between the words \( aaabbaa \) and \( a^3 b^2 a^2 \), nor between \( a \varepsilon b \) and \( ab \).

    \thmitem{def:formal_language/reverse} The \term{reverse word} of \( w = (w_1, \ldots, w_n) \) is
    \begin{equation*}
      \op{rev}(w) \coloneqq (w_n, \ldots, w_1).
    \end{equation*}

    \thmitem{def:formal_language/prefix} The word \( p = (p_1, \ldots, p_m) \) is a \term{prefix} of \( w = (w_1, \ldots, w_n) \) if
    \begin{equation*}
      w = (\underbrace{p_1, \ldots, p_m}_p, w_{m+1}, \ldots, w_n).
    \end{equation*}

    \thmitem{def:formal_language/suffix} The word \( s \) is a \term{suffix} of \( w \) if \( \op{rev}(s) \) is a prefix of \( \op{rev}(w) \).

    \thmitem{def:formal_language/subword} The word \( v \) is a \term{subword} of \( w \) if there exists a prefix \( p \) and a suffix \( s \) of \( v \) such that
    \begin{equation*}
      w = pvs.
    \end{equation*}

    \thmitem{def:formal_language/kleene_star} The \term{Kleene star} \( \mscrA^* \) of \( \mscrA \) is the set of all words over \( \mscrA \). If we wish to exclude the empty word, like we often do, we instead write \( \mscrA^+ \) for the set of all non-empty words over \( \mscrA \).

    \thmitem{def:formal_language/language} A \term{language} over \( \mscrA \) is any subset of \( \mscrA^* \). Note that in some contexts like \hyperref[subsec:propositional_logic]{propositional logic} or \hyperref[subsec:first_order_logic]{first-order logic} the term \enquote{language} may refer to the alphabet itself (see \fullref{rem:propositional_language_is_alphabet}).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:kleene_star_is_monoid}
  For any alphabet \( \mscrA \), the Kleene star \( \mscrA^* \) is a \hyperref[def:unital_magma/associative]{monoid} under concatenation.
\end{proposition}
\begin{proof}
  Concatenation is clearly associative and the empty word \( \varepsilon \) is a \hyperref[def:magma_identity]{two-sided identity} under concatenation.
\end{proof}

\begin{definition}\label{def:formal_grammar}\mcite[def. 2.2]{Sipser2013}
  Let \( V \) and \( \Sigma \) be disjoint nonempty subsets of some \hyperref[def:formal_language/alphabet]{alphabet}.

  \begin{thmenum}
    \thmitem{def:formal_grammar/terminals} We call elements of \( \Sigma \) \term{terminals}. We denote terminals in abstract grammars using lowercase Greek letters, and we denote words using lowercase Latin letters.

    \thmitem{def:formal_grammar/non_terminals} We call elements of \( V \) \term{non-terminals}. By convention, variables are denoted using capital letters.

    \thmitem{def:formal_grammar/start} We assume that a special \term{start symbol} \( S \in V \) is fixed.

    \thmitem{def:formal_grammar/production_rules} We define a binary \hyperref[def:relation]{relation} \( \to \) of \term{production rules} over \( (V \cup \Sigma)^* \).

    We impose the restriction that no rules of the form \( \varepsilon \to v \) exist for any word \( v \). We do allow, however, production rules of the form \( v \to \varepsilon \). Such rules are called \term{\( \varepsilon \)-rules}.

    Rules describe transformations that define how a language is \enquote{generated} starting from \( S \). See \fullref{def:grammar_derivation} and \fullref{ex:natural_number_arithmetic_grammar/derivation}.

    \thmitem{def:formal_grammar/grammar} The quadruple \( G \coloneqq (V, S, \Sigma, \to) \) is called a \term{formal grammar} or simply a \term{grammar}.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:chomsky_hierarchy}
  We will define the \term{Chomsky hierarchy} of \hyperref[def:formal_grammar]{formal grammars}. We can classify a grammar \( G = (V, S, \Sigma, \to) \) as follows, based on their rules:
  \begin{thmenum}
    \thmitem{def:chomsky_hierarchy/unrestricted} In general, every production rule has the form \( v \to w \), where both \( v \) and \( w \) are words consisting of terminal and non-terminals, and \( v \) is nonempty.

    When no additional restrictions are imposed on the rules of the grammar, we call it \term{unrestricted grammar}. The other levels of the hierarchy are subsets of the unrestricted grammars.

    \thmitem{def:chomsky_hierarchy/non_contracting} The grammar is \term{non-contracting} if \( \len(v) \leq \len(w) \) for every production rule \( v \to w \).

    \thmitem{def:chomsky_hierarchy/context_sensitive} The grammar is \term{context-sensitive} if every rule has the form \( aAb \to w \) for some non-terminal \( A \), arbitrary words \( a \) and \( b \), and a nonempty word \( w \).

    The requirement for \( w \) to be nonempty is set up so that context-sensitive grammars are non-contracting.

    \thmitem{def:chomsky_hierarchy/context_free} The grammar is \term{context-free} every rule has the form \( A \to w \) for some non-terminal \( A \) and a nonempty word \( w \).

    Unlike for context-sensitive languages, \( w \) is allowed to be empty. Thus, a context-free grammar is non-contracting, however it may not be context-sensitive if it has \( \varepsilon \)-rules.

    \thmitem{def:chomsky_hierarchy/regular} Finally, the grammar is \term{regular} if every rule has one of the forms
    \begin{align*}
      &A \to \varepsilon, \\
      &A \to B \tau, \\
      &A \to \tau B, \\
      &A \to \tau,
    \end{align*}
    where \( A \) and \( B \) are non-terminals and \( \tau \) is a terminal.

    Regular grammars are obviously context-free.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/backus_naur_form}
  We define a grammar for primary school notation of multiplication and division of \hyperref[def:set_of_natural_numbers]{natural numbers}. Note that we consider the numbers in \( \BbbN \) only as symbols, without any regard to semantics.

  Let \( V \coloneqq \set{ E } \) and \( \Sigma \coloneqq \BbbN \cup \set{ \times, \div, (, ) } \). Define the grammar
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}
    \begin{aligned}
      &E \to 0 \\
      &E \to 1 \\
      &\phantom{E \to} \vdots \\
      &E \to n \\
      &\phantom{E \to} \vdots \\
      &E \to (E \times E) \\
      &E \to (E \div E)
    \end{aligned}
  \end{equation}

  We can use the following shorthand:
  \begin{equation}\label{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}
    E \to 0 \mid 1 \mid \ldots \mid (E \times E) \mid (E \div E).
  \end{equation}

  This grammar is clearly \hyperref[def:chomsky_hierarchy]{context-free}.

  The infinitude of possible rules may not bother us formally, but when dealing with software implementations, we must have a finite number of rules. An example of a nontrivial grammar in the wild is the Python grammar that can be found in \cite{Python39Grammar}.

  There are other advantages of introducing a more convenient metasyntax (a syntax for describing language syntax).

  For \hyperref[def:chomsky_hierarchy/context_free]{context-free grammars}, is often convenient to use the \term{Backus-Naur form (BNF)}. In our example, this becomes
  \begin{bnf*}
    \bnfprod{nonzero digit} {\bnfts{1} \bnfor \bnfts{2} \bnfor \bnfts{3} \bnfor \bnfts{4} \bnfor \bnfts{5} \bnfor \bnfts{6} \bnfor \bnfts{7} \bnfor \bnfts{8} \bnfor \bnfts{9}} \\
    \bnfprod{digit}         {\bnfts{0} \bnfor \bnfpn{nonzero digit}} \\
    \bnfprod{number}        {\bnfpn{nonzero digit} \bnfor \bnfpn{number} \bnfsp \bnfpn{digit}} \\
    \bnfprod{operation}     {\bnfts{\( \times \)} \bnfor \bnfts{\( \div \)}} \\
    \bnfprod{expression}    {\bnfpn{number} \bnfor \bnfts{(} \bnfsp \bnfpn{number} \bnfsp \bnfpn{operation} \bnfsp \bnfpn{number} \bnfsp \bnfts{)}}.
  \end{bnf*}
  with \( \bnfpn{expression} \) as the starting variable.

  The obvious difference is that we explicitly define numbers via their decimal representation, which means that we get a finite amount of rules. Compared to \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple} some other differences are:
  \begin{itemize}
    \item Variables are denoted by \( \langle \)words enclosed in angle brackets\( \rangle \), so that we can name variables more descriptively using more than one symbol.
    \item Terminals are, by convention, put in \enquote{quotes}. In human-readable rich text documents like this one, it is sometimes possible to use different fonts, and so instead of using \enquote{quotes} we specify terminals using an \texttt{upright typewriter font}.
    \item Free-text rules can be specified using a normal font. This is also only used in human-readable rich text documents, however this usage is justified because such rules are only beneficial for human understanding and not for machine parsing.
    \item By convention, the symbol \( \Coloneqq \) is used instead of \( \to \) for specifying transition rules.
    \item Different rules with the same, source are concatenated as in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/shorthand}.
    \item In order to fully describe a context-free grammar, we must only specify its Backus-Naur form and its starting variable.
  \end{itemize}
\end{example}

\begin{definition}\label{def:backus_naur_form}
  We have defined the \term{Backus-Naur form} of a \hyperref[def:chomsky_hierarchy/context_free]{context-free grammar} in \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}.

  Although formally necessary for \fullref{def:formal_grammar}, it is of slight inconvenience to explicitly specify the starting variable for a nontrivial grammar in Backus-Naur form because the same Backus-Naur form can be used with different starting variables.

  For this reason, we will say that the Backus-Naur form specifies \term{grammar schemas} and not grammars. Given a grammar schema, we can select any of its variables to obtain a grammar.
\end{definition}

\begin{definition}\label{def:abstract_reduction_system}\cite[def. 1.1.2]{Book1993}
  Fix an arbitrary \hyperref[def:set]{set} \( A \) and an \hyperref[rem:first_order_formula_conventions/infix]{infix} \hyperref[def:binary_relation]{binary relation} \( \to \) on \( A \). We call the operation \( \to \) a \term{reduction relation}, and the pair \( (A, \to) \) --- an \term{abstract reduction system}.

  \begin{thmenum}
    \thmitem{def:abstract_reduction_system/derivations}\mimprovised A \term{reduction path} or \term{derivation} of \( x_n \) from \( x_1 \) is a \hyperref[def:quiver_path/directed]{directed path} from \( x_1 \) to \( x_n \) in the quiver \( (A, \to) \), i.e. a chain
    \begin{equation}\label{eq:def:abstract_reduction_system/derivation}
      \begin{aligned}
        \includegraphics[page=1]{output/def__abstract_reduction_system.pdf}
      \end{aligned}
    \end{equation}

    This terminology is not established and is based on similar concepts from formal grammars.

    We allow empty paths with the caveat described in \fullref{def:quiver_path} that every element of \( A \) has a distinct empty path.

    It there exists at least one derivation of \( x_n \) from \( x_1 \), we say that \( x_n \) is \term{derivable from} \( x_1 \) and that \( x_1 \) is \term{reducible into} \( x_n \). We say that \( x_1 \) itself is \term{derivable} (resp. \term{reducible}) if it is derivable from (resp. reducible into) at least one element and \term{non-derivable} (resp. \term{irreducible}) otherwise.

    \thmitem{def:abstract_reduction_system/ambiguity}\mimprovised A derivable element is \term{uniquely derivable} if it has a unique derivation from a non-derivable element.

    If every derivable element is uniquely derivable, we say that the system is \term{unambiguous}.

    \begin{figure}[h]
      \begin{equation*}
        \begin{aligned}
          \includegraphics[page=2]{output/def__abstract_reduction_system.pdf}
        \end{aligned}
      \end{equation*}
      \caption{A finite \hyperref[def:abstract_reduction_system/ambiguity]{unambiguous} \hyperref[def:abstract_reduction_system]{abstract reduction system}}\label{fig:def:abstract_reduction_system}
    \end{figure}

    \thmitem{def:abstract_reduction_system/relations}\mcite[not. 1.1.1]{Book1993} We also introduce the following auxiliary relations:
    \begin{itemize}
      \item \( \reloset n \to \) is the \( n \)-th \hyperref[def:binary_relation/composition]{iterated composition} of \( \to \), where \( n \) is a nonnegative integer. Clearly \( x \reloset n \to y \) if there exists a derivation of length \( n \) from \( x \) to \( y \).

      \item \( \reloset + \to \) is the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \to \). Clearly \( x \reloset + \to y \) if \( y \neq x \) is derivable from \( x \).

      \item \( \reloset {*} \to \) is the \hyperref[def:relation_closures/reflexive]{reflexive closure} of \( \reloset + \to \). Clearly \( x \reloset + \to y \) if \( y \) is derivable from \( x \), including the case \( y = x \).

      \item \( {\leftrightarrow} \) is the \hyperref[def:relation_closures/symmetric]{symmetric closure} of \( \to \).

      \item \( \reloset + \leftrightarrow \) is the \hyperref[def:relation_closures/transitive]{transitive closure} of \( \leftrightarrow \).

      \item \( \reloset {*} \leftrightarrow \) is the \hyperref[def:relation_closures/reflexive]{reflexive closure} of \( \reloset + \leftrightarrow \), i.e. the smallest equivalence relation containing \( \to \).
    \end{itemize}

    \thmitem{def:abstract_reduction_system/equivalent} We say that \( x \) and \( y \) are \term{equivalent} if \( x \reloset {*} \leftrightarrow y \). This is a stronger condition than \( x \) and \( y \) being reducible into each other. Indeed, the latter corresponds to \hyperref[def:quiver_connectedness/weak]{weak connectedness} of quivers and equivalence corresponds to \hyperref[def:quiver_connectedness/strong]{strong connectedness}.

    \thmitem{def:abstract_reduction_system/normal_form}\mcite[def. 1.1.5]{Book1993} Given an \hyperref[def:equivalence_relation]{equivalence relation} \( \cong \), if \( x \cong y \) and \( y \) is irreducible, we say that \( x \) is a \term{normal form} of \( y \) modulo \( \cong \).

    Without further context, we assume that \( \cong \) is the equivalence relation \( \reloset {*} \leftrightarrow \).
  \end{thmenum}
\end{definition}

\begin{theorem}[Structural induction]\label{thm:structural_induction}\mimprovised
  Let \( (A, \to) \) be an \hyperref[def:abstract_reduction_system/ambiguity]{unambiguous abstract reduction system}.

  Unlike for the other induction principles in \fullref{rem:induction}, we will not formulate the \term{structural induction} principle via logical formulas. This will complicate us unnecessarily. We will instead describe how the principle is used in practice.

  Suppose we want to prove some statement for every member of \( A \). We can proceed as follows:
  \begin{thmenum}
    \thmitem{thm:structural_induction/base_step} The \term{base step} is to prove the statement for all non-derivable elements of \( A \).
    \thmitem{thm:structural_induction/inductive_step} The \term{inductive step} is to fix a derivable element \( x \), suppose that the statement holds for all immediate ancestors of \( x \), and then prove it for \( x \).
  \end{thmenum}
\end{theorem}
\begin{proof}
  We prove the object statement for all non-derivable elements of \( A \) via \fullref{thm:structural_induction/base_step} and for all derivable elements via \fullref{thm:structural_induction/inductive_step}. Therefore, statement holds for all elements of \( A \).

  We require unique derivability because without it, it is possible to prove the statement for \( x \) using one derivation and disprove it using another derivation.
\end{proof}

\begin{definition}\label{def:string_rewriting_system}\mcite[def. 2.1.1]{Book1993}
  Fix an \hyperref[def:formal_language/alphabet]{alphabet} \( \mscrA \). A \term{string rewriting system} over \( \mscrA \) is an \hyperref[def:abstract_reduction_system]{abstract reduction system} over the \hyperref[thm:kleene_star_is_monoid]{Kleene star} \( \mscrA^* \).

  A member of the reduction relation \( \to \) of a string rewriting system is called a \term{rewrite rule}.
\end{definition}

\begin{definition}\label{def:grammar_derivation}
  Fix a \hyperref[def:formal_grammar]{formal grammar} \( G = (V, S, \Sigma, \to) \).

  \begin{thmenum}
    \thmitem{def:grammar_derivation/full} For any two \hyperref[def:formal_language/word]{words} \( p \) and \( s \) over \( V \cup \Sigma \) and every production rule \( v \to w \), we write \( pvw \Rightarrow pws \). The relation \( \Rightarrow \) induced a \hyperref[def:string_rewriting_system]{string rewriting system} over \( V \cup \Sigma \), which we call the \term{full derivation system} of the grammar.

    \thmitem{def:grammar_derivation/grammar_language} The \term{language} of the grammar is the set
    \begin{equation*}
      \mscrL(G) \coloneqq \set{ w \in \Sigma^* \colon S \Rightarrow w }
    \end{equation*}
    of all ancestors of the starting symbol \( S \) under the full (i.e. not leftmost) rewriting system.

    We also say that strings in \( \mscrL(G) \) are \term{generated} by the grammar \( G \).

    If a language can be generated by a \hyperref[def:chomsky_hierarchy/regular]{regular} grammar, we say that the language itself is regular, and similarly for \hyperref[def:chomsky_hierarchy/context_free]{context-free} and \hyperref[def:chomsky_hierarchy/context_sensitive]{context-sensitive} grammars.

    For other grammars, for example \hyperref[def:chomsky_hierarchy/unrestricted]{unrestricted} or \hyperref[def:chomsky_hierarchy/non_contracting]{non-contracting}, such a terminology is not established.

    \thmitem{def:grammar_derivation/unambiguous} In grammars we have different possible notions of non-ambiguity.

    We define the relation \( \Rightarrow_L \) as the restriction of \( \Rightarrow \) to the cases where the prefix \( p \) contains only terminal symbols. This relation induces a string rewriting system, which we call the \term{leftmost derivation system} because it always substitutes the leftmost possible non-terminal. Rightmost derivations are defined analogously.

    We say that \( G \) is \term{unambiguous} if its leftmost derivation system is unambiguous when restricted to \( \mscrL(G) \). Restricting this requirement to \( \mscrL(G) \) makes sure that extraneous rules that cannot be reached from \( S \) do not introduce ambiguity. The choice of leftmost derivations for defining grammar ambiguity is established in practice.
  \end{thmenum}
\end{definition}

\begin{example}\label{ex:natural_number_arithmetic_grammar/derivation}
  We continue \fullref{ex:natural_number_arithmetic_grammar/backus_naur_form}. Depending on our choice of starting symbol, we can derive different sets of words.

  For the sake of simplifying our exposition and proof, however, we will assume the simpler grammar described in \eqref{eq:ex:natural_number_arithmetic_grammar/backus_naur_form/simple}.

  Choose the starting symbol to be \( E \). We will show that this grammar is unambiguous.

  \Cref{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous} demonstrates that removing the parentheses makes even this simple grammar ambiguous.

  \begin{figure}
    \hfill
    \includegraphics[page=1]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{The unique way to produce the parenthesized arithmetic expression \( ((6 \div 2) \times 3) \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/unambiguous}
  \end{figure}

  \begin{figure}
    \hfill
    \includegraphics[page=2]{output/ex__natural_number_arithmetic_grammar__derivation.pdf}
    \hfill\hfill
    \caption{Different leftmost derivations of the parenthesis-less arithmetic expression \( 6 \div 2 \times 3 \)}
    \label{fig:ex:natural_number_arithmetic_grammar/derivation/ambiguous}
  \end{figure}
\end{example}
\begin{proof}
  We will show that \( G \) is unambiguous. Let \( w \) be a word in \( \mscrL(G) \). We explicitly build the leftmost derivation of \( w \) using recursion on \( \len(w) \):
  \begin{itemize}
    \item If \( \len(w) = 1 \), then \( w = n \in \BbbN \), and the word has been generated by the rule \( E \to n \).

    \item Assume that \( w \) is unambiguously derived for \( \len(w) < m + 2 \) and let \( \len(w) = m + 2 \), then \( w \) is necessarily enclosed in parentheses. Let \( w = ( \sigma_1 \ldots \sigma_m ) \) be the symbols of \( w \). Because of the parentheses, the only possibility for \( \sigma_1 \ldots \sigma_m \) is that it consists of two words in \( \mscrL(G) \) with either a multiplication symbol \( \times \) or a division symbol \( \div \) between them. Let \( k \) be the index of the operator symbol, that is, the index such that \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) both belong to \( \mscrL(G) \).

    By the inductive hypothesis, both \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \) are unambiguously derived. Depending on the operator symbol \( \sigma_k \), there are two possible rules for how \( w \) has been generated from the subwords \( \sigma_1 \ldots \sigma_{k-1} \) and \( \sigma_{k+1} \ldots \sigma_m \). Therefore, the derivation of \( w \) is also unambiguous.
  \end{itemize}
\end{proof}
