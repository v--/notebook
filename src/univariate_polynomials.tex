\subsection{Univariate polynomials}\label{subsec:univariate_polynomials}

We will discuss here the \hyperref[def:polynomial_semiring]{polynomial ring} \( R[X] \) in one indeterminate over the nontrivial \hyperref[def:ring/commutative]{commutative unital ring} \( R \). We call them \term{univariate polynomials} using the general convention for function arguments from \fullref{def:multi_valued_function/arguments}. \Fullref{rem:polynomials_over_infinitely_many_indeterminates} discusses why we often focus only on finitely many indeterminates, and why the theory of univariate polynomials is often sufficient.

Polynomials are not functions in general, and the exact relationship between polynomials and polynomial functions is discussed in \fullref{thm:polynomial_semiring_universal_property} and \fullref{thm:functions_over_finite_fields}.

\begin{definition}\label{def:polynomial_degree}
  The \term{degree} of the nonzero univariate \hyperref[def:polynomial_semiring]{monomial} \( X^k \) is its power \( k \). More generally, the degree of a multivariate monomial \( \prod_{X \in \mscrX} X^{\gamma_X} \) in the set of indeterminates \( \mscrX \) is the \hyperref[def:multi_index]{multi-index norm} \( \norm \gamma = \sum_{X \in \mscrX} \gamma_X \).

  The degree \( \deg(p) \) of a polynomial \( p \) is the maximal degree of its nonzero monomials. For the zero polynomial, we leave the degree undefined.

  For a univariate polynomial
  \begin{equation*}
    p(X) = \sum_{k=0}^\infty a_k X^k = a_0 + a_1 X + a_2 X^2 + a_3 X^3 + \cdots,
  \end{equation*}
  the degree \( n \coloneqq \deg(p) \) allows us to write
  \begin{equation*}
    p(X) = \sum_{k=0}^n a_k X^k = a_0 + a_1 X + a_2 X^2 + \cdots + a_{n-1} X^{n-1} + a_n X^n.
  \end{equation*}

  This notation also subsumes the zero polynomial. We call \( a_n \) the \term{leading coefficient} and \( a_0 \) the \term{constant coefficient} of the polynomial.

  We introduce the following names for univariate polynomials of certain degrees:
  \begin{center}
    \begin{tabular}{l | l}
      Constant  & \( \deg(p) = 0 \) or \( p \) is the zero polynomial \\
      Linear    & \( \deg(p) = 1 \)                                   \\
      Quadratic & \( \deg(p) = 2 \)                                   \\
      Cubic     & \( \deg(p) = 3 \)                                   \\
      Quartic   & \( \deg(p) = 4 \)                                   \\
      Quintic   & \( \deg(p) = 5 \)
    \end{tabular}
  \end{center}
\end{definition}

\begin{definition}\label{def:monic_polynomial}
  We say that the nonzero univariate polynomial \( p(X) \) is \term{monic} if its leading coefficient is \( 1 \).
\end{definition}

\begin{proposition}\label{thm:def:polynomial_degree}
  The \hyperref[def:polynomial_degree]{polynomial degree} has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:polynomial_degree/sum} For any two zero polynomials satisfying \( p(X) \neq -q(X) \), we have
    \begin{equation}\label{eq:thm:def:polynomial_degree/sum}
      \deg (p + q) \leq \max \set{ \deg p, \deg q }.
    \end{equation}

    \thmitem{thm:def:polynomial_degree/product} For any two nonzero polynomials \( p(X) \) and \( q(X) \) whose leading coefficients do not multiply to zero, we have
    \begin{equation}\label{eq:thm:def:polynomial_degree/product}
      \deg (pq) = \deg p + \deg q.
    \end{equation}

    An easy sufficient condition for \eqref{eq:thm:def:polynomial_degree/product} is for the ring to be \hyperref[def:entire_semiring]{entire}, although it is also sufficient for the ring to be nontrivial (so that \( 0_R \neq 1_R \)) and either \( p(X) \) or \( q(X) \) to be \hyperref[def:monic_polynomial]{monic}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  Fix nonzero polynomials
  \begin{align*}
    p(X) &\coloneqq \sum_{k=0}^n a_k X^k, \\
    q(X) &\coloneqq \sum_{k=0}^m b_k X^k.
  \end{align*}

  \SubProofOf{thm:def:polynomial_degree/sum} Additionally assume that \( p(X) \neq -q(X) \) since otherwise \( p(X) + q(X) = 0 \) and \( \deg(p + q) \) is undefined. Thus, there exists at least one index \( k = 1, 2, \ldots \), so that \( a_k \neq b_k \). Denote by \( k_0 \) the largest such index (only finitely many are nonzero). Then
  \begin{equation*}
    a_k = b_k = 0 \T{for} k > k_0.
  \end{equation*}

  Therefore, \( \deg(p + q) = k_0 \). Note that \( k_0 \) cannot exceed both \( \deg p \) and \( \deg q \) because it corresponds to a nonzero coefficient. Thus, \( k_0 \leq \max\set{ \deg p, \deg q } \).

  \SubProofOf{thm:def:polynomial_degree/product} The coefficient \( c_{n + m} \) of the product \( p(X) q(X) \) is \( a_n b_m \) by definition. By assumption, it is nonzero. Then, since \( c_{n+m+1} = 0 \), we have
  \begin{equation*}
    \deg (pq) = \deg p + \deg q.
  \end{equation*}
\end{proof}

\begin{algorithm}[Euclidean division of polynomials]\label{alg:euclidean_division_of_polynomials}\mcite[prop. 1.12]{Knapp2016BasicAlgebra}
  Fix two univariate polynomials \( f(X) \) and \( g(X) \), and assume that \( g(X) \) is \hyperref[def:monic_polynomial]{monic}.

  We will build polynomials \( q(X) \) and \( r(X) \), where \( r(X) \) is either zero or \( \deg r < \deg g \), such that
  \begin{equation*}
    f(X) = g(X) q(X) + r(X).
  \end{equation*}

  The algorithm only demonstrates existence; we will prove uniqueness right after it.

  \begin{thmenum}
    \thmitem{alg:euclidean_division_of_polynomials/zero_degree} If \( \deg f = \deg g = 0 \), necessarily \( g(X) = 1_R \), and in this case we define
    \begin{align*}
      q(X) &\coloneqq f(X), \\
      r(X) &\coloneqq 0_R.
    \end{align*}

    \thmitem{alg:euclidean_division_of_polynomials/no_division} If \( f(X) \) is the zero polynomial or \( \deg f < \deg g \), define
    \begin{align*}
      q(X) &\coloneqq 0_R, \\
      r(X) &\coloneqq f(X).
    \end{align*}

    In this case, \( r(X) \) is either zero or \( \deg r = \deg f < \deg b \).

    \thmitem{alg:euclidean_division_of_polynomials/positive_degree} Suppose that
    \begin{align*}
      f(X) = a_n X^n + \hat f(X), \\
      g(X) = X^m + \hat g(X),
    \end{align*}
    where \( n \) and \( m \) are positive, \( \hat f(X) \) is either zero or \( \deg \hat f < \deg f \), and similarly for \( \deg \hat g \).

    Then
    \begin{align*}
    f(X) - g(X) a_n X^{n-m}
    &=
    a_n X^n + \hat f(X) - (b_m X^m + \hat g(X)) a_n X^{n-m}
    = \\ &=
    a_n X^n + \hat f(X) - a_n X^n - \hat g(X) a_n X^{n-m}
    = \\ &=
    \underbrace{\hat f(X) - \hat g(X) a_n X^{n-m}}_{\hat r(X)}.
    \end{align*}

    The polynomial \( \hat r(X) \) is either zero, in which case we define \( r(X) \coloneqq \hat r(X) \), or \( \deg \hat r \leq n - 1 \).

    In the latter case, we use the algorithm recursively to divide \( \hat r(X) \) by \( g(X) \), and obtain \( \hat q(X) \) and \( r(X) \) such that
    \begin{equation*}
      \hat r(X) \coloneqq g(X) \hat q(X) + r(X),
    \end{equation*}
    where \( r(X) \) is either zero or \( \deg r < \deg g \).

    Then
    \begin{align*}
      \hat r(X)                                         &= f(X) - g(X) a_n X^{n-m} \\
      g(X) \hat q(X) + r(X)                             &= f(X) - g(X) a_n X^{n-m} \\
      g(X) \left(\hat q(X) - a_n X^{n-m} \right) + r(X) &= f(X).
    \end{align*}

    Define
    \begin{equation*}
      q(X) \coloneqq \hat q(X) - a_n X^{n-m}.
    \end{equation*}

    We have obtained polynomials \( r(X) \) and \( q(X) \) where \( r(X) \) is either zero or \( \deg r < \deg g \).
  \end{thmenum}
\end{algorithm}
\begin{defproof}
  \SubProof{Proof of uniqueness} Suppose that
  \begin{equation*}
    a(X) = g(X)q(X) + r(X) = g(X) \widetilde{q}(X) + \widetilde{r}(X),
  \end{equation*}
  where \( r(X) \) and \( \widetilde{r}(X) \) are either zero or have degree less than \( g(X) \).

  Assume that \( r(X) \neq \widetilde{r}(X) \).

  \begin{itemize}
    \item If both \( r(X) \) and \( \widetilde{r}(X) \) are nonzero, we have
    \begin{equation*}
      g(X) \parens[\Big]{ q(X) - \widetilde{q}(X) } = -\parens[\Big]{ r(X) - \widetilde{r}(X) }.
    \end{equation*}

    Since \( g(X) \) is monic and its leading coefficient \( 1_R \) is not a zero divisor, \fullref{thm:def:polynomial_degree/product} holds, and thus
    \begin{equation*}
      \deg g + \deg(q - \widetilde{q})
      \reloset {\eqref{eq:thm:def:polynomial_degree/product}} =
      \deg(g (q - \widetilde{q}))
      =
      \deg(r - \widetilde{r})
      \reloset {\eqref{eq:thm:def:polynomial_degree/sum}} =
      \leq \max\set{ \deg r, \deg \widetilde{r} }
      <
      \deg g,
    \end{equation*}
    which is a contradiction.

    \item If \( r(X) \) is zero but \( \widetilde{r}(X) \) is not, then
    \begin{equation*}
      g(X) q(X) = g(X) \widetilde{q}(X) + \widetilde{r}(X),
    \end{equation*}
    implying that
    \begin{equation*}
      \widetilde{r}(X) = g(X) \parens[\Big]{ q(X) - \widetilde{q}(X) }.
    \end{equation*}

    By \eqref{thm:def:polynomial_degree/product}, \( \deg g \leq \widetilde{r} \), which contradicts our choice of \( \widetilde{r}(X) \).
  \end{itemize}
\end{defproof}

\begin{definition}\label{def:algebraic_derivative}
  Generalizing \fullref{def:differentiability} from analysis, we define the \term{algebraic derivative} of a univariate polynomial
  \begin{equation*}
    p(X) = \sum_{k=0}^n a_k X^k = a_n X^n + a_{n-1} X^{n-1} + \cdots + a_2 X^2 + a_1 X + a_0
  \end{equation*}
  as
  \begin{equation*}
    p'(X) \coloneqq \sum_{k=1}^n k a_k X^{k-1} = n a_n X^{n-1} + (n-1) a_{n-1} X^{n-2} + \cdots + a_2 X + a_1.
  \end{equation*}

  Via \hyperref[rem:natural_number_recursion]{natural number recursion}, we can define algebraic derivatives of order \( m \) as
  \begin{equation*}
    p^{(m)}(X) \coloneqq \begin{cases}
      p(X)              &m = 0 \\
      \parens[\Big]{ p^{(m - 1)} }'(X) &m > 0
    \end{cases}
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:def:algebraic_derivative}
  \hyperref[def:algebraic_derivative]{Algebraic derivatives} have the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:algebraic_derivative/linear} The derivative operator \( p(X) \mapsto p'(X) \) is linear.
    \thmitem{thm:def:algebraic_derivative/degree} \( p^{(n)}(X) \) is either zero or has degree \( \deg p - n \).

    \thmitem{thm:def:algebraic_derivative/product} We have the product rule
    \begin{equation}\label{eq:thm:def:algebraic_derivative/product}
      (pq)' = p'q + pq'.
    \end{equation}

    \thmitem{thm:def:algebraic_derivative/leibniz} Leibniz' rule holds:
    \begin{equation}\label{thm:def:algebraic_derivative/product}
      (pq)^{(n)} = \sum_{k=0}^n \binom n k p^{(k)} q^{(n-k)}
    \end{equation}

    \thmitem{thm:def:algebraic_derivative/affine_power} If \( m \leq n \), the \( m \)-th derivative of \( (X - u)^n \) is \( \tfrac {n!} {(n-m)!} (X - u)^{n-m} \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:algebraic_derivative/linear} Trivial.

  \SubProofOf{thm:def:algebraic_derivative/degree} Trivial.

  \SubProofOf{thm:def:algebraic_derivative/product} By \fullref{thm:def:algebraic_derivative/linear}, it is enough to consider the case where both \( p(X) \) and \( q(X) \) are monomials.

  \begin{align*}
    p'(X) q(X) + p(X) q'(X)
    &=
    n a_n X^{n-1} \cdot b_m X^m + a_n X^n \cdot m b_m X^{m-1}
    = \\ &=
    (n + m) a_n b_m X^{n+m-1}
    = \\ &=
    (a_n b_m X^{n+m})'
    = \\ &=
    (pq)'(X).
  \end{align*}

  \SubProofOf{thm:def:algebraic_derivative/leibniz} The proof in \fullref{thm:leibniz_rule} relies only on the product rule, hence it holds here as well.

  \SubProofOf{thm:def:algebraic_derivative/affine_power} We use outer induction on \( m \) and inner induction on \( n \).

  The case \( m = n = 1 \) is obvious. Assume that the statement holds for \( m = 1 \) and \( n - 1 \). Then
  \begin{equation*}
    \parens[\Big]{ (X - u)^n }'
    =
    \parens[\Big]{ (X - u)^{n-1} \cdot (X - u) }'
    \reloset {\eqref{eq:thm:def:algebraic_derivative/product}} =
    \parens[\Big]{ (X - u)^{n-1} }' (X - u) + (X - u)^{n-1}
    \reloset {\T{ind.}} =
    n (X - u)^{n-1}.
  \end{equation*}

  Now suppose that the statement holds for derivatives of order less than \( m \) and for every \( n \geq m \). Then,
  \begin{equation*}
    \parens[\Big]{ (X - u)^n }^{(m)}
    =
    \parens*{\parens[\Big]{ (X - u)^n }^{(m-1)}}'
    \reloset {\T{ind.}} =
    \parens*{ \frac {n!} {(n - m + 1)!} (X - u)^{n - m + 1} }'
    \reloset {\T{ind.}} =
    \frac {n!} {(n - m)!} (X - u)^{n - m}.
  \end{equation*}
\end{proof}

\begin{definition}\label{def:polynomial_root}
  Let \( R \) be a nontrivial commutative ring.

  We say that the value \( u \in R \) is a \term{root} of multiplicity \( m \) for the univariate polynomial \( p(X) \in R[X] \) of degree \( n \geq m \) if any of the following equivalent conditions hold:
  \begin{thmenum}
    \thmitem{def:polynomial_root/division} The polynomial \( (X - u)^m \) divides \( p(X) \).

    \thmitem{def:polynomial_root/derivative_roots} The value \( u \) is a \hyperref[def:zero_locus]{zero} of the \hyperref[def:algebraic_derivative]{algebraic derivatives} \( p^{(0)}(X), p^{(1)}(X), \ldots, p^{(m-1)}(X) \) of \( p(X) \).
  \end{thmenum}

  Every polynomial \( p(X) \) has a \hyperref[def:weighted_set/multiset]{multiset} of roots.
\end{definition}
\begin{defproof}
  \ImplicationSubProof{def:polynomial_root/division}{def:polynomial_root/derivative_roots} Suppose that \( (X - u)^m \) divides \( p(X) \). Then there exists a polynomial \( q(X) \) such that
  \begin{equation*}
    p(X) = (X - u)^m q(X).
  \end{equation*}

  For the \( n < m \)-th derivative of \( p(X) \), by \fullref{thm:def:algebraic_derivative/leibniz}, we have
  \begin{equation*}
    p^{(n)}(X) = \sum_{k=0}^n \binom n k \underbrace{\parens[\Big]{ (X - u)^m }^{(k)}}_{\mathclap{\frac {m!} {k!} (X - u)^{m-k} \T*{by} \ref{thm:def:algebraic_derivative/affine_power}}} q^{(n-k)}(X).
  \end{equation*}

  Let \( \Phi_u: R[X] \to R \) be the \hyperref[thm:polynomial_semiring_universal_property]{evaluation homomorphism} at \( u \). Then
  \begin{equation*}
    \Phi_u(p^{(n)}) = \sum_{k=0}^n \binom n k \frac {m!} {k!} 0_R^{m-k} \Phi_u(q^{(n-k)})
  \end{equation*}

  For \( n < m \), clearly \( \Phi_u(p^{(n)}) = 0_R \).

  \ImplicationSubProof{def:polynomial_root/derivative_roots}{def:polynomial_root/division} Suppose that \( u \) is a root of \( p^{(0)}(X), \ldots, p^{(m-1)}(X) \). We will use induction on \( m \) to show that \( (X - u)^m \mid p(X) \).

  The case \( m = 0 \) is trivial. Suppose that \( u \) being a root of \( p^{(0)}(X), \ldots, p^{(m-1)}(X) \) implies that \( (X - u)^{m-1} \mid p(X) \), and additionally let \( u \) be a root of \( p^{(m)}(X) \).

  By the inductive hypothesis, there exists a polynomial \( q(X) \) such that
  \begin{equation*}
    p(X) = (X - u)^{m-1} q(X).
  \end{equation*}

  By \fullref{thm:def:algebraic_derivative/leibniz},
  \begin{equation*}
    p^{(m-1)}(X) = \sum_{k=0}^{m-1} \binom {m-1} k \underbrace{\parens[\Big]{ (X - u)^{m - 1} }^{(k)}}_{\mathclap{\frac {(m - 1)!} {k!} (X - u)^{m - k - 1} \T*{by} \ref{thm:def:algebraic_derivative/affine_power}}} q^{(m - k - 1)}(X).
  \end{equation*}

  Then
  \begin{equation*}
    \Phi_u(p^{(m-1)}) = \sum_{k=0}^{m-1} \binom {m-1} k \frac {(m - 1)!} {k!} 0_R^{m - k - 1} \Phi_u(q^{(m - k - 1)}).
  \end{equation*}

  All terms on the right are zero except for \( \Phi_u(q) \). But \( u \) is a root of \( p^{(m-1)} \), implying that it is also a root of \( q \).

  We use \fullref{alg:euclidean_division_of_polynomials} to obtain a polynomial \( s(X) \) and a constant polynomial \( r(X) = r_0 \) so that
  \begin{equation*}
    q(X) = (X - u) s(X) + r_0.
  \end{equation*}

  Since \( \Phi_u(q) = 0_R \), then necessarily \( r_0 = 0_R \). Therefore,
  \begin{equation*}
    p(X) = (X - u)^{m-1} q(X) = (X - u)^m s(X).
  \end{equation*}
\end{defproof}

\begin{proposition}\label{thm:representatives_in_univariate_polynomial_quotient_set}
  Given \hyperref[def:monic_polynomial]{monic polynomial} \( g(X) \) in a nontrivial commutative ring \( R \), every coset in \( R[X] / \braket{ g(X) } \) has a unique representative that is either the zero polynomial or a polynomial of degree less than \( g(X) \).
\end{proposition}
\begin{proof}
  Let \( f(X) \) be an arbitrary polynomial. \Fullref{alg:euclidean_division_of_polynomials} gives us polynomials \( q(X) \) and \( r(X) \) so that
  \begin{equation*}
    f(X) = g(X) q(X) + r(X),
  \end{equation*}
  where \( r(X) \) is either zero or has degree less than \( g(X) \).

  Multiples of \( q(X) \) are congruent to \( 0_R \) modulo the ideal \( \braket{ q(X) } \), hence \( f(X) \) is congruent to \( r(X) \).

  By the uniqueness of \( r(X) \), the statement of the corollary follows.
\end{proof}

\begin{remark}\label{rem:adjoining_roots}
  Fix arbitrary commutative rings \( R \subseteq S \) and some element \( u \) of \( S \). By \fullref{thm:polynomial_semiring_universal_property}, there exists a unique \hyperref[def:algebra_over_ring/homomorphism]{\( R \)-algebra homomorphism} \( \Phi_u: R[X] \to S \) sending \( X \) to \( u \). If the kernel of \( \Phi_u \) is a principal ideal, and if \( p(X) \) is a generator, then we have the algebra isomorphism
  \begin{equation*}
    R[X] / \braket{ p(X) } \cong R[u].
  \end{equation*}

  By \fullref{thm:representatives_in_univariate_polynomial_quotient_set}, there exists a correspondence between polynomials
  \begin{equation*}
    f(X) = \sum_{k=0}^n a_k X^k
  \end{equation*}
  of degree less than \( \deg p \), and elements of the form
  \begin{equation*}
    \sum_{k=0}^n a_k u^k
  \end{equation*}

  Furthermore, multiplication in \( R[u] \) corresponds to polynomial multiplication modulo \( p(X) \).
\end{remark}

\begin{example}\label{ex:gaussian_integers}
  The \term{Gaussian integers} are complex numbers \( z = a + bi \) with integer real and imaginary components. We can define several isomorphic rings for the Gaussian integers, demonstrating \fullref{rem:adjoining_roots}.

  \begin{thmenum}
    \thmitem{ex:gaussian_integers/quotient} We can take the \hyperref[def:ring/quotient]{quotient ring} \( \BbbZ[X] / \braket{X^2 + 1} \). By \fullref{thm:representatives_in_univariate_polynomial_quotient_set}, the remainder from \fullref{alg:euclidean_division_of_polynomials} can be used as a canonical representative within the quotient. The remainder must be either a constant or a linear polynomial. That is, \( r(X) = aX + Y \).

    In order to make sense of the imposed ring structure in the quotient, we can see how multiplication modulo \( X^2 + 1 \) works. We have
    \begin{align*}
      (bX + a) (dX + c)
      &\cong
      bdX^2 + (ad + bc)X + ac
      &\pmod {X^2 + 1} \cong \\ &\cong
      bd\parens[\Big]{ X^2 + 1 } + \parens[\Big]{ (ad + bc)X - bd + ac }
      &\pmod {X^2 + 1} \cong \\ &\cong
      (ad + bc)X + (ac - bd)
      &\pmod {X^2 + 1}. \phantom{\cong}
    \end{align*}

    This is precisely the definition of multiplication of complex numbers as given in \fullref{def:set_of_complex_numbers}. Thus,
    \begin{equation*}
      \BbbZ[X] / \braket{X^2 + 1}
    \end{equation*}
    is the desired ring of Gaussian integers.

    \thmitem{ex:gaussian_integers/evaluation} We can also \hyperref[thm:adjoining_elements_to_semiring]{adjoin} \( i \) to \( \BbbZ \) to obtain the ring \( \BbbZ[i] \).

    Given a Gaussian integer \( z = a + bi \), it corresponds to the polynomial
    \begin{equation*}
      p_z(X) \coloneqq a + bX.
    \end{equation*}

    Conversely, consider the \hyperref[thm:polynomial_semiring_universal_property]{evaluation homomorphism} \( \Phi_i: \BbbZ[X] \to \BbbC \) for the imaginary unit. Let \( p(X) \in \BbbZ[X] \). Then
    \begin{equation*}
      p(i)
      =
      \Phi_i(p)
      =
      \sum_{k=0}^n a_k i^n
      =
      \thickspace \sum_{\scriptscriptstyle{\rem(k, 4) = 0}}^n a_k - \sum_{\scriptscriptstyle{\rem(k, 4) = 2}}^n a_k + i \parens[\Bigg]{ \sum_{\scriptscriptstyle{\rem(k, 4) = 1}}^n a_k - \sum_{\scriptscriptstyle{\rem(k, 4) = 3}}^n a_k }.
    \end{equation*}

    This is clearly a Gaussian integer.

    It remains to show that multiplication in \( \BbbZ[i] \) is compatible with multiplication in \( \BbbC \). But complex \hyperref[def:set_of_complex_numbers]{multiplication} is defined to be compatible with the notation \( a + bi \), that is,
    \begin{equation*}
    (a + bi) (c + di)
    =
    ac + ibc + iad - bd
    =
    (ac - bd) + i(bc + ad).
    \end{equation*}

    Thus, the Gaussian integers are precisely the homomorphic image of \( \BbbZ[X] \) under \( \Phi_i \).
  \end{thmenum}
\end{example}

\begin{corollary}\label{thm:polynomial_quotient_modules_vs_algebras}
  For two nonzero monic polynomials \( p(X) \) and \( q(X) \) of the same degree, the \hyperref[def:ring/quotient]{quotient rings} \( R[X] / \braket{ p(X) } \) and \( R[X] / \braket{ q(X) } \) are isomorphic as \( R \)-modules, but may not be isomorphic as \( R \)-algebras.
\end{corollary}
\begin{proof}
  By \fullref{thm:representatives_in_univariate_polynomial_quotient_set}, for every coset in the quotient, \fullref{alg:euclidean_division_of_polynomials} gives us a unique representative of the corresponding degree. Addition and scalar multiplication must be the same in both.

  As shown in \fullref{ex:gaussian_integers} and \fullref{ex:integers_with_sqrt2}, however, the vector multiplication operation may differ.
\end{proof}

\begin{example}\label{ex:integers_with_sqrt2}
  Similarly to how the Gaussian integers were defined in multiple ways in \fullref{ex:gaussian_integers}, \fullref{rem:adjoining_roots} gives us an isomorphism
  \begin{equation*}
    \BbbZ[X] / \braket{X^2 - 2} \cong \BbbZ[\sqrt 2].
  \end{equation*}

  The gist of this example is that, even though \( \BbbZ[\sqrt 2] \) and \( \BbbZ[i] \) are isomorphic as modules, their vector multiplication operation is different. Indeed, multiplication modulo \( X^2 - 2 \) works as follows:
  \begin{align*}
    (aX + b) (cX + bd)
    &\cong
    acX^2 + (bc + ad)X + bd
    &\pmod {X^2 - 2} \cong \\ &\cong
    ac(X^2 - 2) + \parens[\Big]{ (bc + ad)X + 2ac + bd }
    &\pmod {X^2 - 2} \cong \\ &\cong
    (bc + ad)X + (2ac + bd)
    &\pmod {X^2 - 2}. \phantom{\cong}
  \end{align*}
\end{example}

\begin{definition}\label{def:algebraic_dependence}\mimprovised
  Let \( M \) be an \( R \)-\hyperref[def:algebra_over_ring]{algebra} over a \hyperref[def:ring/commutative]{commutative ring} \( R \) and fix a subset \( B \subseteq M \). We say that the elements of \( B \) are \term{algebraically independent} if any of the following conditions hold:

  \begin{thmenum}
    \thmitem{def:algebraic_dependence/direct} If \( \seq{ u_b }_{b \in B} \) is a root of some polynomial with indeterminates \( \set{ X_b \given b \in B } \) and coefficients in \( R \), then it is the zero polynomial.

    \thmitem{def:algebraic_dependence/evaluation} The \hyperref[thm:polynomial_semiring_universal_property]{evaluation map} \( \Phi_B: R[X_b \given b \in B] \to M \) is injective.
  \end{thmenum}

  Unsurprisingly, if the elements of \( B \) are not \term{algebraically independent}, we say that they are \term{algebraically dependent}.

  Compare this concept to \hyperref[def:linear_dependence]{linear dependence}.
\end{definition}
\begin{defproof}
  \ImplicationSubProof{def:algebraic_dependence/direct}{def:algebraic_dependence/evaluation} Suppose that \( \Phi_B \) is injective and that there exists a polynomial \( p(X_b \given b \in B) \) such that \( \Phi_B(p) = 0_M \). Then for any other polynomial \( q(X_x \given b \in B) \), we have \( \Phi_B(p q) = 0_M \), and hence either \( p \) is the zero polynomial or the evaluation map is not injective.

  \ImplicationSubProof{def:algebraic_dependence/evaluation}{def:algebraic_dependence/direct} Conversely, suppose that \( B \) is a root only of the zero polynomial. Let \( \Phi_B(p) = \Phi_B(q) \). Then \( B \) is a root of \( p - q \) and hence the latter is the zero polynomial. But this implies that \( p = q \). Hence, the evaluation map is injective.
\end{defproof}

\begin{proposition}\label{thm:def:algebraic_dependence}
  \hyperref[def:algebraic_dependence]{Algebraic dependence} for the \hyperref[def:integral_domain]{integral domain} \( D \) has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:algebraic_dependence/n_independent} Monomials for different indeterminates are algebraically independent over \( D \).

    \thmitem{thm:def:algebraic_dependence/two_univariate_dependent} Every two univariate polynomials in \( D \) are algebraically dependent over \( D \).

    \thmitem{thm:def:algebraic_dependence/n_plus_one_dependent} Every \( n + 1 \) polynomials in \( D[X_1, \ldots, X_n] \) are algebraically dependent over \( D \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:algebraic_dependence/n_independent} Suppose that the monomials \( X_1, \ldots, X_n \) are algebraically dependent over \( D \). Then there exists some nonzero polynomial \( f(Y_1, \ldots, Y_n) \) such that the evaluation \( \Phi_{X_1, \dots, X_n}(f) \) is the zero polynomial. But the evaluation simply renames the variables, hence \( f \) itself is zero. But we have assumed that it is nonzero.

  The obtained contradiction demonstrates that \( X_1, \ldots, X_n \) are algebraically independent over \( D \).

  \SubProofOf{thm:def:algebraic_dependence/two_univariate_dependent} Fix polynomials \( p(X) \) and \( q(X) \) over \( D \). We will construct a polynomial \( f(Y, Z) \) over \( D \) such that \( \Phi_{p,q}(f) = 0 \).

  If \( p(X) \) is zero, simply define \( f(Y, Z) \coloneqq Z \). If \( q(X) \) is zero, put \( f(Y, Z) \coloneqq Y \).

  Suppose that both are nonzero; denote by \( n \) be the degree of \( p(X) \) and by \( m \) the degree of \( q(X) \). We will consider polynomials of the form \( p^l q^k \).

  Fix a positive integer \( d \). We want the degree of \( p^l q^k \) to be at most \( d \). If
  \begin{align*}
    l < \frac d {2n} && k < \frac d {2m},
  \end{align*}
  then, by \fullref{thm:def:polynomial_degree/product},
  \begin{equation*}
    \deg(p^l q^k) = nl + km < \frac d 2 + \frac d 2 = d.
  \end{equation*}

  These polynomials are all in
  \begin{equation*}
    L_d \coloneqq \linspan\set{ 1, X, X^2, X^3, \ldots, X^{d-1} }.
  \end{equation*}

  This is a module of \hyperref[thm:commutative_module_rank]{rank} \( d \).

  Furthermore, there are \( \ifrac {d^2} {(4nm)} \) such polynomials. If \( d > 4nm \), there are more polynomials of the form \( p^l q^k \) than the \hyperref[thm:commutative_module_rank]{rank} of \( L_d \). Hence, every \( d + 1 \) such polynomials are linearly dependent, and hence there exists some linear combination
  \begin{equation*}
    a_1 p^{l_1} q^{k_1} + \cdots + a_{d+1} p^{l_{d+1}} q^{k_{d+1}} = 0.
  \end{equation*}

  We can thus define the following polynomial in \( D[Y, Z] \):
  \begin{equation*}
    f(Y, Z) \coloneqq a_1 Y^{l_1} Z^{k_1} + \cdots + a_{d+1} Y^{l_{d+1}} Z^{k_{d+1}}.
  \end{equation*}

  Then clearly \( \Phi_{p,q}(f) = 0 \), so \( p \) and \( q \) are algebraically dependent over \( D \).

  \SubProofOf{thm:def:algebraic_dependence/n_plus_one_dependent} Let \( p_1, \ldots, p_{n+1} \) be polynomials in \( D[X_1, \ldots, X_{n-1}][X_n] \). By \fullref{thm:def:algebraic_dependence/two_univariate_dependent}, the polynomials \( p_n \) and \( p_{n+1} \) are algebraically dependent over \( D[X_1, \ldots, X_{n-1}] \).

  Let \( f(Y_n, Y_{n+1}) \) be a polynomial in \( D[X_1, \ldots, X_{n-1}][Y_n, Y_{n+1}] \) such that \( \Phi_{p_n,p_{n+1}}(f) = 0 \). The coefficients of \( f \) are themselves polynomials. Let
  \begin{equation*}
    \widehat{f}(Y_1, \ldots, Y_{n-1}, Y_n, Y_{n+1})
  \end{equation*}
  be the polynomial obtained from
  \begin{align*}
    f(X_1, \ldots, X_{n-1}, Y_n, Y_{n+1})
  \end{align*}
  by renaming the corresponding variables.

  Then \( \Phi_{p_1,\ldots,p_{n+1}}(f) = 0 \). Therefore, \( p_1, \ldots, p_{n+1} \) are algebraically dependent over \( D \).
\end{proof}

\begin{definition}\label{def:noetherian_semiring}\mcite[prop. 6.16]{Golan2010}
  We say that a (not necessarily commutative) \hyperref[def:semiring]{(semi)ring} is \term{left noetherian} (resp. right noetherian) if it is a left (resp. right) \hyperref[def:noetherian_semimodule]{noetherian (semi)module} over itself.

  Explicitly, any of the following equivalent conditions characterize a left noetherian semiring:
  \begin{thmenum}
    \thmitem{def:noetherian_semiring/acc} Every ascending chain of left ideals stabilizes.
    \thmitem{def:noetherian_semiring/maximal} Every nonempty set of left ideals has a maximal element.
    \thmitem{def:noetherian_semiring/generated} Every left ideal is \hyperref[def:semiring_ideal/generated]{finitely generated}.
  \end{thmenum}
\end{definition}

\begin{theorem}[Hilbert's basis theorem]\label{thm:hilberts_basis_theorem}\mcite[thm. 7.4]{КоцевСидеров2016}
  If \( R \) is a \hyperref[def:noetherian_semiring]{noetherian commutative ring}, then so is \( R[X] \).
\end{theorem}
\begin{proof}
  Let \( I \subseteq R[X] \) be an arbitrary ideal. We will prove that \( I \) is finitely generated.

  Denote by \( L \) the set of all leading coefficients of polynomials in \( I \). The leading coefficient of the product \( p(X) q(X) \) of univariate polynomials is the product of their leading coefficients, hence \( L \) is an ideal as a consequence of \( I \) being an ideal.

  As a consequence of \( R \) being noetherian, \( L \) is finitely generated. Suppose that \( L = \set{ l_1, \ldots, l_n } \).

  For every generator \( l_k \), there exists a polynomial \( p_k(X) \) in \( I \) whose leading coefficient is \( l_k \). Denote by \( d_k \) the degree of \( p_k \) and let \( d \) be the maximum of the degrees. We will show that \( I \) itself is equal to the sum of the finitely generated ideals
  \begin{equation*}
    J \coloneqq \underbrace{ \braket{ p_1, \ldots, p_n } + \braket{ X, X^2, \ldots, X^d } }_{ \braket{ p_1, \ldots, p_n, X, X^2, \ldots, X^d } }.
  \end{equation*}

  Let \( f(X) \) be some polynomial from \( I \) whose leading term is \( l X^m \).

  We proceed by induction on \( m \) to show that \( f(X) \) belongs to \( J \).
  \begin{itemize}
    \item If \( m \leq d \), then \( f(X) \) belongs to the second ideal \( \braket{ X, X^2, \ldots, X^d } \).

    \item Suppose that \( m > d \) and that every polynomial in \( I \) of degree less than \( m \) belongs to \( J \).

    Since \( l \in L \), it is a linear combination \( l = \sum_{k=1}^n t_k l_k \) with coefficients in \( R \). Consider the polynomial
    \begin{equation*}
      p(X) \coloneqq \sum_{k=1}^n t_k p_k(X) X^{m - d_k}.
    \end{equation*}

    Define \( r(X) \coloneqq f(X) - p(X) \). Since \( p(X) \) belongs to \( I \), \( r(X) \) does too. It is a polynomial in \( I \) of degree less than \( m \), hence it belongs to \( J \). Then
    \begin{equation*}
      f(X) = \underbrace{ p(X) }_{\mathclap{\braket{ p_1(X) \cdots, p_n(X) }}} + \overbrace{ r(X) }^J.
    \end{equation*}

    Hence, \( f(X) \in J \).
  \end{itemize}

  Our choice of polynomial \( f(X) \in I \) was arbitrary. Therefore,
  \begin{equation*}
    I \subseteq \braket{ p_1, \ldots, p_n } + \braket{ X, X^2, \ldots, X^d } \subseteq I,
  \end{equation*}
  demonstrating that \( I \) is finitely generated.
\end{proof}
