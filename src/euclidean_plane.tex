\subsection{Euclidean plane}\label{subsec:euclidean_plane}

\begin{definition}\label{def:euclidean_plane}
  We call the two-dimensional \hyperref[def:euclidean_space]{Euclidean space} \( \BbbR^2 \) the \term{Euclidean plane}.
\end{definition}

\begin{remark}\label{rem:euclidean_plane_embedding}
  Every \hyperref[def:affine_plane]{affine plane} in \( \BbbR^n \) is isomorphic to \( \BbbR^2 \), and we can use the concepts from this subsection as long as we fix a plane.
\end{remark}

\begin{remark}\label{rem:xyz}
  By convention, depending on the context, in \hyperref[def:euclidean_plane]{Euclidean planes} the letters \( x \) and \( y \) have several meanings:
  \begin{itemize}
    \item The vectors of the \hyperref[def:sequence_space]{standard basis}.
    \item The corresponding \hyperref[def:euclidean_plane]{coordinate axes}.
    \item The \hyperref[def:affine_coordinate_system]{(affine) coordinates} of some arbitrary point.
  \end{itemize}

  We call the axis \( x \) the \term{abscissa} and \( y \) --- the \term{ordinate}.

  In three-dimensional \hyperref[def:euclidean_space]{Euclidean spaces}, we use the letter \( z \) to denote the third coordinate axis and call it the \term{applicata}.

  To avoid confusion, we avoid using \( x \), \( y \) and \( z \) in Euclidean planes to denote points and vectors.
\end{remark}

\begin{definition}\label{def:plane_line_equations}
  \hyperref[def:affine_line]{Lines} in \( \BbbR^2 \) are so ubiquitous that they are often represented via a variety of \hyperref[ex:equations]{equations}.

  We will start with \fullref{def:affine_line/parametric} --- the \hyperref[def:affine_operator]{affine} \hyperref[def:parametric_curve]{parametric curve}
  \begin{equation}\label{eq:def:plane_line_equations/parametric}
    l(t) = O + td
  \end{equation}

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/thm__plane_line_equations__cartessian.pdf}
    \caption{A \hyperref[def:affine_line]{line} in \( \BbbR^2 \) defined using its \hyperref[def:plane_line_equations/cartesian]{Cartesian equation}.}\label{fig:def:plane_line_equations/cartesian}
  \end{figure}

  \begin{thmenum}
    \thmitem{def:plane_line_equations/vector_parametric}\mcite[def. 2.1]{ВеселовТроицкий2002Лекции} We call \eqref{eq:def:plane_line_equations/parametric} a \term{vector parametric equation} of \( L \).

    \medspace

    \thmitem{def:plane_line_equations/scalar_parametric}\mcite[def. 2.1]{ВеселовТроицкий2002Лекции} The parametric equation \eqref{eq:def:plane_line_equations/parametric} can be rewritten as
    \begin{equation}\label{eq:def:plane_line_equations/scalar_parametric}
      \begin{cases}
         &l_x(t) = o_x + t d_x, \\
         &l_y(t) = o_y + t d_y.
      \end{cases}
    \end{equation}

    We say that these are \term{scalar parametric equations} of the line. They are non-unique by the same reason as the vector parametric equation.

    \thmitem{def:plane_line_equations/general}\mcite[exmpl. 2.4]{ВеселовТроицкий2002Лекции} The image of the scalar equations \eqref{eq:def:plane_line_equations/scalar_parametric} consists of all pairs \( (x, y) \) such that
    \begin{equation}\label{eq:def:plane_line_equations/general}
      \underbrace{ Ax + By + C }_{ p(x, y) } = 0
    \end{equation}
    for some scalars \( A \), \( B \) and \( C \), where \( A \) or \( B \) (or both) are nonzero.
    We call \eqref{eq:def:plane_line_equations/general} a \term{general equation} of the line.

    More concretely,
    \begin{equation*}
      A(o_x + td_x) + B(o_y + td_y) + C = 0
    \end{equation*}
    for all \( t \) if \( A = d_y \), \( B = -d_x \) and \( C = o_y d_x - o_x d_y \).

    Conversely, given the general equation \eqref{eq:def:plane_line_equations/general}, assuming \( A \neq 0 \), we can define the parametric equations
    \begin{equation*}
      \begin{cases}
        &l_x(t) \coloneqq -\tfrac C A - t \tfrac B A  \\
        &l_y(t) \coloneqq t.
      \end{cases}
    \end{equation*}

    The case when \( A = 0 \) and \( B \neq 0 \) is handled analogously.

    Note that multiple general equations can have the same locus --- actually all scalar multiples of \( p(x, y) \). If \( A^2 + B^2 = 1 \) in \eqref{eq:def:plane_line_equations/general}, we call it a \term{normal equation}. There are only two normal equations.

    \thmitem{def:plane_line_equations/cartesian} It is common, especially in analysis, to use the \term{Cartesian equation}
    \begin{equation}\label{eq:def:plane_line_equations/cartesian}
      y = kx + m
    \end{equation}
    for some scalars \( k \) and \( m \). We call \( k \) the \term{slope} of the line.

    It is a special case of the general equation \eqref{eq:def:plane_line_equations/general} with \( A = -k \), \( B = -1 \) and \( C = m \).

    Unlike the general equation, the Cartesian equation of a line is unique, but it cannot express vertical lines. If \( B \neq 0 \) in \eqref{eq:def:plane_line_equations/general}, we can define \( k = -\ifrac A B \) and \( m = -\ifrac C B \) to form a Cartesian equation.

    \begin{figure}[!ht]
      \centering
      \includegraphics[align=c]{output/thm__plane_line_equations__cartessian.pdf}
      \caption{A \hyperref[def:affine_line]{line} in \( \BbbR^2 \) defined using its \hyperref[def:plane_line_equations/cartesian]{Cartesian equation}.}\label{fig:def:plane_line_equations/cartesian_drawing}
    \end{figure}

    \thmitem{def:plane_line_equations/intercept} Another equation that is occasionally used is the \term{intercept equation}
    \begin{equation}\label{eq:def:plane_line_equations/intercept}
      \frac x a + \frac y b = 1
    \end{equation}
    for some nonzero real numbers \( a \) and \( b \).

    It is again a special case of the general equation \eqref{eq:def:plane_line_equations/general} with \( A = \ifrac 1 a \), \( B = \ifrac 1 b \) and \( C = -1 \). It is also unique, but it cannot express neither vertical nor horizontal lines, nor lines passing through the origin.

    Conversely, if \( A \), \( B \) and \( C \) are all nonzero in the general equation \eqref{eq:def:plane_line_equations/general}, we can define an intercept equation as \( a = -\ifrac C A \) and \( b = -\ifrac C B \).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:parallel_lines_in_plane}
  Let \( Ax + By + C = 0 \) and \( Dx + Ey + F = 0 \) be the \hyperref[def:plane_line_equations/general]{general equations} of two lines. The lines are \hyperref[def:affine_parallelism]{parallel} if and only if the vectors \( (A, B) \) and \( (D, E) \) are linearly dependent, and identical if and only if \( (A, B, C) \) and \( (D, E, F) \) are linearly dependent.
\end{proposition}

\begin{proposition}\label{thm:lines_intersect_in_plane}
  Two \hyperref[def:affine_line]{lines} in the Euclidean plane intersect if and only if they are not \hyperref[def:affine_parallelism]{parallel}.
\end{proposition}

\begin{proposition}\label{thm:rotation_matrix_symmetry}
  For a \hyperref[def:rigid_motion/rotation]{rotation matrix}
  \begin{equation*}
    A = \begin{pmatrix}
      a & b \\
      c & d
    \end{pmatrix},
  \end{equation*}
  i.e. an \hyperref[def:unitary_matrix]{orthogonal matrix} with \hyperref[def:matrix_determinant]{determinant} \( 1 \), we have \( b = -c \) and \( d = a \). That is,
  \begin{equation*}
    A = \begin{pmatrix}
      a & -c \\
      c & a
    \end{pmatrix}
  \end{equation*}
  and
  \begin{equation*}
    a^2 + c^2 = 1.
  \end{equation*}
\end{proposition}
\begin{proof}
  Since \( A \) is orthogonal, \( ab + cd = 0 \). Also, \( \det A = ad - bc = 1 \). Either \( a \) or \( b \) or both must be nonzero, because otherwise \( A \) would be singular.
  \begin{itemize}
    \item If \( a = 0 \), then \( cd = 0 \) and hence either \( c = 0 \) or \( d = 0 \). If \( c = 0 \), then \( \det A = 0 \), which contradicts the assumption that \( \det A = 1 \). Thus, \( c \neq 0 \) and \( d = 0 \).

    Then \( b^2 = c^2 = 1 \) since the columns are normed, and also \( \det A = -bc = -1 < 0 \). Thus, \( \abs{b} = \abs{c} = 1 \) and they have different signs.

    \item If \( a \neq 0 \), then \( b = -\ifrac {cd} a \) and \( ad + \ifrac {c^2 d} a = 1 \). Multiplying both sides by \( a \), we obtain
    \begin{equation*}
      (a^2 + c^2) d = a.
    \end{equation*}

    But \( a^2 + c^2 = 1 \) because the columns of \( A \) are normed. Thus, \( d = a \) and \( c = -b \).
  \end{itemize}

  In both cases,
  \begin{equation*}
    A
    =
    \begin{pmatrix}
      a & -c \\
      c & a
    \end{pmatrix}
  \end{equation*}
  and also
  \begin{equation*}
    \det A = a^2 + c^2 = 1.
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:plane_ray_abscissa_rotation}
  Every \hyperref[def:geometric_ray]{ray} at the origin in the Euclidean plane is a \hyperref[def:rigid_motion/rotation]{rotation} of the \hyperref[rem:xyz]{abscissa}. Furthermore, this rotation is unique.
\end{proposition}
\begin{proof}
  Let \( r(t) = td \) be some ray and let \( (x, y) \) be the coordinates of the vector \( d \).

  \UniquenessSubProof Suppose that there exist rotations \( A \) and \( B \) such that
  \begin{equation*}
    \begin{pmatrix} x \\ y \end{pmatrix} = A \begin{pmatrix} 1 \\ 0 \end{pmatrix} = B \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
  \end{equation*}

  \Fullref{thm:rotation_matrix_symmetry} then implies that
  \begin{equation*}
    A = B = \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}.
  \end{equation*}

  \ExistenceSubProof The matrix
  \begin{equation*}
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}.
  \end{equation*}
  is obviously a rotation matrix.

  Since \( (1, 0) \) are the coordinates of the abscissa basis vector,
  \begin{equation*}
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x & -y \\
      y & x
    \end{pmatrix}
    \begin{pmatrix}
      1 \\ 0
    \end{pmatrix}
    =
    \frac 1 {x^2 + y^2}
    \begin{pmatrix}
      x \\ y
    \end{pmatrix}.
  \end{equation*}

  This vector is \hyperref[def:geometric_ray/unidirectional]{unidirectional} with \( d \), hence its ray at the origin coincides with \( r \).
\end{proof}

\begin{proposition}\label{thm:plane_ray_rotation}
  For every point \( O \) and every pair of rays \( r(t) = O + td \) to \( s(t) = O + te \), there exists a unique \hyperref[def:rigid_motion]{rigid motion} \( f(v) \), whose linear part of \( f(v) \) is a \hyperref[def:rigid_motion/rotation]{rotation}, sending (the image of) \( r \) to \( s \). Furthermore, \( s(t) = f(r(t)) \).
\end{proposition}
\begin{proof}
  \SubProof{Proof that \( s = f \bincirc r \)} Suppose that \( f(v) = a + Tv \) is a rigid motion sending the image of \( r(t) \) to the image of \( s(t) \). That is, \( f(\img r) = \img s \), but we do not know how the functions \( f \), \( r \) and \( s \) relate.

  Suppose that \( \norm{d} = \norm{e} = 1 \). Let \( f(o) = s(\lambda) \), i.e.
  \begin{equation*}
    a + T O = f(o) = f(r(0)) = s(\lambda) = O + \lambda e.
  \end{equation*}

  Next, suppose that \( f(r(1)) = s(\mu) \). That is,
  \begin{equation*}
    f(r(1)) = a + T (o + d) = O + \mu e = s(\mu).
  \end{equation*}

  Then
  \begin{equation*}
    (a + T o) + T d = O + \mu e
  \end{equation*}
  and
  \begin{equation*}
    Td = (\mu - \lambda) e.
  \end{equation*}

  Note that \( T \) preserves norms as an orthogonal transformation, hence
  \begin{equation*}
    \underbrace{\norm{Td}}_{1} = (\mu - \lambda) \underbrace{\norm{e}}_{1}.
  \end{equation*}

  It follows that \( \mu = \lambda + 1 \) and \( e = Td \). Therefore,
  \begin{equation*}
    f(r(t)) = a + T(o + td) = (a + To) + t e.
  \end{equation*}

  Note that there exists some scalar \( \tau \) such that
  \begin{equation*}
    f(r(\tau)) = s(0) = o.
  \end{equation*}

  Then
  \begin{equation*}
    O = f(r(\tau)) = a + T O + \tau e = O + \lambda e + t e
  \end{equation*}
  and \( \lambda = -\tau \).

  Since both \( \lambda \) and \( \tau \) are nonnegative, it follows that \( \lambda = -\tau = 0 \). Then
  \begin{equation*}
    a + T O = f(r(0)) = s(\lambda) = s(0) = o,
  \end{equation*}
  hence \( a = O - T O \).

  Thus,
  \begin{equation*}
    f(v) = O - T O + Tv = O + T(v - o).
  \end{equation*}

  In particular,
  \begin{equation*}
    f(r(t)) = O + T(o + td - o) = O + t Td = O + te = s(t).
  \end{equation*}

  \UniquenessSubProof Suppose that \( f(v) \) and \( g(v) \) are rigid motions sending the ray \( r(t) \) to \( s(t) \). We have already shown that \( O \) is a fixed point of both \( f(v) \) and \( g(v) \), hence, by \fullref{thm:rigid_motion_fixed_point}, there exist some rotation operators \( F \) and \( G \) such that \( f(v) = O + F(v - o) \) and \( g(v) = O + G(v - o) \). Then
  \begin{equation*}
    \vect 0 = s(t) - s(t) = f(r(t)) - g(r(t)) = O + F(v - o) - O - G(v - o).
  \end{equation*}

  Therefore,
  \begin{equation*}
    F(v - o) = G(v - o)
  \end{equation*}
  and
  \begin{equation*}
    (G - F) v = (G - F) o.
  \end{equation*}

  Since this holds for arbitrary \( v \), it is only possible that \( (G - F) v = (G - F) O = \vect 0 \). Thus, \( F = G \) and \( f(v) = g(v) \).

  \ExistenceSubProof \Fullref{thm:plane_ray_abscissa_rotation} implies that there exists a unique rotation \( R \) sending the abscissa to \( r'(t) = td \) and \( S \) sending it to \( s'(t) = te \).

  Then
  \begin{equation*}
    S^{-1} e
    =
    S^{-1} S \begin{pmatrix} 1 \\ 0 \end{pmatrix}
    =
    R^{-1} R \begin{pmatrix} 1 \\ 0 \end{pmatrix}
    =
    R^{-1} d.
  \end{equation*}

  Hence,
  \begin{equation*}
    e = S R^{-1} d.
  \end{equation*}

  That is, \( T \coloneqq R^{-1} S \) sends \( r' \) to \( s' \). Then \( O + T(v - o) \) sends \( r \) to \( s \).
\end{proof}

\begin{proposition}\label{thm:plane_rotation_matrix}
  The map
  \begin{equation}\label{eq:thm:plane_rotation_matrix}
    \varphi
    \mapsto
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
  \end{equation}
  is an \hyperref[def:morphism_invertibility/right_cancellative]{epimorphism} from the real numbers under addition to the group of \hyperref[def:rigid_motion/rotation]{rotations} in \( \BbbR^2 \) under composition. The kernel of this map is the set of multiples of \( 2\pi \).

  We call \( \varphi \) the \term{angle} of the rotation; the semantics of the work \enquote{angle} are discussed in \fullref{def:angle}.

  There are other groups isomorphic to the rotation group --- see \fullref{def:circle_group}.
\end{proposition}
\begin{proof}
  \SubProof{Proof of well-definedness} The matrix \eqref{eq:thm:plane_rotation_matrix} is orthogonal, and its determinant is \( 1 \) as a consequence of \fullref{thm:trigonometric_identities/pythagorean_identity}. Hence, it induces a rotation.

  \SubProofOf[def:function_invertibility/surjective/equality]{surjectivity} Let
  \begin{equation*}
    A
    =
    \begin{pmatrix}
      a & b \\
      c & d
    \end{pmatrix}
  \end{equation*}
  be a rotation matrix, i.e. an \hyperref[def:unitary_matrix]{orthogonal matrix} with \hyperref[def:matrix_determinant]{determinant} \( 1 \).

  Since \( A \) is orthogonal, \( ab + cd = 0 \). Also, \( \det A = ad - bc = 1 \). Either \( a \) or \( b \) or both must be nonzero, because otherwise \( A \) would be singular.
  \begin{itemize}
    \item If \( a = 0 \), then \( cd = 0 \) and hence either \( c = 0 \) or \( d = 0 \). If \( c = 0 \), then \( \det A = 0 \), which contradicts the assumption that \( \det A = 1 \). Thus, \( c \neq 0 \) and \( d = 0 \).

    Then \( b^2 = c^2 = 1 \) since the columns are normed, and also \( \det A = -bc = -1 < 0 \). Thus, \( \abs{b} = \abs{c} = 1 \) and they have different signs.

    \item If \( a \neq 0 \), then \( b = -\ifrac {cd} a \) and \( ad + \ifrac {c^2 d} a = 1 \). Multiplying both sides by \( a \), we obtain
    \begin{equation*}
      (a^2 + c^2) d = a.
    \end{equation*}

    But \( a^2 + c^2 = 1 \) because the columns of \( A \) are normed. Thus, \( d = a \) and \( c = -b \).
  \end{itemize}

  In both cases,
  \begin{equation*}
    A
    =
    \begin{pmatrix}
      a & -c \\
      c & a
    \end{pmatrix}
  \end{equation*}
  and also
  \begin{equation*}
    \det A = a^2 + c^2 = 1.
  \end{equation*}

  Define \( \varphi \) as
  \begin{equation*}
    \varphi \coloneqq \begin{cases}
      \arccos a,  &c \geq 0, \\
      -\arccos a, &c < 0.
    \end{cases}
  \end{equation*}

  Then
  \begin{equation*}
    (\sin \varphi)^2 = 1 - (\cos \varphi)^2 = 1 - a^2 = c^2.
  \end{equation*}

  \begin{itemize}
    \item If \( c \geq 0 \), then \( \varphi \in [0, \pi) \) and hence \( \sin \varphi \geq 0 \). Since the square root has nonnegative values,
    \begin{equation*}
      \sin \varphi = \sqrt{ 1 - a^2 } = c.
    \end{equation*}

    \item If \( c < 0 \), then \( \varphi \in (-\pi, 0) \) and hence \( \sin \varphi < 0 \). Thus,
    \begin{equation*}
      \sin \varphi = -\sqrt{ 1 - a^2 } = c.
    \end{equation*}
  \end{itemize}

  Therefore,
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    =
    \begin{pmatrix}
      a & -c \\
      c & a
    \end{pmatrix}
    =
    A.
  \end{equation*}

  \SubProof{Proof of homomorphism condition} We have
  \begin{equation*}
    \cos(\varphi + \psi)
    \reloset {\eqref{eq:thm:trigonometric_identities/sum_of_angles/cos}} =
    \cos \varphi \cos \psi - \sin \varphi \sin \psi
    =
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \cos \psi \\ \sin \psi
    \end{pmatrix}.
  \end{equation*}
  and
  \begin{equation*}
    \sin(\varphi + \psi)
    \reloset {\eqref{eq:thm:trigonometric_identities/sum_of_angles/cos}} =
    \cos \varphi \sin \psi + \sin \varphi \cos \psi
    =
    \begin{pmatrix}
      \cos \varphi & \sin \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \sin \psi \\ \cos \psi
    \end{pmatrix}.
  \end{equation*}

  Then
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    \begin{pmatrix}
      \cos \psi & -\sin \psi \\
      \sin \psi & \cos \psi
    \end{pmatrix}
    =
    \begin{pmatrix}
      \cos (\varphi + \psi) & -\sin (\varphi + \psi) \\
      \sin (\varphi + \psi) & \cos (\varphi + \psi)
    \end{pmatrix}.
  \end{equation*}

  \SubProof{Proof that kernel are multiples of \( 2\pi \)} Suppose that
  \begin{equation*}
    \begin{pmatrix}
      \cos \varphi & -\sin \varphi \\
      \sin \varphi & \cos \varphi
    \end{pmatrix}
    =
    \begin{pmatrix}
      \cos \psi & -\sin \psi \\
      \sin \psi & \cos \psi
    \end{pmatrix}.
  \end{equation*}

  Both \( \sin \) and \( \cos \) are bijective on the interval \( [0, 2\pi) \). From \fullref{thm:trigonometric_function_period} it follows that, if \( \cos \varphi = \cos \psi \), then \( 2\pi \) divides \( \varphi - \psi \).
\end{proof}

\begin{definition}\label{def:angle}
  A \term{directed angle} is an ordered pair of \hyperref[def:geometric_ray]{rays} with a common vertex. We denote the angle between the rays \( r \) and \( s \) via \( \sphericalangle(r, s) \).

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__angle.pdf}
    \caption{The two \hyperref[def:angle]{directed angles} \( \sphericalangle(r, s) \) and \( \sphericalangle(r, s) \) given by the rays \( r \) and \( s \).}\label{def:angle/measure/figure}
  \end{figure}

  \begin{thmenum}
    \thmitem{def:angle/measure} Denote by \( O \) the common vertex of \( r \) and \( s \). \Fullref{thm:plane_ray_rotation} implies that there exists a unique \hyperref[def:rigid_motion]{rigid motion} \( f(v) = O + T(v - o) \), where \( T \) is a \hyperref[def:rigid_motion/rotation]{rotation}, sending \( r \) to \( s \). \Fullref{thm:plane_rotation_matrix} then implies the existence of a unique number \( \varphi \in [0, 2\pi) \) entirely determining \( T \). We will call \( \varphi \) the \term{measure} of \( \sphericalangle(r, s) \).

    It is conventional to conflate an angle and its measure. For this reason, it is sometimes convenient to define angles via directional vectors rather than rays, disregarding the vertex.

    We can classify angles based on their measure as
    \begin{thmenum}
      \thmitem{def:angle/measure/zero} \term{zero} if \( \varphi = 0 \),
      \thmitem{def:angle/measure/acute} \term{acute} if \( 0 < \varphi < \ifrac \pi 2 \),
      \thmitem{def:angle/measure/right} \term{right} if \( \varphi = \tfrac \pi 2 \),
      \thmitem{def:angle/measure/obtuse} \term{obtuse} if \( \ifrac \pi 2 < \varphi < \pi \),
      \thmitem{def:angle/measure/straight} \term{straight} if \( \varphi = \pi \), in which case the angle is actually a line,
      \thmitem{def:angle/measure/reflex} \term{reflex} if \( \varphi > \pi \).
    \end{thmenum}

    \thmitem{def:angle/undirected} Given the transformation \( f(v) \) sending \( r \) to \( s \), its inverse \( f^{-1}(v) \) sends \( s \) to \( r \). Their composition is the identity, whose angle measure is a multiple \( 2\pi \). \Fullref{thm:plane_rotation_matrix} implies that the angle measures \( \sphericalangle(r, s) \) and \( \sphericalangle(s, r) \) sum to \( 2\pi \). We call the angle with the smaller measure the \term{undirected angle} between \( r \) and \( s \).

    To recap, the word \enquote{angle} may refer to either a directed angle, its measure, an undirected angle or its measure.
  \end{thmenum}
\end{definition}

\begin{definition}\label{thm:angles_of_intersection}
  Let \( g \) and \( h \) be non-\hyperref[def:affine_parallelism]{parallel} lines and let \( O \) be their intersection point.

  Let \( d \) and \( e \) be arbitrary directional vectors for \( g \) and \( h \) correspondingly. Then the \hyperref[def:angle/undirected]{\hi{undirected} angles} \( \sphericalangle(\vect{Od}, \vect{Oe}) \) and \( \sphericalangle(-\vect{Od}, -\vect{Oe}) \) are have equal measures.

  We call this common value the \term{angle} \( \sphericalangle(g, h) \) of a line intersection.

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/thm__angles_of_intersection.pdf}
    \caption{The angles in \fullref{thm:angles_of_intersection}.}\label{fig:thm:angles_of_intersection}
  \end{figure}
\end{definition}

\begin{definition}\label{thm:angles_of_transversal}
  Let \( l \) be a \hyperref[def:transversal_line]{transversal} through the distinct \hyperref[def:affine_parallelism]{parallel lines} \( g \) and \( h \). Then the \hyperref[thm:angles_of_intersection]{line intersection angles} \( \sphericalangle(l, g) \) and \( \sphericalangle(l, h) \) have equal measures.

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/thm__angles_of_transversal.pdf}
    \caption{The angles in \fullref{thm:angles_of_transversal}.}\label{fig:thm:angles_of_transversal}
  \end{figure}
\end{definition}

\begin{definition}\label{def:triangle}
  A \hyperref[def:simplex]{\( 2 \)-simplex} is called a \term{triangle}. This definition holds more generally than Euclidean spaces, however we restrict it because we have not defined \hyperref[def:angle]{angles} more generally.

  \begin{figure}[!ht]
    \centering
    \includegraphics[align=c]{output/def__triangle.pdf}
    \caption{An \hyperref[def:triangle/acute]{acute triangle}.}\label{fig:def:triangle}
  \end{figure}

  Given a triangle with vertices \( A \), \( B \) and \( C \), we define the associated \hyperref[def:line_segment]{line segments}, called the \term{sides} of the triangle, and its \hyperref[def:angle]{undirected angles} as
  \begin{align*}
    a \coloneqq [B, C], && \alpha \coloneqq \sphericalangle(\vect{AB}, \vect{AC}), \\
    b \coloneqq [A, C], && \beta  \coloneqq \sphericalangle(\vect{BA}, \vect{BC}),  \\
    c \coloneqq [A, B], && \gamma \coloneqq \sphericalangle(\vect{CA}, \vect{CB}).
  \end{align*}

  We can classify triangles based on their sides as
  \begin{thmenum}
    \thmitem{def:triangle/isosceles} \term{isosceles} if at least two of its sides have equal length
    \thmitem{def:triangle/equilateral} \term{equilateral} if all of its sides have equal length
  \end{thmenum}
  or based on their angles as
  \begin{thmenum}
    \thmitem{def:triangle/acute} \term{acute} if all of its angles are \hyperref[def:angle/measure/acute]{acute}.
    \thmitem{def:triangle/right} \term{right} if at least one of the angles is \hyperref[def:angle/measure/straight]{straight}.
    \thmitem{def:triangle/obtuse} \term{obtuse} if at least one of its angles is \hyperref[def:angle/measure/obtuse]{obtuse}.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:sum_of_angle_triangles}
  The sum of the (measures of) the angles of an arbitrary \hyperref[def:triangle]{triangle} is \( 2\pi \).
\end{proposition}
