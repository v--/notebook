\subsection{Polynomials}\label{subsec:polynomials}

\begin{remark}\label{rem:polynomials_vs_polynomial_functions}
  Polynomial are a purely algebraic framework for describing certain well-behaved functions. The link between a polynomial and a function is given by \fullref{def:polynomial_function}, but in general these are different concepts. The link between a polynomial and its conventional symbolic expression is given by \fullref{def:algebra_of_polynomials}.

  \Fullref{thm:polynomial_embedding_behavior} allow us to ignore this distinction in certain special cases.
\end{remark}

\begin{definition}\label{def:polynomial}\mcite\cite[149]{Knapp2016BasicAlgebra}
  A \term{polynomial} \( p \) over \( R \) is a sequence of members of \( R \) called \term{coefficients},
  \begin{equation*}
    p \coloneqq ( a_0, a_1, a_2, \ldots ) \subseteq R,
  \end{equation*}
  such that only finitely many coefficients are nonzero. We can regard \( p \) as a \hyperref[def:topological_net]{net} over \( \BbbZ_{\geq 0} \) with finite \hyperref[def:function_support]{support}.

  \begin{thmenum}
    \ilabel{def:polynomial/zero_polynomial} An exception to most rules is the \term{zero polynomial}, all of whose coefficients are zeroes.

    \ilabel{def:polynomial/leading_coefficient} The last nonzero coefficient of a nonzero polynomial is called the \term{leading coefficient} and is denoted by \( \op{LC}(p) \). If \( \op{LC}(p) = 1 \), we call the polynomial \term{2}.

    \ilabel{def:polynomial/degree} The zero-based index of the leading coefficient is called the \term{degree} of the polynomial as is denoted by \( \deg(p) \). That is, if only \( a_0 \) is nonzero, then \( \deg(p) = a_0 \). The degree of the zero polynomial is left undefined.

    \ilabel{def:polynomial/monomial} A \term{monomial} is a polynomial with only one nonzero element.

    \ilabel{def:polynomial/degree_names} Polynomials of degree \( n \) with special names include
    \begin{itemize}
      \item \term{constant} for the zero polynomial or if \( n = 0 \).
      \item \term{linear} if \( n = 1 \).
      \item \term{quadratic} if \( n = 2 \).
      \item \term{cubic} if \( n = 3 \).
      \item \term{quartic} if \( n = 4 \).
      \item \term{quintic} if \( n = 5 \).
    \end{itemize}
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:algebra_of_polynomials}
  Denote by \( R[X] \) the set of polynomials over \( R \). Note that it is bijective with \( c_{00} \) and we can inherit pointwise addition and scalar multiplication from there. That is,

  \begin{thmenum}
    \ilabel{def:algebra_of_polynomials/addition} We define \term{polynomial addition} point as
    \begin{balign*}
       & +: R[X] \times R[X] \to R[X]                                                     \\
       & (a_0, a_1, \ldots) + (b_0, b_1, \ldots) \coloneqq (a_0 + b_0, b_0 + b_1, \ldots)
    \end{balign*}

    \ilabel{def:algebra_of_polynomials/scalar_multiplication} We define \term{scalar multiplication} as
    \begin{balign*}
       & \cdot: R[X] \times R[X] \to R[X]                            \\
       & t \cdot (a_0, a_1, \ldots) \coloneqq (t a_0, t b_1, \ldots)
    \end{balign*}

    \ilabel{def:algebra_of_polynomials/polynomial_multiplication} In order to make \( R[X] \) into an \hyperref[def:algebra_over_ring]{algebra}, we define \term{Cauchy multiplication} \( \odot: R[X] \times R[X] \to R[X] \) as follows: if \( (a_0, a_1, \ldots) \) and \( (b_0, b_1, \ldots) \) are polynomials, their product is defined to be the polynomial with coefficients
    \begin{equation}
      c_l \coloneqq \sum_{i+j=l} a_i b_j, l = 0, 1, \ldots.
    \end{equation}

    Polynomial multiplication is bilinear, associative and commutative.
  \end{thmenum}

  We will implicitly use the canonical embedding \( \iota: R \to R[X] \), which sends an element \( r \) of \( R \) into the constant polynomial \( p(X) \coloneqq r \).

  We usually refer to \( R[X] \) as the \term{polynomial ring}, especially since scalar multiplication is the same multiplication by constants.
\end{definition}

\begin{remark}\label{rem:polynomial_symbolic_expression}
  We choose a \hyperref[def:language]{symbol}, usually \( X \), called an \term{indeterminate}, and give it \hyperref[def:first_order_semantics/satisfiability]{semantics} using the \hyperref[def:polynomial/monomial]{monomial}
  \begin{equation*}
    X \coloneqq (0, 1, 0, 0, \ldots)
  \end{equation*}
  (the assignment should be understood as \enquote{defining the interpretation of \( X \) in a certain first-order language}).

  Using the definition of multiplication, we see that the coefficients \( c_0, c_1, \ldots \) of \( X^2 = X \cdot X \) can be expressed in terms of the coefficients \( a_0, a_1, \ldots \) of \( X \) as
  \begin{balign*}
    c_0 & = a_0 \cdot a_0 = 0                                                                 \\
    c_1 & = a_0 \cdot a_1 + a_1 \cdot a_0 = 0 + 0 = 0                                         \\
    c_2 & = a_0 \cdot a_2 + a_1 \cdot a_1 + a_2 \cdot a_0 = 0 + 1 + 0 = 1                     \\
    c_3 & = a_0 \cdot a_3 + a_1 \cdot a_2 + a_2 \cdot a_1 + a_0 \cdot a_3 = 0 + 0 + 0 + 0 = 0 \\
    c_4 & = \cdots = 0                                                                        \\
    c_5 & = \cdots = 0                                                                        \\
    \vdots
  \end{balign*}

  Proceeding by induction\IND, we see that \( X^k \) corresponds to the sequence
  \begin{equation*}
    (\underbrace{0, 0, \ldots, 0, 0}_{k \text{times}}, 1, 0, 0, \ldots).
  \end{equation*}

  We define \( X^0 \coloneqq 1 \).

  It is conventional to then write a polynomial of degree \( n \) as the \hyperref[def:language]{expression}
  \begin{equation}\label{eq:rem:polynomial_symbolic_expression}
    p(X) = a_n X^n + a_{n-1} X^{n-1} + \ldots + a_2 X^2 + a_1 X + a_0 = \sum_{i=0}^n a_i X^i
  \end{equation}
  and the zero polynomial as
  \begin{equation*}
    p(X) \coloneqq 0.
  \end{equation*}

  We use capital letters to highlight that this is not a function - see \fullref{def:polynomial_function}. We say that \( p(X) \) is a polynomial in one indeterminate.
\end{remark}

\begin{proposition}\label{thm:polynomial_degree_properties}
  The polynomial degree has the following basic properties:
  \begin{thmenum}
    \ilabel{thm:polynomial_degree_properties/sum} For nonzero polynomials \( p, q \in R[X] \) with \( p \neq -q \), we have
    \begin{equation*}
      \deg (p + q) \leq \max \{ \deg p, \deg q \}.
    \end{equation*}

    \ilabel{thm:polynomial_degree_properties/product} For nonzero polynomials \( p, q \in R[X] \) with \( pq \neq 0 \), we have
    \begin{equation*}
      \deg (pq) \leq \deg p + \deg q,
    \end{equation*}
    with equality holding if \( R \) is an integral domain.

    The requirement that \( pq \neq 0 \) may also be dropped if \( R \) is an integral domain as per \fullref{thm:polynomials_over_integral_domain_are_integral_domain}.
  \end{thmenum}
\end{proposition}
\begin{proof}
  Fix nonzero polynomials
  \begin{align}
    p(X) &\coloneqq \sum_{k=0}^n a_k X^k, \label{eq:thm:polynomial_degree_properties/p} \\
    q(X) &\coloneqq \sum_{k=0}^m b_k X^k. \label{eq:thm:polynomial_degree_properties/q}
  \end{align}

  \SubProofOf{thm:polynomial_degree_properties/sum} Additionally assume that \( p \neq -q \) since otherwise \( p + q = 0 \) and \( \deg(p + q) \) is undefined. Thus there exists at least one index \( k = 1, 2, \ldots \) so that \( a_k \neq b_k \). Denote by \( k_0 \) the largest such index (only finitely many are nonzero). Then
  \begin{equation*}
    a_k = b_k = 0 \T{for} k > k_0.
  \end{equation*}

  Therefore \( \deg(p + q) = k_0 \). Note that \( k_0 \) cannot exceed both \( \deg p \) and \( \deg q \) because it corresponds to a nonzero coefficient. Thus \( k \leq \max\{ \deg p, \deg q \} \).

  \SubProofOf{thm:polynomial_degree_properties/product} By assumption \( pq \neq 0 \) so there exists at least one nonzero coefficient, say \( c_k \). Obviously \( k \leq \deg p + \deg q \) since the highest possible degree of \( pq \) is \( \deg p + \deg q \). Thus
  \begin{equation*}
    k = \deg (pq) \leq \deg p + \deg q.
  \end{equation*}

  If \( R \) is an integral domain, the product of nonzero elements is nonzero. Thus the leading coefficient \( \op{LC}(pq) = \op{LC}(p)\op{LC}(q) \) is nonzero and
  \begin{equation*}
    \deg(pq) = \deg p + \deg q.
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:polynomial_ring_universal_property}\mcite\cite[150]{Knapp2016BasicAlgebra}
  For any nontrivial commutative unital ring \( T \), any unital ring homomorphism \( \varphi: R \to T \) and any \( t \in T \), there exists a unique homomorphism \( \Phi_t: R[X] \to T \) such that \( \iota(1) = t \) and the following diagram commutes:

  \begin{alignedeq}\label{thm:polynomial_ring_universal_property/diagram}
    \xymatrix{
      R \ar[rr]^\iota \ar[rd]_\varphi &   & R[X] \ar@{-->}[ld]^{\Phi_t} \\
                                      & T &
    }
  \end{alignedeq}

  We call the map \( \Phi_t \) a \term{substitution homomorphism}.

  If \( T \) is a superring of \( R \), we call \( \Phi_t \) an \term{evaluation} at \( t \in T \). We also write
  \begin{equation}
    R[t] \coloneqq \Phi_t(R[X]).
  \end{equation}

  This allows us to \term{adjoin} elements from a superring to a subring. See \fullref{ex:polynomial_evaluation_gaussian_integers}.
\end{proposition}
\begin{proof}
  We will first prove uniqueness. Let \( \Phi_t: R[X] \to T \) and \( \Psi_t: R[X] \to T \) are two such homomorphisms and take their difference \( \Theta_t \coloneqq \Phi_t - \Psi_t \).

  Then for \( r \in R \) we have
  \begin{equation*}
    \Theta_t(\iota(r)) = \Psi_t(\iota(r)) - \Psi_t(\iota(r)) = \varphi(r) - \varphi(r) = 0.
  \end{equation*}

  Now since for any polynomial we have \( p = \iota(1) p \) and since \( \Theta_t \) is a homomorphism of rings, we have
  \begin{equation*}
    \Theta_t(p) = \Theta_t(\iota(1) p) = 0 \Theta_t(p) = 0.
  \end{equation*}

  Thus \( \Theta_t = 0 \) and \( \Phi_t = \Psi_t \).

  Now we will show existence. Take a polynomial
  \begin{equation*}
    p = (a_0, a_1, \ldots, a_n, 0, 0, \ldots).
  \end{equation*}

  Define
  \begin{equation*}
    \Phi_t(p) \coloneqq \sum_{i=1}^n \phi(a_0) t^i.
  \end{equation*}

  By additivity, \( \Phi_t: R[X] \to T \) is obviously a homomorphism and \( \Phi_t((0, 1, 0, \ldots)) = t \). Therefore we have proven existence.
\end{proof}

\begin{example}\label{ex:polynomial_evaluation_gaussian_integers}
  The Gaussian \hyperref[def:gaussian_integers]{integers} \( \BbbZ[i] \) are complex numbers with integer real and complex parts. We will now motivate this notation.

  Consider the substitution map \( \Phi_i: \BbbZ[X] \to \BbbC \) for the imaginary unit given by \fullref{thm:polynomial_ring_universal_property}. Let \( p(X) \in \BbbZ[X] \). Then
  \begin{equation*}
    p(i)
    =
    \Phi_i(p)
    =
    \sum_{j=0}^n a_j i^n
    =
    \sum_{\rem(j, 4) = 0}^n a_j - \sum_{\rem(j, 4) = 2}^n a_j + i \left(\sum_{\rem(j, 4) = 1}^n a_j - \sum_{\rem(j, 4) = 3}^n a_j \right).
  \end{equation*}

  This is clearly a Gaussian integer.

  Now fix a Gaussian integer \( z = a + bi \). It can given by the polynomial
  \begin{equation*}
    p_z(X) \coloneqq a + bX.
  \end{equation*}

  It remains to show that multiplication in \( \BbbZ[X] \) is compatible with multiplication in \( \BbbC \). But complex \hyperref[def:complex_numbers]{multiplication} is defined to be compatible with the notation \( a + bi \), that is,
  \begin{equation*}
    (a + bi) (c + di)
    =
    ac + ibc + iad - bd
    =
    (ac - bd) + i(bc + ad).
  \end{equation*}

  Thus the Gaussian integers are precisely the homomorphic image of \( Z[X] \) under \( \Phi_i \).
\end{example}

\begin{proposition}\label{thm:polynomial_ring_units}
  The units of the polynomial ring \( R[X] \) are precisely the units of \( R \).
\end{proposition}
\begin{proof}
  Any unit of \( R \) is obviously a unit of \( R[X] \).

  For the converse, fix a nonzero constant polynomial \( p(X) = r \). In order for it to have an inverse \( q(X) \), we should have
  \begin{equation*}
    1 = p(X) q(X) = r q(X),
  \end{equation*}
  which can only happen if \( q(X) \) is a constant and a multiplicative inverse of \( r \).
\end{proof}

\begin{proposition}\label{thm:polynomial_algebra_basis}
  The polynomial \hyperref[def:algebra_of_polynomials]{algebra} \( R[X] \) has a Hamel \hyperref[def:left_module_hamel_basis]{basis} consisting of all \hyperref[def:polynomial/monomial]{monomials}
  \begin{equation*}
    B \coloneqq \{ 1, X, X^2, X^3, \ldots \}.
  \end{equation*}
\end{proposition}
\begin{proof}
  By \fullref{def:algebra_of_polynomials/addition}, every polynomial can easily be represented as a sum of finitely many monomials.
\end{proof}

\begin{definition}\label{def:polynomial_free_module}
  It is convenient, especially in \hyperref[sec:approximation_theory]{approximation theory}, to work with the free module of polynomials of degree at most \( n \). We define
  \begin{equation*}
    \pi_n(R[X]) \coloneqq \linspan \{ 1, X, \ldots, X^{n-1}, X^n \}.
  \end{equation*}

  We will use \( \pi_n \) and when the ring is clear from the context.
\end{definition}

\begin{proposition}\label{thm:polynomials_over_integral_domain_are_integral_domain}
  If \( R \) is an integral domain, the polynomial ring \( R[X] \) is also an integral domain.
\end{proposition}
\begin{proof}
  Polynomial multiplication inherits its commutativity from multiplication in \( R \). It remains only to show that \( R[X] \) has no zero divisors.

  Fix two polynomials \( p, q \in R[X] \). If either of them is zero, their product \( pq \) is zero.

  Assume that both are nonzero polynomials. The leading coefficient of their product is, by definition of multiplication, \( \op{LC}(pq) = \op{LC}(p) \op{LC}(q) \). Since \( R \) has no zero divisors, then \( \op{LC}(pq) \neq 0 \) and thus \( pq \) is a nonzero polynomial.

  Therefore \( R[X] \) is an integral domain.
\end{proof}

\begin{proposition}\label{thm:polynomials_over_unique_factorization_domain_are_unique_factorization_domain}
  If \( R \) is a unique factorization domain, the polynomial ring \( R[X] \) is also a unique factorization domain.
\end{proposition}

\begin{theorem}[Euclidean division of polynomials]\label{thm:euclidean_division_of_polynomials}\mcite\cite[10]{Knapp2016BasicAlgebra}
  Let \( a, b \in R[X] \) and \( b \) be \hyperref[def:polynomial/leading_coefficient]{monic} (in particular, \( b \neq 0 \)). Then there exist unique polynomials \( q, r \in R[X] \), where \( r \) is either zero or \( \deg r < \deg b \), such that
  \begin{equation*}
    a = bq + r.
  \end{equation*}
\end{theorem}
\begin{proof}
  Let \( a, b \in R[X] \) and \( b \neq 0 \). If \( a = 0 \) or \( \deg a < \deg b \), define
  \begin{balign*}
    q & \coloneqq 0, \\
    r & \coloneqq a.
  \end{balign*}

  In this case, \( \deg r = \deg a < \deg b \).

  Suppose that \( \deg b \leq \deg a \). We will use proof by induction\IND on \( \deg a \). If \( \deg a = 0 \), obviously \( \deg b = 0 \) (thus \( b = 1 \)) and we define
  \begin{balign*}
    q & \coloneqq a, \\
    r & \coloneqq 0.
  \end{balign*}

  In this case, \( r \) is the zero polynomial.

  Assume the result holds for \( \deg a < n \) and let \( \deg a = n, \deg b = m \). Then there exists a polynomial \( \hat a(X) \) that is either zero or \( \deg \hat a = n - 1 \) such that
  \begin{equation*}
    a(X) = a_n a^n + \hat a(X).
  \end{equation*}

  Analogously, we find \( \hat b(X) \) that is either zero or \( \deg \hat b = m - 1 \) such that
  \begin{equation*}
    b(X) = X^m + \hat b(X).
  \end{equation*}

  Thus
  \begin{balign*}
    \hat r(X)
     & \coloneqq
    a(X) - b(X) a_n X^{n-m}
    =            \\ &=
    a_n X^n + \hat a(X) - (b_m X^m + \hat b(X)) a_n X^{n-m}
    =            \\ &=
    a_n X^n + \hat a(X) - a_n X^n - \hat b(X) a_n X^{n-m}
    =            \\ &=
    \hat a(X) - \hat b(X) a_n X^{n-m}.
  \end{balign*}

  Therefore \( \hat r(X) \) is either the zero polynomial (in which case we define \( r(X) \coloneqq \hat r(X) \)) or \( \deg \hat r \leq n - 1 \). In the latter case, we can divide \( \hat r \) by \( b \) to obtain \( \hat q(X) \) and \( r(X) \) such that
  \begin{equation*}
    \hat r(X) \coloneqq b(X) \hat q(X) + r(X),
  \end{equation*}
  where \( r = 0 \) or \( \deg r < \deg b \).

  Substitute into the definition of \( \hat r(X) \):
  \begin{balign*}
    \hat r(X)                                         & = a(X) - b(X) a_n X^{n-m} \\
    b(X) \hat q(X) + r(X)                             & = a(X) - b(X) a_n X^{n-m} \\
    b(X) \left(\hat q(X) - a_n X^{n-m} \right) + r(X) & = a(X).
  \end{balign*}

  Define
  \begin{equation*}
    q(X) \coloneqq \hat q(X) - a_n X^{n-m}.
  \end{equation*}

  We have obtained polynomials \( r(X) \) and \( q(X) \) where \( r(X) \) is either zero or \( \deg r < \deg b \).

  It remains only to show uniqueness. Suppose that
  \begin{equation*}
    a = bq + r = bq' + r'.
  \end{equation*}

  If \( r - r' \) is the zero polynomial, so is \( q - q' \) and uniqueness follows.

  If \( r - r' \) is not zero, then neither is \( q - q' \). Then \( b(q - q') = -(r - r') \) and
  \begin{equation*}
    \deg b + \deg(q - q') = \deg[b (q - q')] = \deg(r - r') \leq \max(\deg r, \deg r') < \deg b,
  \end{equation*}
  which is a contradiction.

  This proves uniqueness.
\end{proof}

\begin{corollary}\label{thm:polynomials_over_field_are_euclidean_domain}\mcite\cite[10]{Knapp2016BasicAlgebra}
  The polynomial \hyperref[def:semiring/integral_domain]{ring} \( \BbbK[X] \) over a field \( \BbbK \) is an \hyperref[def:semiring/euclidean_domain]{Euclidean} domain with \( \delta(p) \coloneqq \deg p \). Furthermore, the remainder and quotient are unique.
\end{corollary}
\begin{proof}
  By \fullref{thm:polynomials_over_integral_domain_are_integral_domain}, \( \BbbK[X] \) is an integral domain.

  To show that it is Euclidean, fix two polynomials \( a, b \in \BbbK[X] \) with \( b \neq 0 \). We use \fullref{thm:euclidean_division_of_polynomials} to perform Euclidean division of \( a \) by the monic polynomial \( \frac {b} {\op{LC}(b)} \) and obtain polynomials \( q, r \), where either \( r = 0 \) or \( \deg r < \deg b \), such that
  \begin{equation*}
    a = \frac {b} {\op{LC}(b)} q + r.
  \end{equation*}

  Instead of dividing \( b \) by its leading coefficient \( \op{LC}(b) \), we can divide \( q \) and thus obtain the required factorization.
\end{proof}

\begin{definition}\label{def:polynomial_function}
  Denote by \( \cat{Set}(R) \) the ring of all functions over \( R \) (see \fullref{thm:functions_over_ring_form_algebra}). Define the unital ring homomorphism
  \begin{balign*}
     & \Phi: R[X] \to \cat{Set}(R)                                                                      \\
     & \Phi((a_0, a_1, \ldots, a_n, 0, 0, \ldots)) \coloneqq \left( x \to \sum_{i=0}^n a_i x^n \right),
  \end{balign*}
  which constructs a \term{polynomial function} from a polynomial. This map is not injective in general and multiple polynomials may be equivalent as \hyperref[def:function]{functions}.

  If we want to highlight that we are referring to a polynomial function rather than a polynomial \( p(X) \), we usually use a lowercase letter for the variable, i.e.
  \begin{equation*}
    p(x) = \sum_{i=0}^n a_i x^i.
  \end{equation*}

  If the ring is \hyperref[def:finite_set]{infinite}, \fullref{thm:polynomial_embedding_behavior} allows us to set aside the difference between polynomials and polynomial functions and we usually identify the two when working over \( \BbbR \) or \( \BbbC \).
\end{definition}
\begin{proof}
  It is obvious that \( \Phi \) is a homomorphism of the additive groups of \( R \) and \( \cat{Set}(R) \).

  We will prove that multiplication of polynomials corresponds to multiplication of polynomial functions. Take
  \begin{balign*}
    p(X) & \coloneqq \sum_{i=0}^n a_i X^i, \\
    q(X) & \coloneqq \sum_{j=0}^m b_j X^j.
  \end{balign*}

  For their product \( s(X) = \sum_{i=0}^{n + m} c_i X^i \) by definition we have
  \begin{equation*}
    c_l = \sum_{i+j=l} a_i b_j, l = 0, 1, \ldots, n + m.
  \end{equation*}

  We need to show that for any \( r \in R \),
  \begin{equation*}
    \Phi_r(p) \Phi_r(q) = \Phi_r(s).
  \end{equation*}

  Using associativity and commutativity of multiplication and distributivity of multiplication over addition, we obtain
  \begin{balign*}
    \Phi_r(p) \Phi_r(q)
     & =
    \left( \sum_{i=0}^n a_i r^i \right) \left( \sum_{j=0}^m b_j r^j \right)
    =    \\ &=
    \sum_{i=0}^n a_i r^i \left( \sum_{j=0}^m b_j r^j \right)
    =    \\ &=
    \sum_{i=0}^n a_i r^i \left( \sum_{j=0}^m b_j r^j \right)
    =    \\ &=
    \sum_{i=0}^n \sum_{j=0}^m a_i r^i b_j r^j
    =    \\ &=
    \sum_{i=0}^n \sum_{j=0}^m a_i b_j r^{i + j}
    =    \\ &=
    \sum_{l=0}^{n + m} \sum_{i+j=l} a_i b_j r^l
    =    \\ &=
    \sum_{l=0}^{n + m} c_l r^l
    =
    \Phi_r(s),
  \end{balign*}
  where we have used that \( a_i = 0, i > n \) and \( b_j = 0, j > m \).

  Thus \( \Phi: R[X] \to \fun(R) \) is indeed a homomorphism of rings.
\end{proof}

\begin{definition}\label{def:formal_power_series}
  If we extend \fullref{def:polynomial} to allow for polynomial with infinite terms (that is, allow for the sequence to have infinitely many nonzero items), we obtain a set \( R\Bracks{X} \) which we call the \term{formal power series} over \( R \).

  Note that the operations in \fullref{def:algebra_of_polynomials} are well defined and still make \( R\Bracks{X} \) into an algebra. Evaluation (see \fullref{thm:polynomial_ring_universal_property} and \fullref{def:polynomial_function}) is problematic, however, since algebraic operations are finitary by nature. In practice, we use a topology over \( R \) and speak of convergent and divergent power series.
\end{definition}

\begin{theorem}[Newton's binomial theorem]\label{thm:binomial_theorem}
  \begin{equation*}
    (X + Y)^n = \sum_{k=0}^n \binom n k X^k Y^{n-k}
  \end{equation*}
\end{theorem}
\begin{proof}
  We use induction\IND on \( n \). For \( n = 0 \), the theorem trivially holds. Assume that the theorem holds for \( 1, \ldots, n \). Then
  \begin{balign*}
    (X + Y)^{n+1}
     & =
    X (X + Y)^n + Y (X + Y)^n
    =    \\ &=
    \sum_{k=0}^n \binom n k X^{k+1} Y^{n-k} + Y \sum_{k=0}^n \binom n k X^k Y^{n-k}
    =    \\ &=
    X^{n+1} + Y \sum_{k=0}^{n-1} \binom n k X^{k+1} Y^{n-(k+1)} + Y \sum_{k=0}^n \binom n k X^k Y^{n-k}
    =    \\ &=
    X^{n+1} + Y \left[ \sum_{k=1}^n \binom n {k-1} X^k Y^{n-k} + Y^n \sum_{k=1}^n \binom n k X^k Y^{n-k} \right] + Y^{n+1}
    =    \\ &\overset {\ref{thm:pascals_identity}} =
    X^{n+1} + Y \sum_{k=1}^n \binom {n+1} k X^k Y^{n-k} + Y^{n+1}
    =    \\ &=
    \sum_{k=0}^n \binom {n+1} k X^k Y^{(n+1)-k}.
  \end{balign*}
\end{proof}

\begin{proposition}\label{thm:xn_minus_one_factorization}
  \begin{equation*}
    X^n - 1 = (X - 1)(X^{n-1} + X^{n-2} + \cdots + 1).
  \end{equation*}
\end{proposition}
\begin{proof}
  Trivial application of induction\IND.
\end{proof}

\begin{proposition}\label{thm:polynomial_root_iff_divisible}
  The value \( u \in R \) is a \hyperref[def:semiring_kernel]{root} of the polynomial function \( p(x) \) if any only if the polynomial \( (X - u) \) divides \( p(X) \).
\end{proposition}
\begin{proof}
  \SufficiencySubProof Suppose that \( u \in R \) is a root of \( p(x) \). By \fullref{thm:euclidean_division_of_polynomials}, we can divide \( p(X) \) by the monic polynomial \( (X - u) \):
  \begin{equation*}
    p(X) = (X - u) q(X) + r(X).
  \end{equation*}

  Assume\LEM that \( r(X) \) is nonzero. Evaluating \( p(X) \) at \( u \) gives us
  \begin{equation*}
    0 = p(u) = (u - u) q(r) + r(u),
  \end{equation*}
  hence \( u \) is a root of \( r(X) \). But \( \deg r < \deg (X - u) = 1 \), that is, \( r \) is a nonzero constant and cannot have roots. The obtained contradiction proves the statement.

  \NecessitySubProof Suppose that \( (X - u) \) divides \( p(X) \) with quotient \( q(X) \). Then
  \begin{equation*}
    p(X) = (X - u) q(X).
  \end{equation*}

  Evaluation at \( u \) gives us
  \begin{equation*}
    p(u) = (u - u) q(u) = 0.
  \end{equation*}

  Therefore \( u \) is a root of \( p(X) \).
\end{proof}

\begin{definition}\label{def:polynomial_root_multiplicity}
  We say that the polynomial \( p \in R[X] \) has the root \( r \in R \) with multiplicity \( m \in \BbbZ_{>0} \) if there exists a polynomial \( q \in R[X] \) of degree \( \deg q = \deg p - m \) such that \( (X - r) \) does not divide \( q(X) \) and
  \begin{equation*}
    p(X) = (X - r)^m q(X).
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:integral_domain_polynomial_root_limit}
  If \( R \) is an integral domain, a nonzero polynomial of degree \( n \) has at most \( n \) (not necessarily \hyperref[def:polynomial_root_multiplicity]{distinct}) roots.
\end{proposition}
\begin{proof}
  We will use induction\IND on \( n \).

  In the case \( n = 0 \), we have that \( p \) is a nonzero constant polynomial. Such a polynomial cannot\LEM have roots, hence the statement holds.

  Now assume that the statement holds for polynomials of degrees \( 1, \ldots, n - 1 \). Let \( p \in R[X] \) be a polynomial of degree \( n \) and let \( r \in R \) be a root of \( p \). \Fullref{thm:polynomial_root_iff_divisible} implies that there exists a polynomial \( q(X) \) of degree \( n - 1 \) such that
  \begin{equation*}
    p(X) = (X - r) q(X).
  \end{equation*}

  Fix \( t \neq r \) that is a not a root of \( q(X) \). Evaluation at \( t \) gives us
  \begin{equation*}
    p(t) = (t - r) q(t).
  \end{equation*}

  Both \( (t - r) \neq 0 \) and \( q(t) \neq 0 \). Since \( R \) has no zero divisors, the product \( p(t) \) of \( (t - r) \) and \( q(t) \) is also nonzero. Thus the only roots of \( p(X) \) are \( r \) and the roots of \( q(X) \).

  By the induction conjecture, \( q(X) \) has at most \( n - 1 \) roots (counting multiplicities). Thus \( p(X) \) has at most \( (n - 1) + 1 = n \) roots.
\end{proof}

\begin{proposition}\label{thm:polynomials_with_identical_values}
  In an integral domain, two polynomials \eqref{eq:thm:polynomial_degree_properties/p} and \eqref{eq:thm:polynomial_degree_properties/q} with \( m \leq n \) are equal (i.e. have the same coefficients) if and only if their functions agree at \( n + 1 \) points.
\end{proposition}
\begin{proof}
  \SufficiencySubProof Obvious

  \NecessitySubProof Define
  \begin{equation*}
    r(X) \coloneqq p(X) - q(X) = \sum_{k=0}^n (a_k - b_k) X^k.
  \end{equation*}

  This is a polynomial of degree at most \( n \) that has \( n + 1 \) roots. By \fullref{thm:integral_domain_polynomial_root_limit}, \( r \) is the zero polynomial. Hence \( p = q \).
\end{proof}

\begin{definition}\label{def:primitive_polynomial}\mcite\cite[394]{Knapp2016BasicAlgebra}
  A nonzero polynomial is called \term{primitive} if its coefficients are \hyperref[def:coprime_ring_ideals]{coprime}.
\end{definition}

\begin{proposition}\label{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials}
  Fix a monic polynomial \( p(X) \in R[X] \) of degree \( n \). The free module \( \pi_n(R[X]) \), as defined in \fullref{def:polynomial_free_module}, is \hyperref[def:equinumerous_sets]{equinumerous} with the quotient ring \( R[X] / \braket{p(X)} \). This allows us to choose a \enquote{canonical representative} of the cosets of the quotient ring in a similar manner to \fullref{thm:cyclic_group_isomorphic_to_integers_modulo_n}.

  Consequently, for different polynomials \( p(X) \), only the ring structure on \( R[X] / \braket{p(X)} \) differs.
\end{proposition}
\begin{proof}
  Euclidean \hyperref[thm:euclidean_division_of_polynomials]{division} allows us to define the homomorphism
  \begin{balign*}
     & \Theta: R[X] / \braket{p(X)} \to \pi_n(R[X])             \\
     & \Theta(q(X) + \braket{p(X)}) \coloneqq \rem(q(X), p(X)).
  \end{balign*}

  It is injective since if \( q_1(X) \) and \( q_2(X) \) are not congruent modulo \( \braket{p(X)} \), they have different remainders. Conversely, \( \Theta \) is surjective because any remainder \( r(X) \) belongs to the coset
  \begin{equation*}
    r(X) + \braket{p(X)}.
  \end{equation*}

  See \fullref{ex:polynomial_quotient_rings_gaussian_integers} and \fullref{ex:polynomial_quotient_rings_z2} for differing ring structures in \( \pi_n(R[X]) \).
\end{proof}

\begin{example}\label{ex:polynomial_quotient_rings_gaussian_integers}
  The value of \fullref{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials} is in that, like \fullref{thm:integers_modulo_isomorphic_to_quotient_group}, it allows us to identify elements of the quotient rings of the form \( R[X] / \braket{p(X)} \), for monic \( p \), with concrete polynomials.

  \Fullref{thm:polynomial_quotient_rings_equinumerous_with_module_of_polynomials} tells us that we can choose a concrete polynomial from \( \pi_{n-1}(R[X]) \) for every equivalence class in \( R[X] / \braket{p(X)} \) and that these polynomials have degree strictly less than \( n \) (if they are not zero).

  For example, consider the polynomial \( p(X) \coloneqq X^2 + 1 \) over the \hyperref[def:integers]{integers} \( \BbbZ \). It has degree \( 2 \), so the quotient ring \( R[X] / \braket{p(X)} \) can be identified with polynomials of the form
  \begin{equation}\label{ex:polynomial_quotient_rings_gaussian_integers/linear_polynomial}
    bX + a
  \end{equation}
  with integer coefficients.

  In order to make sense of the imposed ring structure in \( \BbbZ[X] / \braket{X^2 + 1} \), we can see how multiplication modulo \( X^2 + 1 \) works. We have
  \begin{balign*}
    (bX + a) (dX + c)
     & \cong
    bdX^2 + (ad + bc)X + ac
     & \pmod {X^2 + 1} \cong            \\ &\cong
    bd[X^2 + 1] + [(ad + bc)X - bd + ac]
     & \pmod {X^2 + 1} \cong            \\ &\cong
    (ad + bc)X + (ac - bd)
     & \pmod {X^2 + 1}. \phantom{\cong}
  \end{balign*}

  This is precisely the definition of multiplication of complex numbers (see \fullref{def:complex_numbers}). Thus we can identify
  \begin{equation*}
    \BbbZ[X] / \braket{X^2 + 1} \cong \BbbZ[i].
  \end{equation*}

  Like in \fullref{ex:polynomial_evaluation_gaussian_integers}, we arrive at the Gaussian \hyperref[def:gaussian_integers]{integers}, but using a different approach.
\end{example}

\begin{example}\label{ex:polynomial_quotient_rings_z2}
  Similarly to how the Gaussian integers were identified using \fullref{ex:polynomial_quotient_rings_gaussian_integers}, we will provide a different ring structure on \( \BbbZ[X] / \braket{p(X)} \) for a polynomial \( p(X) \) of degree \( 2 \).

  Consider the polynomial \( p(X) \coloneqq X^2 - 2 \) over the \hyperref[def:integers]{integers} \( \BbbZ \). We know that \( \sqrt 2 \) is a root of \( X^2 - 2 \) in \( \BbbR \) so we can identify
  \begin{equation*}
    \BbbZ[X] / \braket{X^2 - 2} \cong \BbbZ[\sqrt 2].
  \end{equation*}

  We will verify that multiplication is indeed compatible. Multiplication modulo \( X^2 - 2 \) works as follows:
  \begin{balign*}
    (aX + b) (cX + bd)
     & \cong
    acX^2 + (bc + ad)X + bd
     & \pmod X^2 - 2 \cong            \\ &\cong
    ac[X^2 - 2] + [(bc + ad)X + 2ac + bd]
     & \pmod X^2 - 2 \cong            \\ &\cong
    (bc + ad)X + (2ac + bd)
     & \pmod X^2 - 2. \phantom{\cong}
  \end{balign*}

  Multiplication in \( \BbbZ[\sqrt 2] \) works as follows:
  \begin{balign*}
    (a \sqrt 2 + b) (c \sqrt b + d)
    =
    2ac + (bc + ad) \sqrt 2 + bd.
  \end{balign*}

  The two results are identical.
\end{example}

\begin{definition}\label{def:algebraic_derivative}
  Generalizing \fullref{def:differentiability} from analysis, we define the \term{algebraic derivative} of a polynomial \( p(X) \in R[X] \) as
  \begin{equation*}
    p'(X) \coloneqq n a_n X^{n-1} + (n-1) a_{n-1} X^{n-2} + \cdots + a_2 X + a_1.
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:algebraic_derivative_product_rule}
  Algebraic \hyperref[def:algebraic_derivative]{derivatives} satisfy the product rule
  \begin{equation*}
    (pq)' = p'q + pq'.
  \end{equation*}
\end{proposition}
\begin{proof}
  By linearity, it is enough to consider the case where both \( p(X) \) and \( q(X) \) are monomials.

  \begin{balign*}
    p'(X) q(X) + p(X) q'(X)
     & =
    n a_n X^{n-1} b_m X^m + a_n X^n m b_m X^{m-1}
    =    \\ &=
    (n + m) a_n b_m X^{n+m-1}
    =    \\ &=
    (a_n b_m X^{n+m})
    =    \\ &=
    (pq)'(X).
  \end{balign*}
\end{proof}

\begin{proposition}\label{thm:algebraic_derivative_of_linear_polynomial_power}
  The algebraic \hyperref[def:algebraic_derivative]{derivative} of
  \begin{equation*}
    p(X) \coloneqq a (X - u)^n
  \end{equation*}
  is
  \begin{equation*}
    p'(X) = an(X - u)^{n-1}.
  \end{equation*}
\end{proposition}
\begin{proof}
  We use induction\IND on \( n \). The case \( n = 1 \) is obvious. Assume that the statement holds for \( 1, \ldots, n - 1 \).

  By \fullref{thm:algebraic_derivative_product_rule},
  \begin{balign*}
    p'(X)
     & =
    [a(X - u)^{n-1}]' (X - u) + a(X - u)^{n-1} [(X - u)]'
    =    \\ &=
    a(n-1)(X - u)^{n-2} (X - u) + a(X - u)^{n-1}
    =    \\ &=
    an(X - u)^{n-1}.
  \end{balign*}
\end{proof}

\begin{corollary}\label{thm:repeated_root_iff_derivatives_divisible}
  The value \( u \in R \) is a \hyperref[def:semiring_kernel]{root} of multiplicity \( m \) of the polynomial function \( p(x) \) if any only if \( u \) is a root of multiplicity \( m - 1 \) of its algebraic \hyperref[def:algebraic_derivative]{derivative} \( p'(x) \).
\end{corollary}
\begin{proof}
  \SufficiencySubProof Let \( u \) be a root of \( p(X) \) of multiplicity \( m \), i.e. there exists a polynomial \( q(X) \) of degree \( \deg(q) = \deg(p) - m \) such that \( (X - u) \) does not divide \( q(X) \) and
  \begin{equation*}
    p(X) = (X - u)^m q(X).
  \end{equation*}

  By \fullref{thm:algebraic_derivative_product_rule} and \fullref{thm:algebraic_derivative_of_linear_polynomial_power},
  \begin{equation*}
    p'(X)
    =
    m (X - u)^{m-1} q(X) + (X - u)^m q'(X)
    =
    (X - u)^{m-1} [m q(X) + (X - u) q'(X)].
  \end{equation*}

  Then \( u \) is a root of \( p'(X) \) of multiplicity at least \( m - 1 \). Assume\LEM that the multiplicity is at least \( m \), that is,
  \begin{equation*}
    (X - u) \mid [mq(X) + (X - u) q'(X)].
  \end{equation*}

  Since \( X - u \) obviously divides \( (X - u) q'(X) \), then the above implies
  \begin{equation*}
    (X - u) \mid mq(X).
  \end{equation*}

  But this contradicts our choice of \( q(X) \) that does not divide \( (X - u) \).

  The obtained contradiction proves that \( u \) if a root of \( p'(X) \) of multiplicity exactly \( n \).
\end{proof}

\begin{definition}\label{def:multivariate_polynomial}
  We define the \term{multivariate polynomial ring} in \( n \) indeterminates as the \enquote{iterated} single-variable polynomial ring
  \begin{equation*}
    R[X_1, X_2, \ldots, X_n] \coloneqq R[X_1][X_2] \cdots [X_n].
  \end{equation*}

  Note that we are using the letter \( n \) to represent the number of indeterminates rather than the degree of the multivariate polynomial. When we need the degree, we will note it specifically.

  Just like a polynomial \( p(X) \) in one indeterminate is a sequence, that is, a \hyperref[def:topological_net]{net} over \( \BbbZ_{>0} \), each multivariate polynomial \( p(X_1, \ldots, X_n) \) is a map from \( \BbbZ_{>0}^n \) to \( R \) (there is no natural order on \( \BbbZ_{>0}^n \) for defining \( p \) as a net). We can regard it as an \( n \)-dimensional \hyperref[def:array]{array} over \( R \), although arrays are purposely defined to only have finitely many elements, which makes it more difficult to define operations for an arbitrary pair of polynomials. For example, if there are only two variables, multivariate polynomials are \enquote{infinite matrices}
  \begin{equation*}
    p(X_1, X_2) \coloneqq \begin{pmatrix}
      a_{0,0} & a_{0,1} & \cdots \\
      a_{1,0} & a_{1,1} & \cdots \\
      \vdots  & \vdots  & \ddots \\
    \end{pmatrix}
  \end{equation*}
  with only finitely many nonzero elements.

  A \term{monomial} is a polynomial with only one nonzero element. The monomial
  \begin{equation*}
    p(X_1, X_2) \coloneqq \begin{pmatrix}
      0      & 0      & 0      & \cdots \\
      0      & 0      & 0      & \cdots \\
      0      & r      & 0      & \cdots \\
      0      & 0      & 0      & \cdots \\
      \vdots & \vdots & \vdots & \ddots \\
    \end{pmatrix}
  \end{equation*}
  can also be written symbolically as \( p(X_1, X_2) = r X_1^2 X_2 \), with the power for each variable corresponding to the zero-based index of the element along the corresponding axis.

  The sum of the indices over all axes is called the \term{degree} of this monomial. The above monomial has degree \( 3 = 2 + 1 \). We leave the degree for the zero monomial undefined.

  Every polynomial can be regarded as the sum of finitely many monomials by taking each element of the array and putting it in its own monomial array.

  The \term{degree} \( \deg p \) of a multivariate polynomial \( p \) is defined as the maximal degree among all of its nonzero monomials. If all monomials are zero, the degree is left undefined.

  If all nonzero monomials have the same degree, the polynomial is said to be \term{homogeneous}. Homogenous polynomials of degree \( 1 \) are called \term{linear}.
\end{definition}

\begin{theorem}\label{thm:polynomial_embedding_behavior}
  Let \( \mscrR \) be an integral domain and \( \xi \coloneqq \min \{ \card(\mscrR), \aleph_0 \} \).

  \begin{thmenum}
    \ilabel{thm:polynomial_embedding_behavior/zero} The only polynomial corresponding to the zero function \( f(x) = 0 \) is the zero polynomial.

    \ilabel{thm:polynomial_embedding_behavior/univariate} Let \( p(X) \) be a nonzero polynomial and let \( \Phi(p) \) is its polynomial function. Then there exists exactly one polynomial \( q(X) \) of degree \( \deg(p) < \xi \) such that \( \Phi(q) = \Phi(p) \).

    \ilabel{thm:polynomial_embedding_behavior/multivariate} Let \( p(X_1, \ldots, X_n) \) be a nonzero multivariate polynomial and let \( \Phi(p) \) be its polynomial function. Then there exists exactly one polynomial \( q(X_1, \ldots, X_n) \) such that the power of every variable in every monomial is strictly less than \( \xi \) and \( \Phi(q) = \Phi(p) \).
  \end{thmenum}
\end{theorem}
\begin{proof}
  \SubProofOf{thm:polynomial_embedding_behavior/zero} The nonzero constant polynomials are obviously different from the zero function. The nonconstant polynomials should have at least one value different from zero, hence are again different from the zero function.

  Therefore only the zero polynomial gives rise to the zero function.

  \SubProofOf{thm:polynomial_embedding_behavior/univariate} In the univariate case, by \fullref{thm:polynomials_with_identical_values}, two nonzero polynomials of degree less than \( \xi \) are equal if and only if they agree at \( \xi \) points.

  If \( \deg(p) < \xi \), which is automatically true if \( \mscrR \) is an infinite ring, then \( q \coloneqq p \) is the desired polynomial. It is unique by the previous paragraph.

  If \( \deg(p) \geq \xi \), which is only possible if \( \mscrR \) is a finite ring, we can easily give a non-constructive proof in the general case. \Fullref{alg:finite_field_polynomial_reduction} gives a concrete procedure for finding \( q \) in the case of certain Galois fields.

  If \( \mscrR \) is finite, both the \hyperref[def:polynomial_free_module]{polynomial free module} \( \pi_{\xi - 1} \) and the \hyperref[thm:functions_over_ring_form_algebra]{function space} \( \fun(\mscrR) \) have exactly \( \xi^\xi \) elements. Furthermore, by the first paragraph of the proof, two distinct polynomials in \( \pi_{\xi - 1} \) give rise to distinct functions. Therefore the evaluation \( \Phi: \pi_{\xi - 1} \to \fun(\mscrR) \) is an injective function between finite sets of the same cardinality. It is therefore a bijection. That is, to each endofunction over \( \mscrR \), in particular to \( \Phi(p) \), there corresponds a unique univariate polynomial over \( \mscrR \) of degree less than \( \xi \).

  \SubProofOf{thm:polynomial_embedding_behavior/multivariate} As in the univariate case, if \( \mscrR \) is infinite, the statement trivially holds.

  Assume that \( \mscrR \) is a finite ring. A simple counting argument shows that the vector spaces \( \fun(\mscrR^n, \mscrR) \) and
  \begin{equation*}
    \mscrL \coloneqq \linspan \{ X_1^{k_1} \cdots X_n^{k_n} \colon k_j = 1, \ldots, \xi \T{for} j = 1, \ldots, n \}
  \end{equation*}
  have exactly \( \xi^{\xi^n} \) vectors.

  We must, therefore, only show that \( \Phi \) is injective on \( \mscrL \).

  We use induction on the number of variables. We already showed injectivity for one variable and we now assume that the statement is true for all polynomials with (strictly) less than \( n \) variables.

  Assume\LEM that \( \Phi \) is not injective for polynomials in \( n \) variables. Then there exist polynomials \( f, g \in \mscrL \) such that \( r \coloneqq f - g \) is nonzero and yet \( \Phi(r) = 0 \). We know that
  \begin{equation*}
    f \in \mscrR[X_1, \ldots, X_n] = \mscrR[X_1, \ldots, X_{n-1}][X_n],
  \end{equation*}
  hence
  \begin{equation*}
    f(X_1, \ldots, X_n) = \sum_{k=0}^{q-1} f_k(X_1, \ldots, X_{n-1}) X_n^k,
  \end{equation*}
  where \( f_k(X_1, \ldots, X_{n-1}) \in \mscrL \) satisfy the inductive conjecture and analogously for \( g \).

  Then, since \( \Phi \) is a homomorphism,
  \begin{equation*}
    \Phi(r(X_1, \ldots, X_n)) = \sum_{k=0}^{q-1} \Phi(f_k(X_1, \ldots, X_{n-1}) - g_k(X_1, \ldots, X_{n-1})) \Phi(X_n^k) = 0.
  \end{equation*}

  By the inductive conjecture, the vectors \( \Phi[f_k - g_k], k = 0, \ldots, q - 1 \) are linearly independent. Therefore \( \Phi[r(X_1, \ldots, X_n)] = 0 \) if and only if \( \Phi(X_n^k) = 0 \) for all \( k = 0, \ldots, q - 1 \). But evaluating \( \Phi_t(X_n) \) would give \( t \), which may be nonzero, hence \( \Phi(X_n) \) is necessarily a nonzero function.

  Hence \( \Phi(r) \) is a nonzero function as a nontrivial combination of linearly independent nonzero functions. But this contradicts our assumption that \( f \neq g \). Therefore \( \Phi \) is injective over \( \mscrL \).

  Therefore, as in the univariate case, to each function from \( \fun(\mscrR^n, \mscrR) \), in particular to \( \Phi(p) \), there corresponds a unique polynomial from \( \mscrL \).
\end{proof}

\begin{definition}\label{def:rational_algebraic_function}
  We denote the field of \hyperref[def:field_of_fractions]{fractions} of \( R[X_1, \ldots, X_n] \) by \( R(X_1, \ldots, X_n) \) and call it the field of \term{rational algebraic functions}.
\end{definition}

\begin{definition}\label{def:laurent_polynomial}
  We generalize \hyperref[def:polynomial]{polynomials} by allowing negative coefficients.

  \begin{thmenum}
    \ilabel{def:laurent_polynomial/polynomial} A \term{Laurent polynomial} over \( R \) is, formally, a \hyperref[def:topological_net]{net} with finite support over the integers \( \BbbZ \) rather than a net over \( \BbbZ_{\geq 0} \) (i.e. the nonnegative integers). The operations \fullref{def:algebra_of_polynomials} make the Laurent polynomials into a ring, which we denote by \( R[X^\pm] \). This notation is consistent with \fullref{thm:polynomial_ring_universal_property}. Note that
    \begin{equation*}
      R[X^\pm] \cong R[X, X^{-1}] \cong R[X, Y] / (XY - 1),
    \end{equation*}
    so all three notations are used.

    The terms \enquote{\hyperref[def:polynomial/degree]{degree}} and \enquote{\hyperref[def:polynomial/leading_coefficient]{leading coefficient}} do not generalize naturally so we leave them undefined.

    We use the notation
    \begin{equation*}
      p(X) = \sum_{k \in \BbbZ} a_k X^k = \sum_{k=-\infty}^\infty a_k X^k.
    \end{equation*}

    \ilabel{def:laurent_polynomial/multivariate} Analogously to \fullref{def:multivariate_polynomial}, we define the ring of multivariate Laurent polynomials \( R[X_1^\pm, \ldots, X_n^\pm] \) as maps from \( \BbbZ^n \) to \( R \) rather than from \( \BbbZ \) to \( R \) or, inductively, as
    \begin{equation*}
      R[X_1^\pm, \ldots, X_n^\pm] = R[X_1^\pm, \ldots, X_{n-1}^\pm][X_n^\pm]
    \end{equation*}

    \ilabel{def:laurent_polynomial/series} A \term{formal Laurent series} is simply a Laurent polynomial in which we remove the restriction of only finitely many nonzero coefficients. We denote the set of all formal Laurent series over \( R \) by \( R\Bracks{X^\pm} \).
  \end{thmenum}
\end{definition}
