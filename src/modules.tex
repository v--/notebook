\subsection{Modules}\label{subsec:modules}

\begin{definition}\label{def:left_module}
  Let \( R \) be a \hyperref[def:semiring/dioid]{dioid} and \( M \) be an abelian group. Analogously to \fullref{def:left_monoid_action}, we say that \( M \) is a left \( R \)-\term{module} if it has some additional structure, which can be defined equivalently as
  \begin{thmenum}
    \thmitem{def:left_module/homomorphism} a dioid homomorphism from \( R \) to the endomorphism \hyperref[def:endomorphism_dioid]{ring} \( \End(M) \)

    \thmitem{def:left_module/multiplication}\cite[374]{Knapp2016BasicAlgebra} an \hyperref[def:magma/associative]{associative} and \hyperref[def:unital_magma]{unital} \hyperref[def:left_monoid_action/operation]{operation} \( \cdot: R \times M \to M \), written using juxtaposition.

    We require that \( \cdot \) is associative, distributive over \( + \), and compatible with the identity in \( R \). Explicitly, the following are satisfied for \( x, y \in M \) and \( s, t \in R \):
    \begin{thmenum}
      \thmitem{def:left_module/associativity}(associativity) \( s \cdot (t \cdot x) = (s t) \cdot x \).
      \thmitem{def:left_module/scalar_distributivity}(scalar distributivity) \( (s + t) \cdot x = s \cdot x + t \cdot x \).
      \thmitem{def:left_module/vector_distributivity}(vector distributivity) \( t \cdot (x + y) = t \cdot x + t \cdot y \).
      \thmitem{def:left_module/identity}(identity) \( 1_R \cdot x = x \).
    \end{thmenum}
  \end{thmenum}

  In analogy with \hyperref[def:vector_space]{vector spaces}, we call elements of \( R \) scalars and elements of \( M \) vectors. See \fullref{def:vector_space}.

  We denote the category of modules over \( R \) by \( \cat{Mod}_R \).
\end{definition}
\begin{proof}
  \ImplicationSubProof{def:left_module/homomorphism}{def:left_module/multiplication} Let \( \tau: R \to \End(M) \) be a ring homomorphism. Define the operation
  \begin{balign*}
     & \cdot: R \times M \to M           \\
     & \cdot(r, m) \coloneqq \tau(r)(m).
  \end{balign*}

  Let \( x, y \in M \) and \( s, t \in R \). From the fact that \( \tau \) is a ring homomorphism, we have
  \SubProofOf{def:left_module/associativity}
  \begin{equation*}
    s \cdot (t \cdot x)
    =
    \tau(s)(\tau(t)(x))
    =
    (\tau(s) \circ \tau(t))(x)
    =
    \tau(st)(x).
  \end{equation*}

  \SubProofOf{def:left_module/scalar_distributivity}
  \begin{equation*}
    (s + t) \cdot x
    =
    \tau(s + t)(x)
    =
    \tau(s)(x) + \tau(t)(x)
    =
    s \cdot x + t \cdot x.
  \end{equation*}

  \SubProofOf{def:left_module/vector_distributivity}
  \begin{equation*}
    t \cdot (x + y)
    =
    \tau(t)(x + y).
  \end{equation*}

  Now since \( \tau(t) \) is a group endomorphism, we have \( \tau(t)(x + y) = \tau(t)(x) + \tau(t)(y) \). Thus,
  \begin{equation*}
    t \cdot (x + y)
    =
    t \cdot x + t \cdot y.
  \end{equation*}

  \SubProofOf{def:left_module/identity}
  \begin{equation*}
    1_R \cdot x
    =
    \tau(1_R)(x)
    =
    \id(x)
    =
    x.
  \end{equation*}

  \ImplicationSubProof{def:left_module/multiplication}{def:left_module/homomorphism} Let \( \cdot: R \times M \to M \) be a left scalar multiplication operation. We define
  \begin{balign*}
     & \tau: R \to \End(M)                      \\
     & \tau(t) \coloneqq (x \mapsto t \cdot x).
  \end{balign*}

  This function is well-defined since for each \( t \in R \), the function \( \tau(t) \) is an abelian group homomorphism (due to \fullref{def:left_module/associativity}).

  \( \tau \) is a ring homomorphism because
  \begin{itemize}
    \item it preserves addition:
          \begin{equation*}
            \tau(s + t)
            =
            (x \mapsto (s + t) \cdot x)
            =
            (x \mapsto s \cdot x + t \cdot x)
            =
            \tau(s) + \tau(t).
          \end{equation*}

    \item it preserves multiplication:
          \begin{equation*}
            \tau(st)
            =
            (x \mapsto (st) \cdot x)
            =
            (x \mapsto (s \cdot (t \cdot x)))
            =
            \tau(s) \circ \tau(t).
          \end{equation*}

    \item it preserves identities:
          \begin{equation*}
            \tau(1_R)
            =
            \id,
          \end{equation*}
          which is the multiplicative unit in \( \End(M) \).
  \end{itemize}
\end{proof}

\begin{definition}\label{def:right_module}
  We say that \( \tau: R \to \End(A) \) is a \term{right \( R \)-module} if the same function is a \hyperref[def:left_module]{left module} on the opposite \hyperref[def:opposite_ring]{ring} \( R^{-1} \).
\end{definition}

\begin{definition}\label{def:bimodule}
  An abelian group \( M \) that is both a left \( L \)-module and right \( R \)-module is called an \( L, R \)-\term{bimodule} if \( l \in L, r \in R \) and \( x \in M \) implies
  \begin{equation*}
    (lx)r = l(xr).
  \end{equation*}
\end{definition}

\begin{proposition}\label{thm:def:left_module/properties}
  Any left \( R \)-module \( M \) has the following basic properties:
  \begin{thmenum}
    \thmitem{thm:def:left_module/properties/ring_zero_is_absorbing} Multiplication by \( 0_R \) is \term{absorbing}, that is, \( 0_R x = 0_M \) for any \( x \in M \).

    \thmitem{thm:def:left_module/properties/module_zero_is_absorbing} Multiplication by \( 0_M \) is absorbing, that is, \( t 0_M = 0_M \) for any \( t \in R \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{thm:def:left_module/properties/ring_zero_is_absorbing} For any \( x \in M \) we have that \( 0_R x = (0_R + 0_R)x = 0_R x + 0_R x \), thus \( 0_R x \) is an additive identity and \( 0_R x = 0_M \).

  \SubProofOf{thm:def:left_module/properties/module_zero_is_absorbing} For any \( t \in R \) we have that \( t 0_M = t (0_M + 0_M) = t 0_M + t 0_M \), thus \( t 0_M \) is an additive identity and \( t 0_M = 0_M \).
\end{proof}

\begin{example}\label{ex:module/ideal_of_ring}
  Every unital ring \( R \) is a module over itself. Every ideal \( I \subseteq R \) is an \( R \)-module since it is closed under multiplication with \enquote{scalars} from \( R \).
\end{example}

\begin{definition}\label{def:left_module_kernel}
  The \term{kernel} \( \ker(f) \) of a left \( R \)-module homomorphism \( f: M \to N \) is the zero \hyperref[def:zero_locus]{locus} of \( f \), that is, \hyperref[thm:def:function/properties/preimage]{preimage} \( f^{-1}(0_N) \).

  It is an instance of \fullref{def:zero_morphisms/kernel}.
\end{definition}

\begin{definition}\label{def:quotient_left_module}
  Let \( M \) be a left module and \( N \) be a submodule of \( M \). Define the \term{quotient module}
  \begin{equation*}
    M / N \coloneqq \{ x + N \colon x \in M \}
  \end{equation*}
  with the operations
  \begin{balign*}
    x + N \oplus y + N \coloneqq x + y + N.
    t \odot x + N \coloneqq tx + N.
  \end{balign*}

  Define the canonical projection homomorphism
  \begin{balign*}
     & \pi: G \to G / N        \\
     & \pi(x) \coloneqq x + N.
  \end{balign*}

  The kernel of \( \pi \) is precisely \( N \).
\end{definition}
\begin{proof}
  The proof of correctness is similar to \fullref{def:quotient_group}.
\end{proof}

\begin{theorem}\label{thm:homomorphism_theorem_for_left_modules}
  Fix a ring \( R \). Let \( \varphi: M \to K \) be a homomorphism of left \( R \)-modules. We have the isomorphism
  \begin{equation*}
    M / \ker \varphi \cong \img \varphi.
  \end{equation*}
\end{theorem}
\begin{proof}
  Analogous to \fullref{thm:homomorphism_theorem_for_groups}.
\end{proof}

\begin{definition}\label{def:linear_operator}
  Let \( M \) and \( N \) be two left \( R \)-modules. We say that the function \( f: M \to N \) is \term{linear} or a \term{linear operator} if it satisfies the conditions
  \begin{thmenum}
    \thmitem{def:linear_operator/additivity}(additivity) \( f(x + y) = f(x) + f(y) \) for any \( x, y \in M \).
    \thmitem{def:linear_operator/homogeneity}(homogeneity) \( f(tx) = t f(x) \) for any \( t \in R \) and \( x \in M \) (see \fullref{def:homogenous_function}).
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:map_is_linear_iff_homomorphism}
  A function \( f: M \to N \) between left \( R \)-modules is \hyperref[def:linear_operator]{linear} if and only if it is a module homomorphism in the sense of \fullref{def:first_order_homomorphism}.
\end{proposition}
\begin{proof}
  Since \( (M, +) \) and \( (N, +) \) are groups, it follows from \fullref{thm:group_homomorphism_single_condition} that \fullref{def:linear_operator/additivity} is equivalent to the requirement that \( f \) is a homomorphism between \( (M, +) \) and \( (N, +) \).

  Now fix \( t \in R \). For \( f \) to be a homomorphism, it must satisfy
  \begin{equation*}
    f(\cdot_M^{(t)}(x)) = \cdot_t^{(N)}(f(x)),
  \end{equation*}
  which is just a more formal way to write \fullref{def:linear_operator/homogeneity}.
\end{proof}

\begin{definition}\label{def:affine_operator}
  Let \( M \) and \( N \) be two left \( R \)-modules. We say that the function \( f: M \to N \) is \term{affine} if it is a translation of a \hyperref[def:linear_operator]{linear function}, that is, if there exists a linear function \( l: M \to N \) and a constant \( a \in N \) such that \( f(x) = l(x) + a \).
\end{definition}

\begin{definition}\label{def:multilinear_function}
  Generalizing \fullref{def:linear_operator}, if \( M_1, \ldots, M_k \) and \( N \) are \( R \)-modules, we say that the function
  \begin{equation*}
    f: M_1 \times \ldots \times M_k \to N
  \end{equation*}
  is \term{multilinear} or \term{\( k \)-linear} (\term{bilinear} for \( k = 2 \), \term{trilinear} for \( k = 3 \)) if it is linear in each component, that is, for each component \( i = 1, \ldots, k \), and for each tuple not containing elements from \( M_i \),
  \begin{equation*}
    (u_1, \ldots, u_{i-1}, u_{i+1}, \ldots, u_k) \in M_1 \times \ldots \times M_{i-1} \times M_{i+1} \times \ldots \times M_k \to N
  \end{equation*}
  the following function is linear:
  \begin{balign*}
     & f_i: M_i \to N                                                         \\
     & f_i(u_i) \coloneqq f(u_1, \ldots, u_{i-1}, u_i, u_{i+1}, \ldots, u_k).
  \end{balign*}
\end{definition}

\begin{definition}\label{def:abelian_group_z_module}\mcite[375]{Knapp2016BasicAlgebra}
  Let \( G \) be an abelian group. Associate with \( G \) the \( \BbbZ \)-module \( M \) with scalar multiplication
  \begin{balign*}
    nu \coloneqq \begin{cases}
      0,              & n = 0  \\
      u + \ldots + u, & n > 0  \\
      -((-n)u),       & n < 0.
    \end{cases}
  \end{balign*}
\end{definition}

\begin{proposition}\label{thm:abelian_group_iff_z_module}\mcite[375]{Knapp2016BasicAlgebra}
  Every abelian group is isomorphic to exactly one \( \BbbZ \)-module.
\end{proposition}
\begin{proof}
  We already saw in \fullref{def:abelian_group_z_module} how every abelian group can be regarded as a \( \BbbZ \)-module. Every \( \BbbZ \)-module can then be identified with its additive group.

  Scalar multiplication ensures that there is exactly one way to define a \( \BbbZ \)-module structure on an abelian group since \( na = (n-1)a + a \) and \( 0a = 0 \).
\end{proof}

\begin{definition}\label{def:left_module_direct_product}
  Let \( \{ X_k \}_{k \in \mscrK} \) be a nonempty family of left \( R \)-modules.

  Analogously to \fullref{def:group_direct_product}, we define their \term{direct product} as the module \( \prod_{k \in \mscrK} X_k \), the operations defined componentwise as
  \begin{balign*}
     & \{ x_k \}_{k \in \mscrK} + \{ y_k \}_{k \in \mscrK}
    \coloneqq
    \{ x_k + y_k \}_{k \in \mscrK},                     \\
     & t \{ x_k \}_{k \in \mscrK}
    \coloneqq
    t \{ t x_k \}_{k \in \mscrK}.
  \end{balign*}

  We define their \term{direct sum} as the submodule of \( \prod_{k \in \mscrK} X_k \) (see \fullref{def:left_module_direct_product}) where only finitely many components of any module element are different from zero.
\end{definition}

\begin{proposition}\label{thm:module_categorical_limits}
  We are interested in \hyperref[def:category_of_cones/limit]{categorical limits} and \hyperref[def:category_of_cones/colimit]{colimits} in the category \( \cat{Mod}_R \) of left-modules over \( R \). Fix an indexed family  \( \{ X_k \}_{k \in \mscrK} \) of \( R \)-modules.
  \begin{thmenum}
    \thmitem{thm:module_categorical_limits/product} Their \hyperref[def:discrete_category_limits]{categorical product} is their direct \hyperref[def:left_module_direct_product]{product} \( \prod_{k \in \mscrK} X_k \), the projection morphisms being inherited from \fullref{thm:discrete_category_limits_in_set}.

    \thmitem{thm:module_categorical_limits/coproduct} Their \hyperref[def:discrete_category_limits]{categorical coproduct} is the \hyperref[def:group_direct_product]{direct sum} \( \oplus_{k \in \mscrK} X_k \), the embedding morphisms being inherited from \fullref{thm:abelian_group_categorical_limits/coproduct}.
  \end{thmenum}
\end{proposition}

\begin{definition}\label{def:linear_combination}
  Let \( M \) be a left \( R \)-module. Like \hyperref[def:polynomial]{polynomials}, we define linear combinations to be tuples \( (t_1, t_2, \ldots, t_n) \) of scalars from \( R \). Unlike with polynomials, we are not interested in defining operations on them, but rather defining the function
  \begin{equation}\label{def:linear_combination/function}
    (x_1, \ldots, x_n) \mapsto \sum_{k=1}^n t_k x_k.
  \end{equation}

  The scalars \( t_1, \ldots, t_n \) are called the \term{coefficients} of the linear combination. A linear combination is said to be \term{trivial} if all coefficients are equal to \( 0_R \).

  For convenience, given set of vectors \( x_1, \ldots, x_n \in M \), we also call the sum \( \sum_{k=1}^n t_k x_k \) a linear combination.

  In the special case where \( R \) is a superring of \( \BbbR \), we define the following special types of linear combinations:
  \begin{thmenum}
    \thmitem{def:linear_combination/affine} an \term{affine combination} if \( \sum_{k=1}^n t_k = 1 \).
    \thmitem{def:linear_combination/conic} a \term{conic combination} if all of the coefficients are nonnegative real numbers.
    \thmitem{def:linear_combination/convex} a \term{convex combination} if it is both affine and conic.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:left_module_linear_dependence}
  Let \( M \) be a left \( R \)-module and let \( A \subseteq M \). We say that the set \( A \) is \term{linearly independent} if for any linear \hyperref[def:linear_combination/function]{combination}, the equality
  \begin{equation*}
    \sum_{i=1}^n t_i x_k = 0_M
  \end{equation*}
  for \( x_1, \ldots, x_n \in A \) implies that the combination is trivial.

  We say that the vectors \( x_1, \ldots, x_n \) are linearly independent if the corresponding set \( \{ x_1, \ldots, x_n \} \) is linearly independent.

  We say that \( A \) is \term{linearly dependent} if it is not linearly independent.
\end{definition}

\begin{definition}\label{def:left_module_hamel_basis}
  A subset \( B \) of the left \( R \)-module \( M \) is called a \term{Hamel basis} or simply \term{basis} of \( M \) if \( B \) is a \hyperref[def:partially_ordered_set_extremal_points/maximal_and_minimal_element]{minimal} (with respect to set inclusion) linearly independent subset of \( M \).
\end{definition}

\begin{definition}\label{def:free_left_module}\mcite[377]{Knapp2016BasicAlgebra}
  We say that the left \( R \)-module \( M \) is a \term{free left module} if it has a \hyperref[def:left_module_hamel_basis]{basis}.

  Let \( S \) be any set. If we regard \( R \) as a left module over itself, then the \hyperref[thm:module_categorical_limits/coproduct]{direct sum}
  \begin{equation*}
    F(S) \coloneqq \oplus_{s \in S} R
  \end{equation*}
  with injections \( \{ \iota_s \}_{s \in S} \) is called the free left module \term{generated by \( S \)}. Define the function
  \begin{balign*}
     & \varphi: S \to F(S)                \\
     & \varphi(s) \coloneqq \iota_s(1_R).
  \end{balign*}

  The image \( \varphi(S) \) is then a basis of \( F(S) \).

  The cardinality of the basis of a free left module \( M \) is called the \term{rank} \( \rank M \) of \( M \). \Fullref{thm:left_module_basis_cardinality} tells us that this rank is unique for commutative unital rings. If the rank of a module is finite, we say that the module is \term{finitely generated}.

  We also denote \( F(S) = \braket S \), especially in finitely generated modules.
\end{definition}

\begin{proposition}\label{thm:free_module_is_free_functor}
  The functor \( F: \cat{Set} \to \cat{Mod}_R \), defined pointwise in \fullref{def:free_left_module}, is \hyperref[def:category_adjunction]{free}.
\end{proposition}

\begin{proposition}\label{thm:left_module_basis_decomposition}
  Let \( B \) be a basis of the free left \( R \)-module \( M \). Then each element \( u \) of \( M \) can be uniquely (up to a permutation) represented as a linear \hyperref[def:linear_combination]{combination} of elements of \( B \).
\end{proposition}
\begin{proof}
  Let
  \begin{equation*}
    u = \sum_{i=1}^n t_i v_i
  \end{equation*}
  and
  \begin{equation*}
    u = \sum_{j=1}^m s_i w_i
  \end{equation*}
  be two representations of \( u \) as a linear combination over \( B \).

  Define the function
  \begin{balign*}
     & t: M \to R                                \\
     & t(v) \coloneqq \begin{cases}
      t_i, & v = v_i,                          \\
      0,   & v \not\in \{ v_1, \ldots, v_n \}.
    \end{cases}
  \end{balign*}
  and analogously for \( s: M \to R \). Define the set
  \begin{equation*}
    B' \coloneqq \{ v_1, \ldots, v_n, w_1, \ldots, w_m \}.
  \end{equation*}

  Thus,
  \begin{equation*}
    u = \sum_{b \in B'} t(b) b = \sum_{b \in B'} s(b) b
  \end{equation*}
  and
  \begin{equation*}
    0 = u - u = \sum_{b \in B'} (t(b) - s(b)) b.
  \end{equation*}

  The set \( B' \) is linearly independent as a subset of the basis \( B \), hence only a trivial linear combination can be the zero vector. This gives us
  \begin{equation*}
    t(b) = s(b), b \in B'.
  \end{equation*}

  In particular, the two decompositions of \( u \) along \( B \) are identical up to a permutation.
\end{proof}

\begin{definition}\label{def:left_module_basis_projection}
  Let \( M \) be a left \( R \)-module and let \( B \) be a basis of \( M \). For each \( b \in B \), we define the \text{coordinate projection functional} \( \pi_b: M \to R \) that gives us the unique coefficient in the basis decomposition. Thus, for every \( x \in M \) we have
  \begin{equation*}
    x = \sum_{b \in B} \pi_b(x) b.
  \end{equation*}

  The sum is well-defined since only finitely many terms are nonzero.

  When the basis \( B \) is finite and ordered:
  \begin{equation*}
    B = \{ b_1, \ldots, b_n \},
  \end{equation*}
  we also write
  \begin{equation*}
    x = \sum_{i=1}^n x_k b_i.
  \end{equation*}
\end{definition}
\begin{proof}
  By \fullref{thm:left_module_basis_decomposition}, this decomposition is unique given a basis \( B \).
\end{proof}

\begin{proposition}\label{thm:left_module_basis_projections_are_linear}
  The basis projection \hyperref[def:left_module_basis_projection]{maps} are linear.
\end{proposition}
\begin{proof}
  \SubProofOf{def:linear_operator/homogeneity} Let \( t \in R \) and \( x \in M \). We have the unique decompositions
  \begin{balign*}
    x  & = \sum_{b \in B} \pi_b(x) b,  \\
    tx & = \sum_{b \in B} \pi_b(tx) b.
  \end{balign*}

  Since both decompositions have only finitely many terms, their difference also has only finitely many nonzero terms. Thus,
  \begin{equation*}
    0
    =
    tx - tx
    =
    t \left( \sum_{b \in B} \pi_b(x) b \right) - \sum_{b \in B} \pi_b(tx) b
    =
    \sum_{b \in B} (t \pi_b(x) - \pi_b(tx)) b.
  \end{equation*}

  Since the vectors in \( B \) are linearly independent, no nontrivial linear combination can equal the zero vector. Thus, for all \( b \in B \),
  \begin{equation*}
    t \pi_b(x) = \pi_b(tx).
  \end{equation*}

  \SubProofOf{def:linear_operator/additivity} Analogous.
\end{proof}

\begin{theorem}\label{thm:linear_map_iff_function_on_basis}
  Let \( M \) and \( N \) be left \( R \)-modules and let \( B \) be a basis of \( M \). Then there exists a bijection between the \hyperref[def:function]{functions} from \( B \) to \( N \) and the module \hyperref[def:linear_operator]{homomorphisms} from \( M \) to \( N \), such that each linear map is an \hyperref[def:multi_valued_function/restriction]{extension} of the corresponding function.
\end{theorem}
\begin{proof}
  Let \( \varphi: M \to N \) be a homomorphism. Define the function
  \begin{balign*}
     & f: B \to N                 \\
     & f(b) \coloneqq \varphi(b).
  \end{balign*}

  Now define the linear map
  \begin{balign*}
     & \hat \varphi: M \to N                                   \\
     & \hat \varphi(x) \coloneqq \sum_{b \in B} \pi_b(x) f(b).
  \end{balign*}

  Since the projections \( \pi_b(x) \) are linear functions by \fullref{thm:left_module_basis_projections_are_linear} and since we only use the value of \( f \) on fixed vectors, it follows that \( \hat \varphi \) is also linear.

  It remains to show that \( \varphi = \hat \varphi \). For each \( x \in M \), by linearity of \( \varphi \) we have
  \begin{equation*}
    \hat \varphi(x)
    =
    \sum_{b \in B} \pi_b(x) f(b)
    =
    \sum_{b \in B} \pi_b(x) \varphi(b)
    =
    \varphi(x).
  \end{equation*}
\end{proof}

\begin{remark}\label{rem:linear_map_iff_function_on_basis}
  \Fullref{thm:linear_map_iff_function_on_basis} is very powerful in that is allows to study linear maps given their value at only a small subset of vectors. The connection between multilinear \hyperref[def:multilinear_function]{maps} and \hyperref[def:left_module_tensor_product]{tensors} is based on this idea.
\end{remark}

\begin{corollary}\label{thm:linear_maps_agree_on_free_module_if_they_agree_on_basis}
  If two linear maps from the free left module \( M \) to \( N \) agree on a basis of \( M \), they agree on the whole module.
\end{corollary}

\begin{proposition}\label{thm:left_module_basis_cardinality}\mcite{ProofWiki:bases_of_free_module_have_same_cardinality}
  All bases in a free left module over a commutative unital ring have the same cardinality.
\end{proposition}

\begin{definition}\label{def:left_module_tensor_product}\mcite[574]{Knapp2016BasicAlgebra}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module. Define the free \hyperref[def:free_abelian_group]{abelian group} \( G \) generated by the basis \( M \times N \), that is,
  \begin{equation*}
    G \coloneqq \oplus_{(m,n) \in M \times N} \BbbZ.
  \end{equation*}

  Denote by \( e_{m,n} \) the \( (m,n) \)-th basis vector and by \( t_{m,n} \) the \( (m,n) \)-th coordinate of \( t \in G \) (we can have only a finite amount of nonzero coordinates since \( G \) is a direct sum).

  We can regard \( G \) as a left \( R \)-module with scalar multiplication given by
  \begin{equation*}
    (r t)_{(m,n)} \coloneqq t_{(rm,n)}.
  \end{equation*}

  Let \( H \) be the submodule of \( G \) generated by
  \begin{itemize}
    \item \( e_{(m_1 - m_2, n)} - e_{(m_1,n)} - e_{(m_2,n)} \), \( m_1, m_2, n \in G \)
    \item \( e_{(m, n_1 - n_2)} - e_{(m,n_1)} - e_{(m,n_2)} \), \( m, n_1, n_2 \in G \)
    \item \( e_{(rm,n)} - e_{(m,rn)} \), \( m, n \in G \) and \( r \in R \)
  \end{itemize}

  Define the \term{tensor product} of \( M \) and \( N \) to be the \( R \)-module
  \begin{equation*}
    M \otimes N \coloneqq G / H.
  \end{equation*}
\end{definition}

\begin{theorem}\label{thm:tensor_product_universal_property}\mcite[thm. 10.18]{Knapp2016BasicAlgebra}
  Let \( R \) be a unital ring. Let \( M \) be a right \( R \)-module and \( N \) be a left \( R \)-module and let \( M \otimes N \) be their \hyperref[def:left_module_tensor_product]{tensor product} with \( q: M \times N \to M \otimes N \) being the corresponding quotient map.

  The tensor product \( M \otimes N \) satisfies the following universal mapping property: for every \( R \)-module \( K \) and any bilinear \hyperref[def:multilinear_function]{map} \( f: M \times N \to K \) there exists a unique map \( \hat f: M \otimes N \to K \) such that
  \begin{equation*}
    f = \hat f \circ q,
  \end{equation*}
  that is, the following diagram commutes:

  \begin{alignedeq}\label{thm:tensor_product_universal_property/diagram}
    \text{\todo{Add diagram}}\iffalse\begin{mplibcode}
      beginfig(1);
      input metapost/graphs;

      v1 := thelabel("$M \times N$", origin);
      v2 := thelabel("$M \otimes N$", (2, 0) scaled u);
      v3 := thelabel("$K$", (1, -1) scaled u);

      a1 := straight_arc(v1, v2);
      a2 := straight_arc(v2, v3);
      a3 := straight_arc(v1, v3);

      draw_vertices(v);
      draw_arcs(a);

      label.top("$q$", straight_arc_midpoint of a1);
      label.lrt("$\hat f$", straight_arc_midpoint of a2);
      label.llft("$f$", straight_arc_midpoint of a3);
      endfig;
    \end{mplibcode}\fi
  \end{alignedeq}
\end{theorem}

\begin{proposition}\label{thm:tensor_product_with_underlying_ring}\mcite[677]{Knapp2016BasicAlgebra}
  Let \( R \) be a unital ring (regarded as a right module) and \( B \) be a left \( R \)-module. Their \hyperref[def:left_module_tensor_product]{tensor product} satisfies
  \begin{equation*}
    R \otimes M \cong M.
  \end{equation*}
\end{proposition}

\begin{definition}\label{def:algebra_over_ring}\mcite[408]{Knapp2016BasicAlgebra}
  Let \( R \) be a commutative unital ring. We say that the left \( R \)-module \( A \) is an \( R \)-\term{algebra} if we define an additional bilinear \term{vector multiplication} operation
  \begin{equation*}
    \odot: A \times A \to A
  \end{equation*}
  such that for \( x, y \in M \) and \( t \in R \)
  \begin{equation*}
    t \cdot (x \odot y) = (t \cdot x) \odot y = x \odot (t \cdot y).
  \end{equation*}

  Both vector and scalar multiplication are usually denoted by juxtaposition.

  If \( \odot \) is associative, commutative, unital or invertible, we add this prefix to \( A \), e.g. A is a commutative algebra if \( \odot \) is commutative.
\end{definition}

\begin{proposition}\label{thm:functions_over_ring_form_algebra}
  Let \( X \) be an arbitrary nonempty set and \( R \) be a commutative unital ring. Define
  \begin{equation*}
    A \coloneqq \cat{Set}(X, R)
  \end{equation*}
  to be the set of all functions from \( X \) to \( R \) (see \fullref{def:category_of_small_sets}). Then \( A \) is an \( R \)-algebra with the operations being defined pointwise, that is,
  \begin{balign*}
    [f + g](x)     & \coloneqq f(x) + g(x)     \\
    [f \odot g](x) & \coloneqq f(x) \circ g(x) \\
    [rf](x)        & \coloneqq r f(x)
  \end{balign*}

  We call the algebra \( A \) the \term{algebra of functions} from \( X \) to \( R \).

  If \( X \) itself has a ring structure, we consider the set of ring \hyperref[thm:ring_homomorphism_simpler_conditions]{homomorphisms}
  \begin{equation*}
    \cat{Ring}(X, R),
  \end{equation*}
  which is usually a strict subset of \( \cat{Set}(X, R) \). This set is usually denoted by \( \hom(X, R) \).

  If \( R \) is a module, but not necessarily a ring, then \( \cat{Set}(X, R) \) is a only module since we do not necessarily have multiplication. See \fullref{def:linear_operator}.
\end{proposition}

\begin{definition}\label{def:homogenous_function}
  Let \( M \) and \( N \) be left \( R \)-modules. We say that the function \( f: M \to N \) is homogeneous with degree \( n \) if for all \( t \in R \) and \( x \in M \) we have
  \begin{equation*}
    f(t x) = t^n f(x).
  \end{equation*}
\end{definition}

\begin{definition}\label{def:left_module_annihilator}\mcite[30]{КоцевСидеров2016}
  Fix a subset \( S \subseteq M \) of a left \( R \)-module \( M \). We define the \term{annihilator} of \( S \) as the ideal
  \begin{equation*}
    \op{ann}(S) \coloneqq \{ r \in R \colon rS = \{ 0 \} \}.
  \end{equation*}
\end{definition}
