\subsection{Modules}\label{subsec:modules}

\begin{definition}\label{def:module}
  A \term{module} is a \hyperref[def:semimodule]{semimodule} over a \hyperref[def:ring]{ring} rather than a \hyperref[def:semiring]{semiring}.

  This makes the identity law \eqref{eq:def:semimodule/operation/scalar_multiplication_action/identity} redundant.

  Modules have the following metamathematical properties:
  \begin{thmenum}
    \thmitem{def:module/theory} The first-order theory is identical to the \hyperref[def:semimodule/theory]{theory of semimodules}.

    \thmitem{def:module/homomorphism} A \hyperref[def:first_order_homomorphism]{first-order homomorphism} between two \( R \)-modules \( M \) and \( N \) is simply a \hyperref[def:semimodule/homomorphism]{linear map}.

    \thmitem{def:module/submodel} The set \( A \subseteq M \) is a \hyperref[thm:substructure_is_model]{submodel} of \( M \) if it is a sub-semimodule of \( M \), i.e. a subgroup of \( M \) that is closed under scalar multiplication. We say that \( A \) is a \term{submodule} of \( M \).

    As a consequence of \fullref{thm:positive_formulas_preserved_under_homomorphism}, the \hyperref[def:multi_valued_function/image]{image} of an \( R \)-module homomorphism \( \varphi: M \to N \) is a submodule of \( M \).

    \thmitem{def:module/trivial} The \hyperref[thm:substructures_form_complete_lattice/bottom]{trivial} module is the \hyperref[def:pointed_set/trivial]{trivial pointed set} \( \set{ 0 } \).

    \thmitem{def:module/category} For a fixed ring \( R \), we denote the \hyperref[def:category_of_small_first_order_models]{category of \( \mscrU \)-small models} by \( \ucat{Mod}_R \).

    It is a very well-behaved category, even more than the category \hyperref[def:group/category]{\( \ucat{Grp} \)} of \( \mscrU \)-small groups.
    \begin{itemize}
      \item The trivial module \( \set{ 0 } \) is a zero object. Therefore, we can define kernels and cokernels, and cokernels for modules are particularly simple.

      \item The \hyperref[def:free_semimodule]{free semimodules} over a ring are modules, and \fullref{thm:free_semimodule_universal_property} ensures that this is left adjoint to the forgetful functor \( U: \ucat{Mod}_R \to \ucat{Set} \). Therefore, by \fullref{thm:first_order_categorical_invertibility}, the monomorphisms are exactly the injective homomorphisms, and that the \hyperref[def:subobject_and_quotient]{categorical subobjects} correspond to submodules.

      \item Every epimorphism in \( \ucat{Mod}_R \) is surjective. This will be proved in \fullref{thm:module_epimorphisms_are_surjective}. Along with \fullref{thm:group_epimorphisms_are_normal}, this shows that the \hyperref[def:subobject_and_quotient]{categorical quotient objects} correspond to \hyperref[def:module/quotient]{quotient modules}, which we will define shortly.
    \end{itemize}

    \thmitem{def:module/kernel} The \term{kernel} of an \( R \)-module homomorphism \( \varphi: M \to N \) is its \hyperref[def:zero_locus]{zero locus} \( \varphi^{-1}(0_N) \). This is a submodule of \( M \). It is precisely the kernel of the underlying group in the sense of \fullref{def:group/kernel}, and the \hyperref[def:zero_morphisms/cokernel]{categorical kernel} in the category of modules.

    \thmitem{def:module/quotient} The \hyperref[def:zero_morphisms/cokernel]{categorical cokernel} of an \( R \)-homomorphism \( \varphi: M \to N \) in the category \( \cat{Mod}_R \) is simply the additive \hyperref[def:group/quotient]{quotient group} \( N / \img \varphi \). The quotient group is again a module over \( R \) because \( N \) is closed under scalar multiplication and, for every coset \( x + N \),
    \begin{equation*}
      r(x + N) = rx + rN = rx + N
    \end{equation*}
    is again a coset in \( N / \img \varphi \).

    In particular, given a submodule \( N \) of \( M \), we can form the \term{quotient module} \( M / N \). In practice, quotients are conveniently characterized by \fullref{thm:quotient_module_universal_property}.
  \end{thmenum}
\end{definition}

\begin{proposition}\label{thm:abelian_group_is_module}
  We have an \hyperref[rem:category_similarity/isomorphism]{isomorphism of categories} \( \hyperref[def:abelian_group]{\cat{Ab}} \cong \hyperref[def:module]{\cat{Mod}_\BbbZ} \).

  More concretely, every abelian group \( G \) is a left semimodule over \( \BbbZ \) with scalar multiplication given by \hyperref[rem:additive_magma/multiplication]{recursively defined multiplication}
  \begin{equation}\label{eq:thm:abelian_group_is_module/operation}
    \begin{aligned}
      &\cdot: \BbbZ \times G \to G \\
      &n \cdot x \coloneqq \begin{cases}
        0_G,           &n = 0, \\
        n \cdot x + x, &n > 1, \\
        -(n \cdot x),  &n < 1.
      \end{cases}
    \end{aligned}
  \end{equation}

  Conversely, in every semimodule over \( \BbbZ \), scalar multiplication matches the recursively defined multiplication.

  Compare this result to \fullref{thm:commutative_monoid_is_semimodule}.
\end{proposition}
\begin{proof}
  Simple refinement of \fullref{thm:commutative_monoid_is_semimodule}.
\end{proof}

\begin{theorem}[Quotient module universal property]\label{thm:quotient_module_universal_property}\mcite[thm. 7.12]{Aluffi2009}
  For every \hyperref[def:module]{module} \( M \) over \( R \) and every submodule \( N \) of \( M \), the \hyperref[def:module/quotient]{quotient module} \( R / I \) has the following \hyperref[rem:universal_mapping_property]{universal mapping property}:
  \begin{displayquote}
    Every \( R \)-module homomorphism \( \varphi: M \to K \) satisfying \( N \subseteq \ker \varphi \) \hyperref[def:factors_through]{uniquely factors through} \( M / N \). That is, there exists a unique \( R \)-module homomorphism \( \widetilde{\varphi}: M / N \to K \) such that the following diagram commutes:
    \begin{equation}\label{eq:thm:quotient_module_universal_property/diagram}
      \begin{aligned}
        \includegraphics[page=1]{output/thm__quotient_module_universal_property.pdf}
      \end{aligned}
    \end{equation}

    In the case where \( N = \ker \varphi \), \( \widetilde{\varphi} \) is an \hyperref[def:first_order_homomorphism_invertibility/embedding]{embedding}.
  \end{displayquote}

  Compare this result to \fullref{thm:quotient_group_universal_property} and \fullref{thm:quotient_ring_universal_property}.
\end{theorem}
\begin{proof}
  Simple refinement of \fullref{thm:quotient_group_universal_property}.
\end{proof}

\begin{proposition}\label{thm:module_epimorphisms_are_surjective}
  Every \hyperref[def:morphism_invertibility/right_cancellative]{epimorphism} in \hyperref[def:group/category]{\( \cat{Mod}_R \)} is \hyperref[def:function_invertibility/surjective]{surjective}.
\end{proposition}
\begin{proof}
  Let \( \varphi: M \to N \) be an \( R \)-module epimorphism. Consider the canonical projection \( \pi: N \to N / \img \varphi \) and the zero morphism \( z: N \to N / \img \varphi \). Clearly
  \begin{equation*}
    \pi \bincirc \varphi = z \bincirc \varphi,
  \end{equation*}
  and thus \( \pi = z \) is the zero morphism.

  By, \fullref{thm:def:group/properties/kernel_cokernel_compatibility}, \( \ker \pi = \img \varphi \), and since \( \ker \pi = N \), it follows that \( \varphi \) is a surjective function.
\end{proof}

\begin{definition}\label{def:multilinear_function}\mimprovised
  Generalizing \hyperref[def:semimodule/homomorphism]{linear maps}, if \( M_1, \ldots, M_n \) and \( N \) are \( R \)-modules, we say that the function
  \begin{equation*}
    f: M_1 \times \ldots \times M_n \to N
  \end{equation*}
  is \term{multilinear} (\term{bilinear} for \( n = 2 \)) if it is linear in each component. That is, for every tuple
  \begin{equation*}
    (x_1, \ldots, x_n) \in M_1 \times \cdots \times M_n,
  \end{equation*}
  and for every index \( k = 1, \ldots, n \), the following function is linear:
  \begin{equation*}
    y \mapsto f(x_1, \ldots, x_{k-1}, y, x_{k+1}, \ldots, x_n)
  \end{equation*}
\end{definition}

\begin{definition}\label{def:linear_combination}\mimprovised
  A \term{linear combination} over a \hyperref[def:semiring]{(semi)ring} \( R \) is a finite sequence \( t_1, \ldots, t_n \) of scalars, which we call the \term{coefficients} of the combination. More abstractly, a linear combination is a member of the \hyperref[def:semimodule_direct_product]{direct sum} \( \bigoplus_{k=1}^\infty R \).

  Given a \hyperref[def:semimodule]{(semi)module} \( M \) over \( R \) and a corresponding sequence of vectors \( x_1, \ldots, x_n \), we can \term{evaluate} the linear combination as
  \begin{equation}
    \sum_{k=1}^n t_k x_k,
  \end{equation}
  to obtain a vector in \( M \). Evaluation defines an \( R \)-(semi)module homomorphism
  \begin{equation*}
    \Phi: \underbrace{\bigoplus_{k=1}^\infty R}_{\T{scalars}} \times \underbrace{\bigoplus_{k=1}^\infty M}_{\T{vectors}} \to M.
  \end{equation*}

  The gist is that we treat linear combinations as syntactic objects and then, given a corresponding sequence of vectors, we interpret this syntactic object to obtain another vector. This corresponds to mathematical practice, although making this idea precise requires some level of mathematical maturity.

  \begin{thmenum}
    \thmitem{def:linear_combination/trivial} A \term{trivial} linear combination is the zero vector in \( \bigoplus_{k=1}^\infty R \). In practice, this corresponds to a finite sequence of zeros.

    \thmitem{def:linear_combination/affine} An \term{affine combination} is a linear combination such that \( \sum_{k=1}^n t_k = 1_R \).

    \thmitem{def:linear_combination/conic} If \( R \) is an \hyperref[def:ordered_semiring]{ordered (semi)ring}, a \term{conic combination} in \( R \) is a linear combination with \hyperref[def:ordered_semiring]{nonnegative coefficients}.

    \thmitem{def:linear_combination/convex} A \term{convex combination} is a linear combination that is both affine and conic.
  \end{thmenum}
\end{definition}

\begin{definition}\label{def:module_linear_dependence}\mimprovised
  Fix an \( R \)-module \( M \). We say that the vectors \( x_1, \ldots, x_n \) are \term{linearly independent} if every \hyperref[def:linear_combination]{linear combination} \( \sum_{k=1}^n t_k x_k \) that sums to zero is \hyperref[def:linear_combination/trivial]{trivial}. An equivalent condition can be given in by stating that the \( R \)-module homomorphism
  \begin{equation*}
    (t_1, \ldots, t_n) \mapsto \sum_{k=1}^n t_k x_k
  \end{equation*}
  is injective.

  If the vectors are not linearly independent, we call them \term{linearly dependent}.

  For a general subset \( A \) of \( M \), we say that \( A \) is \term{linearly independent} if every finite sequence \( x_1, \ldots, x_n \) of members of \( A \) is linearly independent.

  A \term{Hamel basis} of \( M \) is a \hyperref[def:partially_ordered_set_extremal_points/maximal_and_minimal_element]{maximal} set of linearly independent vectors.
\end{definition}

\begin{proposition}\label{thm:def:module_linear_dependence/properties}
  For an \( R \)-module \( M \), \hyperref[def:module_linear_dependence]{linear (in)dependence} has the following basic properties:
  \begin{thmenum}
    \thmitem{def:module_linear_dependence/zero} The zero vector \( 0_M \) is by itself linearly dependent.

    \thmitem{def:module_linear_dependence/antimonotonicity} If \( A \) is a linearly \hi{dependent} set and \( A \subseteq B \), then \( A \) is also a linearly dependent set.

    \thmitem{def:module_linear_dependence/monotonicity} If \( A \) is a linearly \hi{independent} set and \( A \supseteq B \), then \( B \) is also a linearly independent set.

    \thmitem{def:module_linear_dependence/span_and_combinations} The \hyperref[def:semimodule/submodel]{linear span} of a set \( A \) of vectors is the set of (the evaluations of) all \hyperref[def:linear_combination]{linear combinations} of members of \( A \).

    \thmitem{def:module_linear_dependence/adding_to_span} For any set of vectors \( A \), if \( x \in \linspan A \) is not in \( A \), then \( A \cup \set{ x } \) is a linearly dependent set.

    \thmitem{def:module_linear_dependence/basis_of_span} Every linearly independent set is a Hamel basis for its own span.

    \thmitem{def:module_linear_dependence/span_of_basis} If \( B \) is a Hamel basis of \( M \), then \( M = \linspan{ B } \).
  \end{thmenum}
\end{proposition}
\begin{proof}
  \SubProofOf{def:module_linear_dependence/zero} Trivial.

  \SubProofOf{def:module_linear_dependence/antimonotonicity} Trivial.

  \SubProofOf{def:module_linear_dependence/monotonicity} Trivial.

  \SubProofOf{def:module_linear_dependence/span_and_combinations} Follows from \fullref{ex:def:first_order_substructure/vector_space}.

  \SubProofOf{def:module_linear_dependence/adding_to_span} By \fullref{def:module_linear_dependence/span_and_combinations}, there exists a linear combination of members of \( A \) such that
  \begin{equation*}
    x = \sum_{k=1}^n t_k x_k.
  \end{equation*}

  If \( x = 0_M \), then \( A \cup \set{ x } \) is not linearly dependent by \fullref{def:module_linear_dependence/zero} and \fullref{def:module_linear_dependence/antimonotonicity}.

  If \( x \neq 0_M \), then \( A \cup \set{ x } \) is not linearly independent because \( x \) is a nontrivial linear combination of other vectors of \( A \).

  \SubProofOf{def:module_linear_dependence/basis_of_span} Suppose that \( A \) is not a maximal linearly independent set in the module \( \linspan A \). Then there exists some nonzero vector \( x \in \linspan A \) such that \( A \cup \set{ x } \) are again linearly independent.

  By \fullref{def:module_linear_dependence/span_and_combinations}, there exists a linear combination in \( A \) such that
  \begin{equation*}
    x = \sum_{k=1}^n t_k x_k.
  \end{equation*}

  Since \( x \) is nonzero, the combination must be nontrivial. But this contradicts the linear independence of \( A \). Therefore, \( A \) is a basis of its span.

  \SubProofOf{def:module_linear_dependence/span_of_basis} Clearly \( \linspan{B} \subseteq M \). If we suppose that \( M \setminus \linspan{B} \) is nonempty, then there exists some vector \( x \) that is not a linear combination of members of \( B \) (since it is not in the span). But this also implies that \( B \cup \set{ x } \) is linearly independent, which contradicts our assumption that \( B \) is a Hamel basis.

  The obtained contradicts shows that \( M = \linspan{B} \).
\end{proof}

\begin{proposition}\label{thm:left_module_basis_decomposition}
  Let \( B \) be a \hyperref[def:module_linear_dependence]{basis} of the free left \( R \)-module \( M \). Then every member of \( M \) can be represented as a linear combination over \( B \) uniquely up the order of summands.

  Explicitly, for every element \( x \) of \( M \), there exists unique finite set \( V \subseteq M \) and a function \( \tau: V \to R \)such that
  \begin{equation*}
    x = \sum_{k=1}^n t_k v_k,
  \end{equation*}
  where \( v_1, \ldots, v_n \) is a well-ordering of \( V \) and \( t_k = \tau(v_k) \).
\end{proposition}
\begin{proof}
  At least one such representation exists by \fullref{def:module_linear_dependence/span_of_basis} and \fullref{def:module_linear_dependence/span_and_combinations}.

  Suppose that there are two such representations
  \begin{equation*}
    x = \sum_{k=1}^n t_k v_k = \sum_{k=1}^m s_k w_k.
  \end{equation*}

  Without loss of generality, we can assume that \( n = m \) and \( v_k = w_k \) for every index \( k = 1, \ldots, n \). We can justify this by explicitly adding terms with \( 0_R \) as the coefficients where needed.

  Hence,
  \begin{equation*}
    0 = x - x = \sum_{k=1}^n (t_k - s_k) v_k.
  \end{equation*}

  The vectors \( v_1, \ldots, v_n \) are linearly independent since they belong to the basis \( B \). Hence, only a trivial linear combination can give the zero vector. This implies that \( t_k = s_k \) for every index \( k = 1, \ldots, n \).

  Therefore, the representation of \( x \) as a linear combination over \( B \) is unique up to reordering.
\end{proof}

\begin{proposition}\label{thm:free_module_hamel_basis}
  The \( R \)-module \( M \) is (isomorphic to) a \hyperref[def:free_semimodule]{free \( R \)-module} with basis \( B \) if and only if \( B \) is a \hyperref[def:module_linear_dependence]{Hamel basis} of \( M \).
\end{proposition}
\begin{proof}
  \SufficiencySubProof Let \( M \) be a free \( R \)-module with basis \( B \). Every vector in \( M \) is then a function \( \tau: B \to R \) with finite \hyperref[def:function_support]{support}.

  Fix members \( b_1, \ldots, b_n \) of \( B \). For their canonical inclusion, we have \( [\iota(b_k)](r) = 1_R \) if \( r = b_k \) and \( 0_R \) otherwise. Thus, if
  \begin{equation*}
    \tau = \sum_{k=1}^n t_k \iota(b_k) = 0_M,
  \end{equation*}
  then for every index \( m = 1, \ldots, n \) we have
  \begin{equation*}
    \tau(b_m) = \sum_{k=1}^n t_k [\iota(b_k)](b_m) = t_m = 0_R.
  \end{equation*}

  The above holds when \( \tau \) is an arbitrary vector in \( M \). Therefore, \( \iota[B] \) is a maximal linearly independent set.

  \NecessitySubProof Let \( M \) be a module with Hamel basis \( B \). We will show that \( F(B) \cong M \).

  By \fullref{thm:free_semimodule_universal_property}, the identity function \( b \mapsto b \) on \( B \) can be extended to an \( R \)-module homomorphism \( \varphi: F(B) \to M \) such that \( \varphi(\iota(b)) = b \) for every \( b \in B \). By linearity of \( \varphi \),
  \begin{equation*}
    \varphi(\tau) = \sum_{k=1}^n \tau(b_k) b_k,
  \end{equation*}
  where \( b_1, \ldots, b_n \) is any well-ordering on the \hyperref[def:function_support]{support} \( \supp(\tau) \).

  To see that \( \varphi \) is injective, suppose that \( \varphi(\tau) = \varphi(\sigma) \). Then
  \begin{equation*}
    \varphi(\tau) - \varphi(\sigma) = \sum_{k=1}^n [\tau(b_k) - \sigma(b_k)] b_k = 0_{F(B)}.
  \end{equation*}

  Since \( B \) is a linearly independent set, the above is only possible when \( \tau(b_k) - \sigma(b_k) = 0_R \) for every \( k \). Therefore, \( \tau = \sigma \), and \( \varphi \) is injective.

  To see that \( \varphi \) is surjective, let \( x \in M \). By \fullref{def:module_linear_dependence/span_of_basis} and \fullref{def:module_linear_dependence/span_and_combinations}, it follows that there exists a linear combination of members of the basis \( B \) of \( M \) such that
  \begin{equation*}
    x = \sum_{k=1}^n t_k b_k.
  \end{equation*}

  Then \( \tau(b_k) \coloneqq t_k \) is a member of \( F(B) \) and, furthermore,
  \begin{equation*}
    \varphi(\tau) = \sum_{k=1}^n \tau(b_k) b_k = \sum_{k=1}^n t_k b_k.
  \end{equation*}

  Therefore, \( \varphi \) is also surjective.

  It follows that \( \varphi: F(B) \to M \) is an isomorphism.
\end{proof}

\begin{definition}\label{def:module_basis_projection}
  Let \( M \) be a left \( R \)-module and let \( B \) be a basis of \( M \). For each \( b \in B \), we define the \text{coordinate projection functional} \( \pi_b: M \to R \) that gives us the unique coefficient in the basis decomposition. Thus, for every \( x \in M \) we have
  \begin{equation*}
    x = \sum_{b \in B} \pi_b(x) b.
  \end{equation*}

  \begin{proposition}\label{thm:left_module_basis_decomposition}
    Let \( B \) be a \hyperref[def:module_linear_dependence]{basis} of the free left \( R \)-module \( M \). Then every member of \( M \) can be represented as a linear combination over \( B \) uniquely up the order of summands.

    Explicitly, for every element \( x \) of \( M \), there exists unique finite set \( V \subseteq M \) and a function \( \tau: V \to R \)such that
    \begin{equation*}
      x = \sum_{k=1}^n t_k v_k,
    \end{equation*}
    where \( v_1, \ldots, v_n \) is a well-ordering of \( V \) and \( t_k = \tau(v_k) \).
  \end{proposition}
  \begin{proof}
    At least one such representation exists by \fullref{def:module_linear_dependence/span_of_basis} and \fullref{def:module_linear_dependence/span_and_combinations}.

    Suppose that there are two such representations
    \begin{equation*}
      x = \sum_{k=1}^n t_k v_k = \sum_{k=1}^m s_k w_k.
    \end{equation*}

    Without loss of generality, we can assume that \( n = m \) and \( v_k = w_k \) for every index \( k = 1, \ldots, n \). We can justify this by explicitly adding terms with \( 0_R \) as the coefficients where needed.

    Hence,
    \begin{equation*}
      0 = x - x = \sum_{k=1}^n (t_k - s_k) v_k.
    \end{equation*}

    The vectors \( v_1, \ldots, v_n \) are linearly independent since they belong to the basis \( B \). Hence, only a trivial linear combination can give the zero vector. This implies that \( t_k = s_k \) for every index \( k = 1, \ldots, n \).

    Therefore, the representation of \( x \) as a linear combination over \( B \) is unique up to reordering.
  \end{proof}

  The sum is well-defined since only finitely many terms are nonzero.

  When the basis \( B \) is finite and ordered:
  \begin{equation*}
    B = \{ b_1, \ldots, b_n \},
  \end{equation*}
  we also write
  \begin{equation*}
    x = \sum_{i=1}^n x_k b_i.
  \end{equation*}
\end{definition}
\begin{proof}
  By \fullref{thm:left_module_basis_decomposition}, this decomposition is unique given a basis \( B \).
\end{proof}

\begin{proposition}\label{thm:left_module_basis_projections_are_linear}
  The basis projection \hyperref[def:module_basis_projection]{maps} are linear.
\end{proposition}
\begin{proof}
  \SubProofOf{def:semimodule/homomorphism/homogeneity} Let \( t \in R \) and \( x \in M \). We have the unique decompositions
  \begin{balign*}
    x  & = \sum_{b \in B} \pi_b(x) b,  \\
    tx & = \sum_{b \in B} \pi_b(tx) b.
  \end{balign*}

  Since both decompositions have only finitely many terms, their difference also has only finitely many nonzero terms. Thus,
  \begin{equation*}
    0
    =
    tx - tx
    =
    t \left( \sum_{b \in B} \pi_b(x) b \right) - \sum_{b \in B} \pi_b(tx) b
    =
    \sum_{b \in B} (t \pi_b(x) - \pi_b(tx)) b.
  \end{equation*}

  Since the vectors in \( B \) are linearly independent, no nontrivial linear combination can equal the zero vector. Thus, for all \( b \in B \),
  \begin{equation*}
    t \pi_b(x) = \pi_b(tx).
  \end{equation*}

  \SubProofOf{def:semimodule/homomorphism/additivity} Analogous.
\end{proof}

\begin{proposition}\label{thm:left_module_basis_cardinality}\mcite{ProofWiki:bases_of_free_module_have_same_cardinality}
  All bases in a free left module over a commutative unital ring have the same cardinality.
\end{proposition}

\begin{definition}\label{def:algebra_over_ring}\mcite[408]{Knapp2016BasicAlgebra}
  Let \( R \) be a commutative unital ring. We say that the left \( R \)-module \( A \) is an \( R \)-\term{algebra} if we define an additional bilinear \term{vector multiplication} operation
  \begin{equation*}
    \odot: A \times A \to A
  \end{equation*}
  such that for \( x, y \in M \) and \( t \in R \)
  \begin{equation*}
    t \cdot (x \odot y) = (t \cdot x) \odot y = x \odot (t \cdot y).
  \end{equation*}

  Both vector and scalar multiplication are usually denoted by juxtaposition.

  If \( \odot \) is associative, commutative, unital or invertible, we add this prefix to \( A \), e.g. A is a commutative algebra if \( \odot \) is commutative.
\end{definition}

\begin{proposition}\label{thm:functions_over_ring_form_algebra}
  Let \( X \) be an arbitrary nonempty set and \( R \) be a commutative unital ring. Define
  \begin{equation*}
    A \coloneqq \cat{Set}(X, R)
  \end{equation*}
  to be the set of all functions from \( X \) to \( R \). Then \( A \) is an \( R \)-algebra with the operations being defined pointwise, that is,
  \begin{balign*}
    [f + g](x)     & \coloneqq f(x) + g(x)     \\
    [f \odot g](x) & \coloneqq f(x) \circ g(x) \\
    [rf](x)        & \coloneqq r f(x)
  \end{balign*}

  We call the algebra \( A \) the \term{algebra of functions} from \( X \) to \( R \).

  If \( X \) itself has a ring structure, we consider the set of ring \hyperref[thm:ring_homomorphism_simpler_conditions]{homomorphisms}
  \begin{equation*}
    \cat{Ring}(X, R),
  \end{equation*}
  which is usually a strict subset of \( \cat{Set}(X, R) \). This set is usually denoted by \( \hom(X, R) \).

  If \( R \) is a module, but not necessarily a ring, then \( \cat{Set}(X, R) \) is a only module since we do not necessarily have multiplication. See \fullref{def:semimodule/homomorphism}.
\end{proposition}
