\subsection{Bilinear forms}\label{subsec:bilinear_forms}

We define \hyperref[def:bilinear_form]{bilinear forms} over arbitrary fields, although they are almost exclusively used over the field of real numbers. In the latter case, they are a special case of \hyperref[def:sesquilinear_form]{sesquilinear forms} over complex numbers.

\begin{definition}\label{def:bilinear_form}\mcite[249]{Knapp2016BasicAlgebra}
  A \term{bilinear form} over the vector space \( V \) over \( \BbbK \) is a bilinear form is a \hyperref[def:multilinear_function]{multilinear function} with signature \( L: V \times V \to \BbbK \).
\end{definition}

\begin{remark}\label{rem:matrices_as_bilinear_forms}
  Similarly to what we discussed in \fullref{rem:matrices_as_functions}, matrices correspond to linear functions and vice versa. Square matrices correspond to \hyperref[def:bilinear_form]{bilinear forms}.

  Let \( e_1, \ldots, e_n \) be the \hyperref[def:standard_basis]{standard basis} of \( \BbbK^n \). To every \( n \times n \) matrix \( A \), there corresponds a bilinear form
  \begin{equation*}
    L_A(x) \coloneqq x^T A x.
  \end{equation*}

  Similarly, given a bilinear form \( L \), we can build the following matrix:
  \begin{equation*}
    A_L \coloneqq
    \begin{pmatrix}
      L(e_1, e_1) & \cdots & L(e_1, e_n) \\
      \vdots      & \ddots & \vdots      \\
      L(e_n, e_1) & \cdots & L(e_n, e_n)
    \end{pmatrix}.
  \end{equation*}

  This matrix is called the generalized \term{Gram matrix} corresponding to \( L \).
\end{remark}

\begin{proposition}\label{thm:symmetric_bilinear_form_matrix}
  The \hyperref[rem:matrices_as_bilinear_forms]{Gram matrix} of a \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form} is \hyperref[def:transpose_matrix]{symmetric}.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{definition}\label{def:bilinear_form_radicals}\mcite[250]{Knapp2016BasicAlgebra}
  Let \( L: V \times V \to \BbbK \) be a bilinear form. We define its \term{left radical}
  \begin{equation*}
    \set{ x \in V \given \qforall {y \in V} L(x, y) = 0 }
  \end{equation*}
  and its \term{right radical}
  \begin{equation*}
    \set{ y \in V \given \qforall {x \in V} L(x, y) = 0 }
  \end{equation*}

  Note that if \( L \) is symmetric or skew-symmetric, the two are identical, and we speak simply of the \term{radical} \( \sqrt L \).
\end{definition}

\begin{definition}\label{def:degenerate_bilinear_form}\mcite[249]{Knapp2016BasicAlgebra}
  We say that a \hyperref[def:bilinear_form]{bilinear form} is \term{degenerate} if either its left or right \hyperref[def:bilinear_form_radicals]{radical} is not trivial.
\end{definition}

\begin{example}\label{ex:def:bilinear_form}\hfill
  \begin{thmenum}
    \thmitem{ex:def:bilinear_form/asymmetric_degenerate} The matrix
    \begin{equation*}
      \begin{pmatrix}
        0 & 1 \\
        0 & 0
      \end{pmatrix}
    \end{equation*}
    corresponds to a \hyperref[def:degenerate_bilinear_form]{degenerate} \hyperref[def:bilinear_form]{bilinear form}. Its \hyperref[def:bilinear_form_radicals]{left radical} is
    \begin{equation*}
      \set*{ \begin{pmatrix} 0 \\ r \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    Its right radical is
    \begin{equation*}
      \set*{ \begin{pmatrix} r \\ 0 \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    \thmitem{ex:def:bilinear_form/symmetric_degenerate} The matrix
    \begin{equation*}
      \begin{pmatrix}
        1 & 0 \\
        0 & 0
      \end{pmatrix}
    \end{equation*}
    is also degenerate. It is symmetric, however, and its left and right radicals coincide with
    \begin{equation*}
      \set*{ \begin{pmatrix} 0 \\ r \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    \thmitem{ex:def:bilinear_form/euclidean} The identity matrix induces the nondegenerate bilinear form \( (x, y) \mapsto x^T y \). It is called the \term{Euclidean product}.
  \end{thmenum}
\end{example}

\begin{definition}\label{def:homogeneous_polynomial}\mimprovised
  We say that a \hyperref[def:polynomial_algebra]{polynomial} is \term{homogeneous} of degree \( n \) if all of its monomials have degree \( n \).
\end{definition}

\begin{definition}\label{def:homogenous_function}\mimprovised
  We say that the function \( f: V \to \BbbK \) is \term{homogeneous} of degree \( n \) if
  \begin{equation*}
    f(t x) = t^n f(x).
  \end{equation*}

  This is a generalization of \hyperref[eq:def:semimodule/homomorphism/homogeneity]{homogeneity} used in the definition of linear maps.
\end{definition}

\begin{proposition}\label{thm:homogeneous_polynomial_is_homogeneous_function}
  A \hyperref[def:homogeneous_polynomial]{homogeneous polynomial} is a \hyperref[def:homogenous_function]{homogeneous function} of the same degree.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{proposition}\label{thm:polarization_identity}\mcite{nLab:polarization_identity}
  Let \( L: V \times V \to \BbbK \) be a \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form} and define \( Q(x) \coloneqq L(x, x) \). Then the \term{polarization identity} holds:
  \begin{equation}\label{thm:polarization_identity/polarization_identity}
    Q(x + y) - Q(x - y) = 2 L(x, y) + 2 L(y, x)
  \end{equation}

  The similar looking, but slightly less useful parallelogram law also holds:
  \begin{equation}\label{thm:polarization_identity/parallelogram_law}
    Q(x + y) + Q(x - y) = 2 Q(x) + 2 Q(y)
  \end{equation}

  We can \enquote{recover} \( L \) from \( Q \):
  \begin{equation}\label{thm:polarization_identity/definition}
    L(x, y) \coloneqq \frac 1 2 \bracks{ Q(x + y) - Q(x) - Q(y) }.
  \end{equation}
\end{proposition}
\begin{proof}
  The identities all follow from the bilinearity of \( L \), that is,
  \begin{equation*}
    Q(x \pm y)
    =
    L(x, x) \pm L(x, y) \pm L(y, x) + L(y, y)
    =
    [Q(x) + Q(y)] \pm [L(x, y) + L(y, x)].
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:quadratic_forms}
  There is a bijective correspondence between \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear forms} and \hyperref[def:homogeneous_polynomial]{homogeneous} \hyperref[def:polynomial_degree]{quadratic polynomials}.

  A \term{quadratic form} \( Q: V \to \BbbK \) is defined as either \( Q(x) \coloneqq L(x, x) \) for a symmetric bilinear form \( L \), or as the \hyperref[thm:polynomial_algebra_universal_property]{polynomial function} of a homogeneous quadratic polynomial.

  Complex quadratic forms differ from the general theory --- see \fullref{rem:complex_quadratic_form}.
\end{proposition}
\begin{proof}
  First, let \( L: V \times V \to \BbbK \) be a bilinear form. Let \( e_k, k \in \mscrK, \) be a \hyperref[def:hamel_basis]{basis} of \( V \). Define the polynomial
  \begin{equation*}
    p_L(X_k \given k \in \mscrK) \coloneqq \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) X_i X_j.
  \end{equation*}

  Conversely, let \( p(X_k \given k \in \mscrK) \) be a homogeneous quadratic polynomial over the set of indeterminates \( \mscrX \). Via \eqref{thm:polarization_identity/definition}, we can define
  \begin{equation*}
    L_p(x, y) = \frac 1 2 \bracks{ p(x + y) - p(x) - p(y) },
  \end{equation*}
  where \( x \) and \( y \) are vectors from \( V \) (i.e. \( \mscrX \)-indexed tuples).

  Given a symmetric bilinear form \( L \), we have
  \begin{balign*}
    &\phantom{{}={}}
    L_{p_L}(x, y)
    = \\ &=
    \frac 1 2 \parens*{ \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) (x_i + y_i) (x_j + y_j) - \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) x_i x_j - \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) y_i y_j }
    = \\ &=
    \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) x_i y_j + \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) y_i x_j
    = \\ &=
    \sum_{j \in \mscrK} L\parens*{ \sum_{i \in \mscrK} x_i e_i, \sum_{j \in \mscrK} y_j e_j }
    = \\ &=
    L(x, y).
  \end{balign*}

  Conversely, given a homogeneous quadratic polynomial \( p \), we have
  \begin{balign*}
    &\phantom{{}={}}
    p_{L_p}(X_k \given k \in \mscrK)
    = \\ &=
    \sum_{i \in \mscrK} \sum_{j \in \mscrK} L_p(e_i, e_j) X_i X_j
    = \\ &=
    \sum_{i \in \mscrK} \sum_{j \in \mscrK} L_p(e_i, e_j) X_i X_j
    = \\ &=
    \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} \bracks{ p(e_i + e_j) - p(e_i) - p(e_j) } X_i X_j.
  \end{balign*}

  By definition, all \hyperref[def:basis_decomposition]{coordinate projections} of \( e_i \) are zero except for the \( i \)-th coordinate, which is one. Hence, the value \( p(e_i) \) is the coefficient before \( X_i^2 \) in \( p \), and similarly for \( p(e_j) \). The value \( p(e_i + e_j) \) is the sum of coefficients before \( X_i^2 \), \( X_i X_j \) and \( X_j^2 \). Therefore,
  \begin{equation*}
    p(e_i + e_j) - p(e_i) - p(e_j)
  \end{equation*}
  is the coefficient before \( X_i X_j \). Furthermore, \( X_i X_j \) is equal to \( X_j X_i \), and so are their coefficients, which allows us to cancel \( \ifrac 1 2 \) above. Thus,
  \begin{equation*}
    p_{L_p}(X_k \given k \in \mscrK) = p(X_k \given k \in \mscrK).
  \end{equation*}
\end{proof}

\begin{definition}\label{def:conjugate_vector_space}\mimprovised
  The \term{conjugate space} of a \hyperref[def:set_of_complex_numbers]{complex} vector space \( V \) is a space that we denote by \( \overline V \), where we define the scalar product as \( t \star x \mapsto \overline t \cdot x \).
\end{definition}

\begin{definition}\label{def:sesquilinear_form}\mcite[258]{Knapp2016BasicAlgebra}
  A \term{sesquilinear\footnote{\enquote{sesqui} is a Latin prefix meaning \enquote{one and a half}} form} over the \hyperref[def:set_of_complex_numbers]{complex} vector space \( V \) is a \hyperref[def:multilinear_function]{bilinear function} with signature \( L: V \times \overline V \to \BbbC \), where \( \overline V \) is the \hyperref[def:conjugate_vector_space]{conjugate space} of \( V \).

  Unlike bilinear forms, we have \( L(x, ty) = \overline t L(x, y) \) rather than \( L(x, ty) = t L(x, y) \). Sesquilinear forms coincide with bilinear forms when restricted to real numbers.
\end{definition}

\begin{definition}\label{def:hermitian_form}\mcite[258]{Knapp2016BasicAlgebra}
  A \hyperref[def:sesquilinear_form]{sesquilinear form} \( L: V \times \overline V \to \BbbC \) is called \term{Hermitian} if
  \begin{equation*}
    L(x, y) = \overline{L(y, x)}.
  \end{equation*}

  Hermitian forms coincide with symmetric forms when restricted to real numbers.
\end{definition}

\begin{remark}\label{rem:complex_quadratic_form}
  In the special case where \( \BbbK = \BbbC \), \hyperref[thm:quadratic_forms]{quadratic forms} can be generalized from the case \( \BbbK = \BbbR \) differently compared to the general approach with fields. Let \( L: V \times V \to \BbbC \) be a \hyperref[def:hermitian_form]{Hermitian} \hyperref[def:sesquilinear_form]{sesquilinear form}. Exchanging the arguments yields
  \begin{equation*}
    L(x, x) = \overline {L(x, x)},
  \end{equation*}
  which ensures that \( Q(x) \coloneqq L(x, x) \) is always a real number. Thus, we regard \( Q \) as a function from \( V \) to \( \BbbR \).

  The definition via homogeneous quadratic polynomials is no longer compatible.
\end{remark}

\begin{definition}\label{def:quadratic_form_definiteness}\mimprovised
  We say that the real or \hyperref[rem:complex_quadratic_form]{complex quadratic form} \( Q: V \to \BbbR \) is
  \begin{thmenum}
    \thmitem{def:quadratic_form_definiteness/positive_semidefinite} \term{positive semidefinite} if \( Q(x) \geq 0 \) for all \( x \in V \).
    \thmitem{def:quadratic_form_definiteness/negative_semidefinite} \term{negative semidefinite} if \( Q(x) \leq 0 \) for all \( x \in V \).
    \thmitem{def:quadratic_form_definiteness/positive_definite} \term{positive definite} if \( Q(x) > 0 \) for all \( x \neq 0_V \).
    \thmitem{def:quadratic_form_definiteness/negative_definite} \term{negative definite} if \( Q(x) < 0 \) for all \( x \neq 0_V \).
    \thmitem{def:quadratic_form_definiteness/indefinite} \term{indefinite} otherwise.
  \end{thmenum}

  The above terminology also applies to symmetric bilinear or Hermitian sesquilinear forms, since they can be used to obtain a quadratic form.
\end{definition}

\begin{definition}\label{def:inner_product_space}\mimprovised
  An \term{real inner product space} is a vector space \( V \) over \( \BbbR \) equipped with a \hyperref[def:quadratic_form_definiteness/positive_definite]{positive definite} \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form}
  \begin{equation*}
    \inprod \anon \anon: V \times V \to \BbbR.
  \end{equation*}

  A \term{complex inner product space} is a vector space \( V \) over \( \BbbC \) equipped with a \hyperref[def:quadratic_form_definiteness/positive_definite]{positive definite} \hyperref[def:hermitian_form]{Hermitian} \hyperref[def:sesquilinear_form]{sesquilinear form}
  \begin{equation*}
    \inprod \anon \anon: V \times V \to \BbbC.
  \end{equation*}
\end{definition}

\begin{definition}\label{def:orthogonality}
  Let \( U \) and \( V \) be vector spaces over \( \BbbK \) and let \( L: U \times V \to \BbbK \) be a nondegenerate bilinear form. We say that the vectors \( x \in U \) and \( y \in V \) are \term{orthogonal} with respect to \( L \) if
  \begin{equation*}
    L(x, y) = 0.
  \end{equation*}

  For every subspace \( U \subseteq V \) we define its \term{orthogonal complement} with respect to \( L \) as
  \begin{equation*}
    U^\perp \coloneqq \set{ x \in U \colon L(x, y) = 0 \T{for all} y \in V }
  \end{equation*}
  and analogously for submodules of \( V \).

  Let \( \mscrK \) be an index set and \( \seq{ x_k }_{k \in \mscrK} \subseteq U \), \( \seq{ y_k }_{k \in \mscrK} \subseteq V \) be two families of vectors indexed by \( \mscrK \). We say that these families form a \term{biorthogonal system} with respect to \( L \) if
  \begin{equation*}
    L(x_k, y_m) = 0 \text{ follows from } k \neq m
  \end{equation*}

  If \( U = V \), we usually consider \term{orthogonal systems} \( \seq{ x_k }_{k \in \mscrK} \subseteq V \) where
  \begin{equation*}
    L(x_k, x_m) = 0 \iff k \neq m
  \end{equation*}
\end{definition}

\begin{lemma}\label{thm:inner_product_quadratic_form_is_positive_definite}
  Let \( V \) be a real or complex \hyperref[def:inner_product_space]{inner product space} with product \( \inprod \cdot \cdot \). The function \( Q(x) \coloneqq \inprod x x \) (which is not a quadratic form in the complex case) is positive definite.
\end{lemma}
\begin{proof}
  The real case is trivial. Assume that \( V \) is a complex vector space and that \( \inprod \cdot \cdot \) is Hermitian. This implies that \( \inprod x x = \overline{\inprod x x} \), thus \( \inprod x x \in \BbbR \). Furthermore, since the inner product is positive definite, we have \( Q(x) = \inprod x x \geq 0 \). Thus, \( Q \) is nonnegative real valued.

  Since \( \inprod \cdot \cdot \) is positive definite, so is \( Q \).
\end{proof}

\begin{theorem}[Cauchy-Bunyakovsky-Schwarz inequality]\label{thm:cauchy_bunyakovsky_schwarz_inequality}
  Let \( V \) be a real or complex \hyperref[def:inner_product_space]{inner product space} with product \( \inprod \cdot \cdot \). For every \( x, y \in V \) it holds that
  \begin{equation}\label{thm:cauchy_bunyakovsky_schwarz_inequality/inequality}
    {\abs{\inprod x y}}^2 \leq \inprod x x \inprod y y.
  \end{equation}

  Furthermore, equality is achieved if and only if \( x \) and \( y \) are linearly dependent.
\end{theorem}
\begin{proof}
  Note that we use this theorem to prove that the induced norm is a norm, so we cannot use the norm here. Associate with \( \inprod \cdot \cdot \) the function \( Q(x) \coloneqq \inprod x x \). By \fullref{thm:inner_product_quadratic_form_is_positive_definite}, \( Q \) is positive definite.

  Fix \( x, y \in V \) and \( t \in \BbbC \). If either vector is zero the statement is trivially true, so let both be nonzero. We have
  \begin{balign*}
    Q(x + ty)
     & =
    \inprod {x + ty} {x + ty}
    =    \\ &=
    Q(x) + \overline t \inprod x y + t \inprod y x + \abs{t}^2 Q(y)
    =    \\ &=
    Q(x) + 2\real t \overline{\inprod x y} + \abs{t}^2 Q(y)
  \end{balign*}

  Take \( t \coloneqq - \frac {\inprod x y} {Q(y)} \), so that
  \begin{equation*}
    Q(x + ty)
    =
    Q(x) - 2 \frac {\abs{\inprod x y}^2} {Q(y)} + \frac {\abs{\inprod x y}^2} {Q(y)}
    =
    Q(x) - \frac {\abs{\inprod x y}^2} {Q(y)}
  \end{equation*}

  Since \( Q(x + ty) \geq 0 \), it follows that
  \begin{balign*}
    Q(x) - \frac {\abs{\inprod x y}^2} {Q(y)} & \geq 0                  \\
    Q(x) Q(y)                               & \geq \abs{\inprod x y}^2.
  \end{balign*}

  If \( x \) and \( y \) are linearly dependent, equality obviously holds. Conversely, suppose that equality holds. This implies that
  \begin{equation*}
    Q(x + ty) = 0,
  \end{equation*}
  which by the positive definiteness of \( Q \) means that \( x = -ty \). Thus, \( x \) and \( y \) are linearly dependent.
\end{proof}
