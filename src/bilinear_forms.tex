\subsection{Bilinear forms}\label{subsec:bilinear_forms}

We define \hyperref[def:bilinear_form]{bilinear forms} over arbitrary fields, although they are almost exclusively used over the field of real numbers. In the latter case, they are a special case of \hyperref[def:sesquilinear_form]{sesquilinear forms} over complex numbers.

\begin{definition}\label{def:bilinear_form}\mcite[249]{Knapp2016BasicAlgebra}
  A \term{bilinear form} over the vector space \( V \) over \( \BbbK \) is a bilinear form is a \hyperref[def:multilinear_function]{multilinear function} with signature \( L: V \times V \to \BbbK \).
\end{definition}

\begin{remark}\label{rem:matrices_as_bilinear_forms}
  Similarly to what we discussed in \fullref{rem:matrices_as_functions}, matrices correspond to linear functions and vice versa. Square matrices correspond to \hyperref[def:bilinear_form]{bilinear forms}.

  Let \( e_1, \ldots, e_n \) be the \hyperref[def:standard_basis]{standard basis} of \( \BbbK^n \). To every \( n \times n \) matrix \( A \), there corresponds a bilinear form
  \begin{equation*}
    L_A(x) \coloneqq x^T A x.
  \end{equation*}

  Similarly, given a bilinear form \( L \), we can build the following matrix:
  \begin{equation*}
    A_L \coloneqq
    \begin{pmatrix}
      L(e_1, e_1) & \cdots & L(e_1, e_n) \\
      \vdots      & \ddots & \vdots      \\
      L(e_n, e_1) & \cdots & L(e_n, e_n)
    \end{pmatrix}.
  \end{equation*}

  This matrix is called the generalized \term{Gram matrix} corresponding to \( L \).
\end{remark}

\begin{proposition}\label{thm:symmetric_bilinear_form_matrix}
  The \hyperref[rem:matrices_as_bilinear_forms]{Gram matrix} of a \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form} is \hyperref[def:transpose_matrix]{symmetric}.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{definition}\label{def:bilinear_form_radicals}\mcite[250]{Knapp2016BasicAlgebra}
  Let \( L: V \times V \to \BbbK \) be a bilinear form. We define its \term{left radical}
  \begin{equation*}
    \set{ x \in V \given \qforall {y \in V} L(x, y) = 0 }
  \end{equation*}
  and its \term{right radical}
  \begin{equation*}
    \set{ y \in V \given \qforall {x \in V} L(x, y) = 0 }
  \end{equation*}

  Note that if \( L \) is symmetric or skew-symmetric, the two radicals are identical, and we speak simply of the \term{radical} \( \sqrt L \).
\end{definition}

\begin{definition}\label{def:degenerate_bilinear_form}\mcite[249]{Knapp2016BasicAlgebra}
  We say that a \hyperref[def:bilinear_form]{bilinear form} is \term{degenerate} if either its left or right \hyperref[def:bilinear_form_radicals]{radical} is not trivial.
\end{definition}

\begin{example}\label{ex:def:bilinear_form}\hfill
  \begin{thmenum}
    \thmitem{ex:def:bilinear_form/asymmetric_degenerate} The matrix
    \begin{equation*}
      \begin{pmatrix}
        0 & 1 \\
        0 & 0
      \end{pmatrix}
    \end{equation*}
    corresponds to a \hyperref[def:degenerate_bilinear_form]{degenerate} \hyperref[def:bilinear_form]{bilinear form}. Its \hyperref[def:bilinear_form_radicals]{left radical} is
    \begin{equation*}
      \set*{ \begin{pmatrix} 0 \\ r \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    Its right radical is
    \begin{equation*}
      \set*{ \begin{pmatrix} r \\ 0 \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    \thmitem{ex:def:bilinear_form/symmetric_degenerate} The matrix
    \begin{equation*}
      \begin{pmatrix}
        1 & 0 \\
        0 & 0
      \end{pmatrix}
    \end{equation*}
    is also degenerate. It is symmetric, however, and its left and right radicals coincide with
    \begin{equation*}
      \set*{ \begin{pmatrix} 0 \\ r \end{pmatrix} \given* r \in \BbbK }.
    \end{equation*}

    \thmitem{ex:def:bilinear_form/euclidean} The identity matrix induces the nondegenerate bilinear form \( (x, y) \mapsto x^T y \). It is called the \term{Euclidean product}.
  \end{thmenum}
\end{example}

\begin{definition}\label{def:homogeneous_polynomial}\mimprovised
  We say that a \hyperref[def:polynomial_algebra]{polynomial} is \term{homogeneous} of degree \( n \) if all of its monomials have degree \( n \).
\end{definition}

\begin{definition}\label{def:homogenous_function}\mimprovised
  We say that the function \( f: V \to \BbbK \) is \term{homogeneous} of degree \( n \) if
  \begin{equation*}
    f(t x) = t^n f(x).
  \end{equation*}

  This is a generalization of \hyperref[eq:def:semimodule/homomorphism/homogeneity]{homogeneity} used in the definition of linear maps.
\end{definition}

\begin{proposition}\label{thm:homogeneous_polynomial_is_homogeneous_function}
  A \hyperref[def:homogeneous_polynomial]{homogeneous polynomial} is a \hyperref[def:homogenous_function]{homogeneous function} of the same degree.
\end{proposition}
\begin{proof}
  Trivial.
\end{proof}

\begin{proposition}\label{thm:polarization_identity}\mcite{nLab:polarization_identity}
  Let \( L: V \times V \to \BbbK \) be a \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form} and define \( Q(x) \coloneqq L(x, x) \). Then the \term{polarization identity} holds:
  \begin{equation}\label{thm:polarization_identity/polarization_identity}
    Q(x + y) - Q(x - y) = 2 L(x, y) + 2 L(y, x)
  \end{equation}

  The similar looking, but slightly less useful parallelogram law also holds:
  \begin{equation}\label{thm:polarization_identity/parallelogram_law}
    Q(x + y) + Q(x - y) = 2 Q(x) + 2 Q(y)
  \end{equation}

  We can \enquote{recover} \( L \) from \( Q \):
  \begin{equation}\label{thm:polarization_identity/definition}
    L(x, y) \coloneqq \frac 1 2 \bracks{ Q(x + y) - Q(x) - Q(y) }.
  \end{equation}
\end{proposition}
\begin{proof}
  The identities all follow from the bilinearity of \( L \), that is,
  \begin{equation*}
    Q(x \pm y)
    =
    L(x, x) \pm L(x, y) \pm L(y, x) + L(y, y)
    =
    [Q(x) + Q(y)] \pm [L(x, y) + L(y, x)].
  \end{equation*}
\end{proof}

\begin{proposition}\label{thm:quadratic_forms}
  There is a bijective correspondence between \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear forms} and \hyperref[def:homogeneous_polynomial]{homogeneous} \hyperref[def:polynomial_degree]{quadratic polynomials}.

  A \term{quadratic form} \( Q: V \to \BbbK \) is defined as either \( Q(x) \coloneqq L(x, x) \) for a symmetric bilinear form \( L \), or as the \hyperref[thm:polynomial_algebra_universal_property]{polynomial function} of a homogeneous quadratic polynomial.

  \hi{Real} quadratic forms are simply quadratic forms over \( \BbbK = \BbbR \). \hi{Complex} quadratic forms, by contrast, differ from the general theory --- see \fullref{rem:complex_quadratic_form}.
\end{proposition}
\begin{proof}
  First, let \( L: V \times V \to \BbbK \) be a bilinear form. Let \( e_k, k \in \mscrK, \) be a \hyperref[def:hamel_basis]{basis} of \( V \). Define the polynomial
  \begin{equation*}
    p_L(X_k \given k \in \mscrK) \coloneqq \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) X_i X_j.
  \end{equation*}

  Conversely, let \( p(X_k \given k \in \mscrK) \) be a homogeneous quadratic polynomial over the set of indeterminates \( \mscrX \). Via \eqref{thm:polarization_identity/definition}, we can define
  \begin{equation*}
    L_p(x, y) = \frac 1 2 \bracks{ p(x + y) - p(x) - p(y) },
  \end{equation*}
  where \( x \) and \( y \) are vectors from \( V \) (i.e. \( \mscrX \)-indexed tuples).

  Given a symmetric bilinear form \( L \), we have
  \begin{balign*}
    &\phantom{{}={}}
    L_{p_L}(x, y)
    = \\ &=
    \frac 1 2 \parens*{ \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) (x_i + y_i) (x_j + y_j) - \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) x_i x_j - \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) y_i y_j }
    = \\ &=
    \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) x_i y_j + \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} L(e_i, e_j) y_i x_j
    = \\ &=
    \sum_{j \in \mscrK} L\parens*{ \sum_{i \in \mscrK} x_i e_i, \sum_{j \in \mscrK} y_j e_j }
    = \\ &=
    L(x, y).
  \end{balign*}

  Conversely, given a homogeneous quadratic polynomial \( p \), we have
  \begin{balign*}
    &\phantom{{}={}}
    p_{L_p}(X_k \given k \in \mscrK)
    = \\ &=
    \sum_{i \in \mscrK} \sum_{j \in \mscrK} L_p(e_i, e_j) X_i X_j
    = \\ &=
    \sum_{i \in \mscrK} \sum_{j \in \mscrK} L_p(e_i, e_j) X_i X_j
    = \\ &=
    \frac 1 2 \sum_{i \in \mscrK} \sum_{j \in \mscrK} \bracks{ p(e_i + e_j) - p(e_i) - p(e_j) } X_i X_j.
  \end{balign*}

  By definition, all \hyperref[def:basis_decomposition]{coordinate projections} of \( e_i \) are zero except for the \( i \)-th coordinate, which is one. Hence, the value \( p(e_i) \) is the coefficient before \( X_i^2 \) in \( p \), and similarly for \( p(e_j) \). The value \( p(e_i + e_j) \) is the sum of coefficients before \( X_i^2 \), \( X_i X_j \) and \( X_j^2 \). Therefore,
  \begin{equation*}
    p(e_i + e_j) - p(e_i) - p(e_j)
  \end{equation*}
  is the coefficient before \( X_i X_j \). Furthermore, \( X_i X_j \) is equal to \( X_j X_i \), and so are their coefficients, which allows us to cancel \( \ifrac 1 2 \) above. Thus,
  \begin{equation*}
    p_{L_p}(X_k \given k \in \mscrK) = p(X_k \given k \in \mscrK).
  \end{equation*}
\end{proof}

\begin{definition}\label{def:antilinear_function}\mimprovised
  We say that the function \( L: V \to W \) between complex vector spaces is \term{antilinear} if it satisfies the additivity condition \eqref{eq:def:semimodule/homomorphism/additive} and if
  \begin{equation}\label{eq:def:antilinear_function}
    L(tx) = \overline t L(x).
  \end{equation}

  That is, we enhance the homogeneity condition \eqref{eq:def:semimodule/homomorphism/homogeneity} from \fullref{def:semimodule/homomorphism} with \hyperref[def:set_of_complex_numbers]{complex conjugation}.
\end{definition}

\begin{definition}\label{def:sesquilinear_form}\mcite[258]{Knapp2016BasicAlgebra}
  A \term{sesquilinear\footnote{\enquote{sesqui} is a Latin prefix meaning \enquote{one and a half}} form} over the \hyperref[def:set_of_complex_numbers]{complex} vector space \( V \) is a function \( L: V \times V \to \BbbC \) that is \hyperref[def:semimodule/homomorphism]{linear} in the first argument and \hyperref[def:antilinear_function]{antilinear} in the second.

  Unlike bilinear forms, we have \( L(x, ty) = \overline t L(x, y) \) rather than \( L(x, ty) = t L(x, y) \). Sesquilinear forms coincide with bilinear forms when restricted to real numbers.
\end{definition}

\begin{definition}\label{def:hermitian_form}\mcite[258]{Knapp2016BasicAlgebra}
  A \hyperref[def:sesquilinear_form]{sesquilinear form} \( L: V \times V \to \BbbC \) is called \term{Hermitian} if
  \begin{equation*}
    L(x, y) = \overline{L(y, x)}.
  \end{equation*}

  Hermitian forms coincide with symmetric forms when restricted to real numbers.
\end{definition}

\begin{definition}\label{def:conjugate_transpose}
  The \term{conjugate transpose} \( A^* \) of the matrix \( A \) over the complex numbers is the \hyperref[def:transpose_matrix]{transpose matrix} in which we take the complex conjugate of every entry.
\end{definition}

\begin{remark}\label{rem:complex_quadratic_form}
  \hyperref[thm:quadratic_forms]{Quadratic forms} can be defined for complex numbers in multiple ways. The obvious definition is to take the base field to be \( \BbbC \). The more popular definition is presented below.

  Let \( L: V \times V \to \BbbC \) be a \hyperref[def:hermitian_form]{Hermitian} \hyperref[def:sesquilinear_form]{sesquilinear form}. Exchanging its parameters yields
  \begin{equation*}
    L(x, x) = \overline {L(x, x)},
  \end{equation*}
  which ensures that \( Q(x) \coloneqq L(x, x) \) is always a real number. Thus, we regard \( Q \) as a function from \( V \) to \( \BbbR \). This is not a quadratic form in the sense of \fullref{thm:quadratic_forms}, but we will call it a \term{complex quadratic form}.

  The definition via homogeneous quadratic polynomials is no longer compatible.
\end{remark}

\begin{definition}\label{def:quadratic_form_definiteness}\mimprovised
  We say that the real or \hyperref[rem:complex_quadratic_form]{complex quadratic form} \( Q: V \to \BbbR \) is
  \begin{thmenum}
    \thmitem{def:quadratic_form_definiteness/positive_semidefinite} \term{positive semidefinite} if \( Q(x) \geq 0 \) for all \( x \in V \).
    \thmitem{def:quadratic_form_definiteness/negative_semidefinite} \term{negative semidefinite} if \( Q(x) \leq 0 \) for all \( x \in V \).
    \thmitem{def:quadratic_form_definiteness/positive_definite} \term{positive definite} if \( Q(x) > 0 \) for all \( x \neq 0_V \).
    \thmitem{def:quadratic_form_definiteness/negative_definite} \term{negative definite} if \( Q(x) < 0 \) for all \( x \neq 0_V \).
    \thmitem{def:quadratic_form_definiteness/indefinite} \term{indefinite} otherwise.
  \end{thmenum}

  The above terminology also applies to symmetric bilinear or Hermitian sesquilinear forms, since they can be used to obtain a quadratic form.
\end{definition}

\begin{proposition}\label{thm:quadratic_forms_are_nondegenerate}
  \hyperref[def:quadratic_form_definiteness]{Definite} \hyperref[thm:quadratic_forms]{quadratic forms} are \hyperref[def:degenerate_bilinear_form]{nondegenerate}.
\end{proposition}
\begin{proof}
  In the real case, the quadratic form is induced by some symmetric bilinear form
  \begin{equation*}
    L: V \times V \to \BbbR.
  \end{equation*}

  Suppose also that \( L \) is positive definite. Due to positive (resp. negative) definiteness, for every \( x \neq 0 \), \( L(x, y) \) is positive (resp. negative) when \( y = x \). Hence, \( L(x, y) = 0 \) for every \( y \) if and only if \( x = 0 \). Hence, \( L \) is nondegenerate.

  In the complex case, the quadratic form is induced by some Hermitian sesquilinear form
  \begin{equation*}
    L: V \times V \to \BbbC.
  \end{equation*}

  Again, \( L(x, y) \) is zero for all \( y \) when \( x = 0 \), hence \( L \) is nondegenerate.
\end{proof}

\begin{definition}\label{def:inner_product_space}\mimprovised
  A \term{real inner product space} is a vector space \( V \) over \( \BbbR \) equipped with a \hyperref[def:quadratic_form_definiteness/positive_definite]{positive definite} \hyperref[def:symmetric_function]{symmetric} \hyperref[def:bilinear_form]{bilinear form}
  \begin{equation*}
    \inprod \anon \anon: V \times V \to \BbbR.
  \end{equation*}

  A \term{complex inner product space} is a vector space \( V \) over \( \BbbC \) equipped with a \hyperref[def:quadratic_form_definiteness/positive_definite]{positive definite} \hyperref[def:hermitian_form]{Hermitian} \hyperref[def:sesquilinear_form]{sesquilinear form}
  \begin{equation*}
    \inprod \anon \anon: V \times V \to \BbbC.
  \end{equation*}

  This notation is generalized for application of linear functionals --- see \fullref{rem:dual_space_bilinear_form}.
\end{definition}

\begin{theorem}[Cauchy-Bunyakovsky-Schwarz inequality]\label{thm:cauchy_bunyakovsky_schwarz_inequality}
  In a real or complex \hyperref[def:inner_product_space]{inner product space}, the following inequality holds:
  \begin{equation}\label{thm:cauchy_bunyakovsky_schwarz_inequality/inequality}
    {\abs{\inprod x y}}^2 \leq \inprod x x \cdot \inprod y y.
  \end{equation}

  Furthermore, equality holds if and only if \( x \) and \( y \) are linearly dependent.
\end{theorem}
\begin{proof}
  \SubProof{Proof of inequality} Fix \( x, y \in V \) and \( t \in \BbbC \). If either \( x \) or \( y \) is the zero vector, the statement is trivially true. Suppose that both are nonzero.

  We have
  \begin{balign*}
    Q(x + ty)
     & =
    \inprod {x + ty} {x + ty}
    =    \\ &=
    Q(x) + \overline t \inprod x y + t \inprod y x + \abs{t}^2 Q(y)
    =    \\ &=
    Q(x) + 2\real \parens*{ t \overline{\inprod x y} } + \abs{t}^2 Q(y).
  \end{balign*}

  Take \( t \coloneqq - \ifrac {\inprod x y} {Q(y)} \), so that
  \begin{equation*}
    Q(x + ty)
    =
    Q(x) - 2 \frac {\abs{\inprod x y}^2} {Q(y)} + \frac {\abs{\inprod x y}^2} {Q(y)}
    =
    Q(x) - \frac {\abs{\inprod x y}^2} {Q(y)}.
  \end{equation*}

  Since \( Q(x + ty) \geq 0 \), it follows that
  \begin{balign*}
    Q(x) - \frac {\abs{\inprod x y}^2} {Q(y)} & \geq 0                  \\
    Q(x) Q(y)                               & \geq \abs{\inprod x y}^2.
  \end{balign*}

  \SubProof{Proof of equality} If \( x \) and \( y \) are linearly dependent, equality obviously holds. Conversely, suppose that equality holds. This implies that
  \begin{equation*}
    Q(x + ty) = 0,
  \end{equation*}
  which by the positive definiteness of \( Q \) means that \( x = -ty \). Thus, \( x \) and \( y \) are linearly dependent.
\end{proof}
